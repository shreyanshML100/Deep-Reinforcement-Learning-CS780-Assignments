{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4W0UvZfuIlz"
      },
      "source": [
        "# ASSIGNMENT 3\n",
        "# Submission Deadline: 20/03/2024 at 10 AM\n",
        "# Submission Link: https://forms.gle/b8s6xYHUYqTJtSNeA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3g2EECAuIl2"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "1. [Provide Information](#Provide-Information)\n",
        "2. [Instructions](#Instructions)\n",
        "3. [Environment](#Environment)\n",
        "4. [Hyperparameters](#Hyperparameters)\n",
        "5. [Helper Functions](#helper)\n",
        "6. [Deep Value Based RL Agents](#deep-value-based)\n",
        "7. [Deep Policy Based RL Agents](#deep-policy-based)\n",
        "8. [Experiments to Run](#experiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_wwBSy9uIl3"
      },
      "source": [
        "# Provide Information\n",
        "<a id=\"Provide-Information\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71bet7leuIl4"
      },
      "source": [
        "*Name*: **Shreyansh Pachauri**\n",
        "\n",
        "Roll No.: **200954**\n",
        "\n",
        "IITK EMail: **shreyanshp20@iitk.ac.in**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71VT5aQsuIl4"
      },
      "source": [
        "# Instructions\n",
        "<a id=\"Instructions\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eu9H0JWuIl4"
      },
      "source": [
        "**Read all the instructions below carefully before you start working on the assignment.**\n",
        "- The purpose of this course is that you learn RL and the best way to do that is by implementation and experimentation.\n",
        "- The assignment requires your to implement some algorithms and you are required report your findings after experimenting with those algorithms.\n",
        "- **You are required to submit ZIP file containing a Jupyter notebook (.ipynb), and an image folder. The notebook would include the code, graphs/plots of the experiments you run and your findings/observations. Image folder is the folder having plots, images, etc.**\n",
        "- In case you use any maths in your explanations, render it using latex in the Jupyter notebook.\n",
        "- You are expected to implement algorithms on your own and not copy it from other sources/class mates. Of course, you can refer to lecture slides.\n",
        "- If you use any reference or material (including code), please cite the source, else it will be considered plagiarism. But referring to other sources that directly solve the problems given in the assignment is not allowed. There is a limit to which you can refer to outside material.\n",
        "- This is an individual assignment.\n",
        "- In case your solution is found to have an overlap with solution by someone else (including external sources), all the parties involved will get zero in this and all future assignments plus further more penalties in the overall grade. We will check not just for lexical but also semantic overlap. Same applies for the code as well. Even an iota of cheating would NOT be tolerated. If you cheat one line or cheat one page the penalty would be same.\n",
        "- Be a smart agent, think long term, if you cheat we will discover it somehow, the price you would be paying is not worth it.\n",
        "- In case you are struggling with the assignment, seek help from TAs. Cheating is not an option! I respect honesty and would be lenient if you are not able to solve some questions due to difficulty in understanding. Remember we are there to help you out, seek help if something is difficult to understand.\n",
        "- The deadline for the submission is given above. Submit at least 30 minutes before the deadline, lot can happen at the last moment, your internet can fail, there can be a power failure, you can be abducted by aliens, etc.\n",
        "- You have to submit your assignment via the Google Form (link above)\n",
        "- The form would close after the deadline and we will not accept any solution. No reason what-so-ever would be accepted for not being able to submit before the deadline.\n",
        "- Since the assignment involves experimentation, reporting your results and observations, there is a lot of scope for creativity and innovation and presenting new perspectives. Such efforts would be highly appreciated and accordingly well rewarded. Be an exploratory agent!\n",
        "- Your code should be very well documented, there are marks for that.\n",
        "- In your plots, have a clear legend and clear lines, etc. Of course you would generating the plots in your code but you must also put these plots in your notebook. Generate high resolution pdf/svg version of the plots so that it doesn't pixilate on zooming.\n",
        "- For all experiments, report about the seed used in the code documentation, write about the seed used.\n",
        "- In your notebook write about all things that are not obvious from the code e.g., if you have made any assumptions, references/sources, running time, etc.\n",
        "-  **DO NOT Forget to write name, roll no and email details above**\n",
        "- **In addition to checking your code, we will be conducting one-on-one viva for the evaluation. So please make sure that you do not cheat!**\n",
        "- **Use of LLMs based tools or AI-based code tools is strictly prohibited! Use of ChatGPT, VS Code, Gemini, CO-Pilot, etc. is not allowed. NOTE VS code is also not allowed. Even in Colab disable the AI assistant. If you use it, we will know it very easily. Use of any of the tools would be counted as cheating and would be given a ZERO, with no questions asked.**\n",
        "- For each of the sub-part in the question create a new cell below the question and put your answer in there. This includes the plots as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qBWxtCjuIl5"
      },
      "source": [
        "# OpenAI Gym Environments\n",
        "<a id=\"Environment\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6G3AOdsuIl5",
        "outputId": "eb86b1a8-4116-49d5-867c-ad07764b97bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.10.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ],
      "source": [
        "# all imports go in here\n",
        "!pip install gymnasium\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import warnings\n",
        "import time\n",
        "import math\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXs_Hw7luIl6"
      },
      "source": [
        "In this assignment we will be exploring Deep RL algorithms and for this we will be using environmentd provided by OpenAI Gym. In particualr we will be exploring \"CartPole-v0\" and \"MountainCar-v0\" environments (https://gymnasium.farama.org/environments/classic_control/ ). The code to instantiate the environments are given in the cells below. Run these cells and play with the environments to learn more details about the environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE7YzeCauIl7",
        "outputId": "10f55c8c-7f4a-4193-a79e-4b21499fb7e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Space = \n",
            "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
            "Action Space = \n",
            "Discrete(2)\n",
            "In episode 0\n",
            "[-0.00352371 -0.03320037  0.00612009 -0.02651561]\n",
            "[-0.00418772 -0.22840956  0.00558978  0.26809198]\n",
            "[-0.00875591 -0.03336782  0.01095162 -0.02282267]\n",
            "[-0.00942327  0.16159537  0.01049516 -0.31203023]\n",
            "[-0.00619136 -0.03367451  0.00425456 -0.016056  ]\n",
            "[-0.00686485 -0.22885722  0.00393344  0.27796626]\n",
            "[-0.01144199 -0.0337916   0.00949276 -0.01347349]\n",
            "[-0.01211782 -0.22904839  0.00922329  0.28218934]\n",
            "[-0.01669879 -0.42430067  0.01486708  0.5777669 ]\n",
            "[-0.02518481 -0.22939022  0.02642242  0.2898043 ]\n",
            "[-0.02977261 -0.03465481  0.0322185   0.00557044]\n",
            "[-0.03046571  0.15999062  0.03232991 -0.2767756 ]\n",
            "[-0.02726589  0.35463676  0.0267944  -0.5590889 ]\n",
            "[-0.02017316  0.15914917  0.01561262 -0.25808614]\n",
            "[-0.01699018  0.3540448   0.0104509  -0.545804  ]\n",
            "[-0.00990928  0.15877756 -0.00046518 -0.24984667]\n",
            "[-0.00673373  0.35390615 -0.00546211 -0.54267627]\n",
            "[ 3.4439494e-04  5.4910445e-01 -1.6315639e-02 -8.3707517e-01]\n",
            "[ 0.01132648  0.7444454  -0.03305714 -1.1348442 ]\n",
            "[ 0.02621539  0.9399839  -0.05575403 -1.4377087 ]\n",
            "[ 0.04501507  1.135747   -0.0845082  -1.7472802 ]\n",
            "[ 0.06773001  1.3317215  -0.11945381 -2.0650089 ]\n",
            "[ 0.09436444  1.5278409  -0.16075398 -2.3921275 ]\n",
            "[ 0.12492125  1.3344537  -0.20859653 -2.1528451 ]\n",
            "Finished after 24 timestep\n",
            "In episode 1\n",
            "[-0.04045401 -0.04183607 -0.00214596 -0.01608562]\n",
            "[-0.04129073  0.15331659 -0.00246768 -0.30944484]\n",
            "[-0.0382244   0.3484736  -0.00865657 -0.602905  ]\n",
            "[-0.03125492  0.15347381 -0.02071467 -0.31296122]\n",
            "[-0.02818545  0.34888464 -0.0269739  -0.6121043 ]\n",
            "[-0.02120776  0.15414985 -0.03921598 -0.3280377 ]\n",
            "[-0.01812476  0.34980753 -0.04577674 -0.63282514]\n",
            "[-0.01112861  0.5455372  -0.05843324 -0.9395657 ]\n",
            "[-2.1786561e-04  7.4139607e-01 -7.7224553e-02 -1.2500222e+00]\n",
            "[ 0.01461006  0.54734415 -0.102225   -0.9824933 ]\n",
            "[ 0.02555694  0.3537295  -0.12187486 -0.72358924]\n",
            "[ 0.03263153  0.55030733 -0.13634665 -1.0520115 ]\n",
            "[ 0.04363767  0.74694794 -0.15738688 -1.3841968 ]\n",
            "[ 0.05857664  0.94364345 -0.18507081 -1.7216742 ]\n",
            "Finished after 14 timestep\n",
            "In episode 2\n",
            "[-0.01893888 -0.04964757 -0.03719389  0.00262153]\n",
            "[-0.01993183 -0.24421692 -0.03714146  0.28334123]\n",
            "[-0.02481617 -0.43878996 -0.03147464  0.56408244]\n",
            "[-0.03359197 -0.63345647 -0.02019299  0.8466856 ]\n",
            "[-0.0462611  -0.43806496 -0.00325927  0.54772174]\n",
            "[-0.0550224  -0.24289739  0.00769516  0.25401366]\n",
            "[-0.05988035 -0.04788615  0.01277543 -0.03623217]\n",
            "[-0.06083807  0.14705029  0.01205079 -0.3248571 ]\n",
            "[-0.05789706 -0.04824115  0.00555365 -0.02839836]\n",
            "[-0.05886189  0.14680071  0.00498568 -0.3193239 ]\n",
            "[-0.05592587 -0.04839189 -0.0014008  -0.02507284]\n",
            "[-0.05689371  0.14675012 -0.00190225 -0.3181974 ]\n",
            "[-0.05395871 -0.04834468 -0.0082662  -0.02611498]\n",
            "[-0.0549256  -0.24334712 -0.0087885   0.26394844]\n",
            "[-0.05979254 -0.04810083 -0.00350953 -0.03149346]\n",
            "[-0.06075456 -0.24317229 -0.0041394   0.2600801 ]\n",
            "[-0.06561801 -0.04799148  0.0010622  -0.03390556]\n",
            "[-0.06657784  0.14711522  0.00038409 -0.32625315]\n",
            "[-0.06363553 -0.0480122  -0.00614097 -0.03344913]\n",
            "[-0.06459577 -0.24304555 -0.00680996  0.25728995]\n",
            "[-0.06945669 -0.04782704 -0.00166416 -0.03753315]\n",
            "[-0.07041322  0.14731874 -0.00241482 -0.33074066]\n",
            "[-0.06746686  0.34247497 -0.00902963 -0.62418413]\n",
            "[-0.06061735  0.14748025 -0.02151332 -0.33435863]\n",
            "[-0.05766775  0.34290168 -0.02820049 -0.6337474 ]\n",
            "[-0.05080971  0.5384054  -0.04087544 -0.93517625]\n",
            "[-0.04004161  0.73405415 -0.05957896 -1.2404182 ]\n",
            "[-0.02536052  0.5397457  -0.08438732 -0.9669785 ]\n",
            "[-0.01456561  0.73589325 -0.10372689 -1.2849333 ]\n",
            "[ 1.5225644e-04  5.4223341e-01 -1.2942557e-01 -1.0264460e+00]\n",
            "[ 0.01099692  0.34904975 -0.14995448 -0.77703905]\n",
            "[ 0.01797792  0.54588073 -0.16549526 -1.1128938 ]\n",
            "[ 0.02889553  0.35327256 -0.18775314 -0.8763628 ]\n",
            "[ 0.03596098  0.550382   -0.2052804  -1.2217066 ]\n",
            "Finished after 34 timestep\n",
            "In episode 3\n",
            "[-0.0374822   0.04278443  0.00914606 -0.00775024]\n",
            "[-0.03662651 -0.15246749  0.00899106  0.28780428]\n",
            "[-0.03967586 -0.3477165   0.01474714  0.5833093 ]\n",
            "[-0.04663019 -0.15280421  0.02641333  0.29530817]\n",
            "[-0.04968628  0.04193141  0.03231949  0.01107123]\n",
            "[-0.04884765  0.2365753   0.03254091 -0.27124187]\n",
            "[-0.04411614  0.43121818  0.02711608 -0.5534862 ]\n",
            "[-0.03549178  0.625949    0.01604635 -0.837504  ]\n",
            "[-0.0229728   0.43061167 -0.00070373 -0.5398183 ]\n",
            "[-0.01436056  0.23549962 -0.01150009 -0.24735716]\n",
            "[-0.00965057  0.4307839  -0.01644724 -0.5436452 ]\n",
            "[-0.00103489  0.6261331  -0.02732014 -0.8414646 ]\n",
            "[ 0.01148777  0.8216171  -0.04414943 -1.1426123 ]\n",
            "[ 0.02792011  1.0172873  -0.06700168 -1.4488074 ]\n",
            "[ 0.04826586  1.2131659  -0.09597783 -1.7616497 ]\n",
            "[ 0.07252917  1.0192522  -0.13121082 -1.500292  ]\n",
            "[ 0.09291422  1.215701   -0.16121666 -1.8308976 ]\n",
            "[ 0.11722824  1.4121997  -0.19783461 -2.1690164 ]\n",
            "Finished after 18 timestep\n",
            "In episode 4\n",
            "[-0.04749201 -0.01157624  0.01850433  0.00250476]\n",
            "[-0.04772354  0.1832755   0.01855442 -0.28428286]\n",
            "[-0.04405803  0.378128    0.01286876 -0.5710566 ]\n",
            "[-0.03649547  0.18282795  0.00144763 -0.27434748]\n",
            "[-0.03283891 -0.01231462 -0.00403932  0.01879168]\n",
            "[-0.0330852   0.18286502 -0.00366348 -0.27516297]\n",
            "[-0.0294279   0.37803906 -0.00916674 -0.5689991 ]\n",
            "[-0.02186712  0.18304686 -0.02054673 -0.27921808]\n",
            "[-0.01820618  0.3784558  -0.02613109 -0.57830995]\n",
            "[-0.01063707  0.18370964 -0.03769729 -0.29397207]\n",
            "[-0.00696287 -0.01085514 -0.04357673 -0.01341263]\n",
            "[-0.00717998  0.18486379 -0.04384498 -0.31951985]\n",
            "[-0.0034827   0.38058186 -0.05023538 -0.62570107]\n",
            "[ 0.00412894  0.57636774 -0.0627494  -0.93377244]\n",
            "[ 0.01565629  0.77227753 -0.08142485 -1.245495  ]\n",
            "[ 0.03110184  0.578289   -0.10633475 -0.9793887 ]\n",
            "[ 0.04266762  0.77466327 -0.12592252 -1.3034899 ]\n",
            "[ 0.05816089  0.97113717 -0.15199232 -1.6327908 ]\n",
            "[ 0.07758363  0.7780916  -0.18464814 -1.3910747 ]\n",
            "Finished after 19 timestep\n",
            "In episode 5\n",
            "[-0.03639025  0.03034079  0.00995679 -0.01086032]\n",
            "[-0.03578344  0.22531854  0.00973958 -0.3003852 ]\n",
            "[-0.03127707  0.03005913  0.00373188 -0.00464658]\n",
            "[-0.03067588 -0.16511615  0.00363895  0.28921145]\n",
            "[-0.03397821 -0.36028978  0.00942318  0.5830398 ]\n",
            "[-0.041184   -0.16530111  0.02108397  0.29334018]\n",
            "[-0.04449002 -0.36071724  0.02695078  0.5925974 ]\n",
            "[-0.05170437 -0.16598272  0.03880272  0.3085243 ]\n",
            "[-0.05502402 -0.36163545  0.04497321  0.6131877 ]\n",
            "[-0.06225673 -0.55735606  0.05723697  0.9196894 ]\n",
            "[-0.07340386 -0.36305252  0.07563075  0.6455298 ]\n",
            "[-0.0806649  -0.1690614   0.08854135  0.37758926]\n",
            "[-0.08404613 -0.36532196  0.09609313  0.696824  ]\n",
            "[-0.09135257 -0.17165466  0.11002962  0.43587118]\n",
            "[-0.09478567  0.02175173  0.11874704  0.17979942]\n",
            "[-0.09435063 -0.17485163  0.12234303  0.5074573 ]\n",
            "[-0.09784766  0.01835331  0.13249217  0.2556953 ]\n",
            "[-0.0974806  -0.17838696  0.13760608  0.5870581 ]\n",
            "[-0.10104834  0.0145668   0.14934725  0.34069204]\n",
            "[-0.100757   -0.18232949  0.15616108  0.6764939 ]\n",
            "[-0.10440359  0.01031759  0.16969097  0.43676454]\n",
            "[-0.10419724 -0.18674886  0.17842625  0.77776855]\n",
            "[-0.10793222  0.00552973  0.19398162  0.54610896]\n",
            "[-0.10782162  0.19747317  0.2049038   0.3202674 ]\n",
            "Finished after 24 timestep\n",
            "In episode 6\n",
            "[-0.00482921  0.01269625  0.04984669  0.04018256]\n",
            "[-0.00457529 -0.18310374  0.05065034  0.3481666 ]\n",
            "[-0.00823736  0.01126258  0.05761367  0.07187585]\n",
            "[-0.00801211 -0.184636    0.05905119  0.3821652 ]\n",
            "[-0.01170483 -0.3805445   0.06669449  0.69286674]\n",
            "[-0.01931572 -0.5765252   0.08055183  1.0057778 ]\n",
            "[-0.03084623 -0.382566    0.10066738  0.7394391 ]\n",
            "[-0.03849754 -0.5789232   0.11545616  1.06203   ]\n",
            "[-0.05007601 -0.77536875  0.13669676  1.3886052 ]\n",
            "[-0.06558339 -0.5821891   0.16446887  1.1416026 ]\n",
            "[-0.07722717 -0.7790331   0.18730092  1.4810205 ]\n",
            "Finished after 11 timestep\n",
            "In episode 7\n",
            "[-0.02035617 -0.00723859  0.0081766  -0.01896771]\n",
            "[-0.02050094  0.18776515  0.00779725 -0.30905965]\n",
            "[-0.01674564 -0.00746703  0.00161606 -0.01392792]\n",
            "[-0.01689498 -0.20261212  0.0013375   0.27926445]\n",
            "[-0.02094722 -0.39775312  0.00692279  0.5723689 ]\n",
            "[-0.02890228 -0.20272893  0.01837017  0.28187492]\n",
            "[-0.03295686 -0.00787375  0.02400766 -0.00495799]\n",
            "[-0.03311434 -0.20333163  0.02390851  0.29520193]\n",
            "[-0.03718097 -0.39878613  0.02981254  0.59532833]\n",
            "[-0.04515669 -0.20409384  0.04171911  0.31218323]\n",
            "[-0.04923857 -0.39978454  0.04796277  0.61772573]\n",
            "[-0.05723426 -0.20536424  0.06031729  0.34052628]\n",
            "[-0.06134154 -0.01115005  0.06712782  0.06745731]\n",
            "[-0.06156454 -0.20716698  0.06847696  0.38054127]\n",
            "[-0.06570788 -0.40319112  0.07608779  0.69400483]\n",
            "[-0.07377171 -0.59928143  0.08996788  1.0096376 ]\n",
            "[-0.08575734 -0.79548144  0.11016063  1.3291622 ]\n",
            "[-0.10166696 -0.6019083   0.13674387  1.0728843 ]\n",
            "[-0.11370513 -0.7985466   0.15820156  1.4051658 ]\n",
            "[-0.12967606 -0.6057025   0.18630488  1.1658295 ]\n",
            "Finished after 20 timestep\n",
            "In episode 8\n",
            "[ 0.02941129 -0.04766902 -0.01913818 -0.00433155]\n",
            "[ 0.02845791  0.1477221  -0.01922481 -0.30299082]\n",
            "[ 0.03141235 -0.04712066 -0.02528462 -0.01643244]\n",
            "[ 0.03046994 -0.24187104 -0.02561327  0.26816687]\n",
            "[ 0.02563252 -0.43661827 -0.02024993  0.55266243]\n",
            "[ 0.01690015 -0.63145006 -0.00919669  0.83889717]\n",
            "[ 0.00427115 -0.8264453   0.00758126  1.1286738 ]\n",
            "[-0.01225776 -1.0216657   0.03015473  1.4237249 ]\n",
            "[-0.03269107 -0.8269293   0.05862923  1.1406171 ]\n",
            "[-0.04922966 -1.0227666   0.08144157  1.4510955 ]\n",
            "[-0.06968498 -1.2187893   0.11046349  1.7680724 ]\n",
            "[-0.09406077 -1.0250747   0.14582492  1.5116818 ]\n",
            "[-0.11456227 -1.2216308   0.17605856  1.8461075 ]\n",
            "Finished after 13 timestep\n",
            "In episode 9\n",
            "[-0.01852578 -0.00040352 -0.03746991 -0.03919268]\n",
            "[-0.01853385  0.19523516 -0.03825376 -0.3434583 ]\n",
            "[-0.01462915  0.00067771 -0.04512293 -0.06307948]\n",
            "[-0.0146156   0.19641659 -0.04638452 -0.3696506 ]\n",
            "[-0.01068726  0.00198332 -0.05377753 -0.09194652]\n",
            "[-0.0106476   0.19783318 -0.05561646 -0.4010996 ]\n",
            "[-0.00669093  0.3936981  -0.06363845 -0.7107855 ]\n",
            "[ 0.00118303  0.19951248 -0.07785416 -0.43879378]\n",
            "[ 0.00517328  0.39564505 -0.08663004 -0.75496745]\n",
            "[ 0.01308618  0.5918476  -0.10172939 -1.0736051 ]\n",
            "[ 0.02492313  0.39820647 -0.12320149 -0.81450194]\n",
            "[ 0.03288726  0.59478074 -0.13949153 -1.143258  ]\n",
            "[ 0.04478287  0.7914219  -0.16235669 -1.4762324 ]\n",
            "[ 0.06061131  0.98811185 -0.19188133 -1.8149108 ]\n",
            "Finished after 14 timestep\n",
            "In episode 10\n",
            "[ 0.01997691  0.01923424 -0.01585499  0.00915329]\n",
            "[ 0.02036159  0.21457994 -0.01567192 -0.2884896 ]\n",
            "[ 0.02465319  0.01968494 -0.02144171 -0.00079037]\n",
            "[ 0.02504689 -0.17512305 -0.02145752  0.28505108]\n",
            "[ 0.02154443 -0.3699325  -0.0157565   0.57088995]\n",
            "[ 0.01414578 -0.56483    -0.0043387   0.85856766]\n",
            "[ 0.00284918 -0.7598926   0.01283265  1.1498833 ]\n",
            "[-0.01234867 -0.56494045  0.03583032  0.8612518 ]\n",
            "[-0.02364748 -0.37032425  0.05305535  0.5800467 ]\n",
            "[-0.03105397 -0.17598434  0.06465629  0.304538  ]\n",
            "[-0.03457366  0.01815947  0.07074705  0.03292651]\n",
            "[-0.03421047  0.21219932  0.07140558 -0.23662288]\n",
            "[-0.02996648  0.40623233  0.06667312 -0.5059553 ]\n",
            "[-0.02184183  0.6003545   0.05655402 -0.7769042 ]\n",
            "[-0.00983474  0.79465497  0.04101593 -1.051271  ]\n",
            "[ 0.00605836  0.59901375  0.01999051 -0.7460006 ]\n",
            "[ 0.01803863  0.40362173  0.0050705  -0.44709435]\n",
            "[ 0.02611107  0.5986716  -0.00387139 -0.7381747 ]\n",
            "[ 0.0380845   0.40360332 -0.01863488 -0.4467126 ]\n",
            "[ 0.04615656  0.20874988 -0.02756913 -0.15996155]\n",
            "[ 0.05033156  0.40425545 -0.03076836 -0.46121275]\n",
            "[ 0.05841667  0.20958158 -0.03999262 -0.17838465]\n",
            "[ 0.0626083   0.01505408 -0.04356031  0.10141859]\n",
            "[ 0.06290939  0.21077237 -0.04153194 -0.20468304]\n",
            "[ 0.06712483  0.0162682  -0.0456256   0.07461476]\n",
            "[ 0.0674502  -0.17817098 -0.04413331  0.35256073]\n",
            "[ 0.06388678  0.01754986 -0.03708209  0.04629435]\n",
            "[ 0.06423777  0.21318339 -0.0361562  -0.25785384]\n",
            "[ 0.06850144  0.40880236 -0.04131328 -0.56171817]\n",
            "[ 0.07667749  0.604479   -0.05254764 -0.8671253 ]\n",
            "[ 0.08876707  0.41010997 -0.06989015 -0.5914161 ]\n",
            "[ 0.09696927  0.6061372  -0.08171847 -0.9052701 ]\n",
            "[ 0.10909201  0.80226505 -0.09982387 -1.2224786 ]\n",
            "[ 0.12513731  0.9985212  -0.12427344 -1.5446968 ]\n",
            "[ 0.14510773  0.8050921  -0.15516739 -1.2932332 ]\n",
            "[ 0.16120958  1.0018079  -0.18103205 -1.6301981 ]\n",
            "Finished after 36 timestep\n",
            "In episode 11\n",
            "[ 0.03009993  0.00603678 -0.04936165 -0.00838687]\n",
            "[ 0.03022067 -0.18834378 -0.04952939  0.2683224 ]\n",
            "[ 0.02645379  0.00744874 -0.04416294 -0.03956192]\n",
            "[ 0.02660277 -0.187013   -0.04495418  0.23886661]\n",
            "[ 0.02286251  0.00872136 -0.04017685 -0.0676504 ]\n",
            "[ 0.02303693  0.2043956  -0.04152986 -0.37273374]\n",
            "[ 0.02712485  0.40008217 -0.04898453 -0.67821676]\n",
            "[ 0.03512649  0.5958492  -0.06254887 -0.9859107 ]\n",
            "[ 0.04704347  0.40161818 -0.08226708 -0.71351135]\n",
            "[ 0.05507584  0.20772575 -0.09653731 -0.44781557]\n",
            "[ 0.05923035  0.01409247 -0.10549362 -0.1870559 ]\n",
            "[ 0.0595122   0.21055317 -0.10923474 -0.5110663 ]\n",
            "[ 0.06372327  0.0171258  -0.11945606 -0.25470573]\n",
            "[ 0.06406578  0.21373282 -0.12455018 -0.58255124]\n",
            "[ 0.06834044  0.0205557  -0.1362012  -0.33155334]\n",
            "[ 0.06875155 -0.17239127 -0.14283226 -0.08473268]\n",
            "[ 0.06530373  0.0244585  -0.14452693 -0.41885054]\n",
            "[ 0.0657929   0.22130102 -0.15290393 -0.7533791 ]\n",
            "[ 0.07021892  0.41816333 -0.16797152 -1.0900061 ]\n",
            "[ 0.07858218  0.2256053  -0.18977164 -0.854386  ]\n",
            "[ 0.08309429  0.42273638 -0.20685937 -1.2002326 ]\n",
            "Finished after 21 timestep\n",
            "In episode 12\n",
            "[-0.03346933  0.03229204  0.02275758  0.01564472]\n",
            "[-0.03282349  0.22708035  0.02307048 -0.26977193]\n",
            "[-0.02828188  0.0316369   0.01767504  0.03009734]\n",
            "[-0.02764914 -0.163734    0.01827699  0.3283041 ]\n",
            "[-0.03092382  0.03112305  0.02484307  0.04144048]\n",
            "[-0.03030136 -0.16434617  0.02567188  0.34185696]\n",
            "[-0.03358829 -0.3598238   0.03250902  0.64252347]\n",
            "[-0.04078476 -0.55538344  0.04535948  0.9452639 ]\n",
            "[-0.05189243 -0.36090085  0.06426476  0.6671712 ]\n",
            "[-0.05911045 -0.1667287   0.07760818  0.39539507]\n",
            "[-0.06244502  0.02721122  0.08551609  0.12815472]\n",
            "[-0.0619008   0.22101063  0.08807918 -0.136371  ]\n",
            "[-0.05748058  0.4147678   0.08535177 -0.40001833]\n",
            "[-0.04918523  0.6085819   0.0773514  -0.6646182 ]\n",
            "[-0.03701359  0.80254745  0.06405903 -0.9319779 ]\n",
            "[-0.02096264  0.60662234  0.04541947 -0.6198725 ]\n",
            "[-0.0088302   0.41089642  0.03302202 -0.31323773]\n",
            "[-0.00061227  0.21532     0.02675727 -0.01032632]\n",
            "[0.00369413 0.01982473 0.02655074 0.2906773 ]\n",
            "[ 0.00409063 -0.17566554  0.03236429  0.59161437]\n",
            "[0.00057732 0.01898872 0.04419658 0.30929932]\n",
            "[ 0.00095709 -0.17673418  0.05038256  0.6155865 ]\n",
            "[-0.00257759  0.01764898  0.0626943   0.339188  ]\n",
            "[-0.00222461  0.21182542  0.06947805  0.06691563]\n",
            "[0.0020119  0.01577969 0.07081637 0.38068485]\n",
            "[ 0.00232749 -0.18027265  0.07843006  0.6948289 ]\n",
            "[-0.00127796  0.01367889  0.09232664  0.42783073]\n",
            "[-0.00100439  0.20738025  0.10088325  0.16562165]\n",
            "[0.00314322 0.01096974 0.10419569 0.48834887]\n",
            "[ 0.00336261 -0.18545605  0.11396267  0.81196773]\n",
            "[-3.4650695e-04 -3.8193923e-01  1.3020203e-01  1.1382133e+00]\n",
            "[-0.00798529 -0.18873774  0.15296629  0.8890353 ]\n",
            "[-0.01176005 -0.38556752  0.170747    1.2256294 ]\n",
            "[-0.0194714  -0.1930048   0.19525959  0.99094176]\n",
            "Finished after 34 timestep\n",
            "In episode 13\n",
            "[-0.01646666  0.03533808 -0.00913517  0.01600304]\n",
            "[-0.0157599  -0.15965168 -0.00881511  0.30578977]\n",
            "[-0.01895294 -0.35464692 -0.00269931  0.59567964]\n",
            "[-0.02604587 -0.54973096  0.00921428  0.8875111 ]\n",
            "[-0.03704049 -0.35473529  0.0269645   0.5977389 ]\n",
            "[-0.0441352  -0.16000083  0.03891928  0.31367   ]\n",
            "[-0.04733521 -0.35565495  0.04519268  0.6183684 ]\n",
            "[-0.05444831 -0.16119245  0.05756005  0.34025455]\n",
            "[-0.05767217 -0.35708416  0.06436514  0.6505188 ]\n",
            "[-0.06481384 -0.16291496  0.07737552  0.37877837]\n",
            "[-0.06807215  0.03102777  0.08495108  0.11146041]\n",
            "[-0.06745159 -0.16520226  0.08718029  0.42968956]\n",
            "[-0.07075564 -0.36144364  0.09577408  0.74853224]\n",
            "[-0.0779845  -0.16776416  0.11074473  0.487459  ]\n",
            "[-0.08133979 -0.36426017  0.1204939   0.8128899 ]\n",
            "[-0.08862499 -0.5608082   0.1367517   1.1409138 ]\n",
            "[-0.09984116 -0.3677126   0.15956998  0.8940543 ]\n",
            "[-0.10719541 -0.5645967   0.17745106  1.2323433 ]\n",
            "[-0.11848734 -0.37214383  0.20209794  1.0000944 ]\n",
            "Finished after 19 timestep\n",
            "In episode 14\n",
            "[ 0.00843393  0.0022332  -0.04096878 -0.02183641]\n",
            "[ 0.00847859  0.19791801 -0.04140551 -0.32715878]\n",
            "[ 0.01243695  0.39360425 -0.04794868 -0.63260627]\n",
            "[ 0.02030903  0.5893612  -0.06060081 -0.9399957 ]\n",
            "[ 0.03209626  0.39510614 -0.07940073 -0.66695374]\n",
            "[ 0.03999838  0.5912373  -0.0927398  -0.9835429 ]\n",
            "[ 0.05182313  0.39747196 -0.11241066 -0.72137034]\n",
            "[ 0.05977257  0.5939546  -0.12683807 -1.0472134 ]\n",
            "[ 0.07165166  0.7905107  -0.14778234 -1.3768696 ]\n",
            "[ 0.08746187  0.5975113  -0.17531973 -1.133816  ]\n",
            "[ 0.0994121   0.79443926 -0.19799605 -1.4759601 ]\n",
            "Finished after 11 timestep\n",
            "In episode 15\n",
            "[-0.02955807 -0.04941426 -0.01964332 -0.03376633]\n",
            "[-0.03054635  0.1459838  -0.02031865 -0.33258164]\n",
            "[-0.02762668 -0.04884315 -0.02697028 -0.04637481]\n",
            "[-0.02860354  0.14665495 -0.02789778 -0.3474436 ]\n",
            "[-0.02567044 -0.04805931 -0.03484665 -0.06368675]\n",
            "[-0.02663163  0.14754447 -0.03612038 -0.36715716]\n",
            "[-0.02368074  0.34316057 -0.04346353 -0.671007  ]\n",
            "[-0.01681753  0.53885895 -0.05688367 -0.9770516 ]\n",
            "[-0.00604035  0.7346957  -0.0764247  -1.2870463 ]\n",
            "[ 0.00865357  0.5406249  -0.10216562 -1.0192369 ]\n",
            "[ 0.01946606  0.7369491  -0.12255036 -1.342172  ]\n",
            "[ 0.03420505  0.93338144 -0.1493938  -1.6705505 ]\n",
            "[ 0.05287268  1.1298904  -0.18280481 -2.0057893 ]\n",
            "Finished after 13 timestep\n",
            "In episode 16\n",
            "[3.8438559e-02 4.0010765e-02 2.4408575e-05 4.1572817e-02]\n",
            "[ 0.03923877  0.23513237  0.00085586 -0.25110242]\n",
            "[ 0.04394142  0.0399982  -0.00416618  0.04185035]\n",
            "[ 0.04474138 -0.15506376 -0.00332918  0.3332159 ]\n",
            "[ 0.04164011 -0.35013816  0.00333514  0.6248471 ]\n",
            "[ 0.03463735 -0.5453065   0.01583208  0.91857857]\n",
            "[ 0.02373121 -0.35040212  0.03420366  0.630913  ]\n",
            "[ 0.01672317 -0.1557737   0.04682191  0.34919506]\n",
            "[ 0.0136077  -0.3515292   0.05380582  0.65626717]\n",
            "[ 0.00657711 -0.15719596  0.06693116  0.3810004 ]\n",
            "[ 0.00343319 -0.3532013   0.07455117  0.6940132 ]\n",
            "[-0.00363083 -0.15918833  0.08843143  0.42569983]\n",
            "[-0.0068146   0.03457701  0.09694543  0.16215248]\n",
            "[-0.00612306  0.22818707  0.10018848 -0.09844163]\n",
            "[-0.00155932  0.03178259  0.09821965  0.22409391]\n",
            "[-0.00092366  0.22537355  0.10270152 -0.03606281]\n",
            "[ 0.00358381  0.41888425  0.10198027 -0.2946582 ]\n",
            "[0.01196149 0.22246745 0.09608711 0.02836653]\n",
            "[0.01641084 0.02610826 0.09665443 0.34975284]\n",
            "[ 0.01693301 -0.17024592  0.10364949  0.6712816 ]\n",
            "[0.01352809 0.02329406 0.11707512 0.41294807]\n",
            "[0.01399397 0.21657875 0.12533408 0.15934722]\n",
            "[0.01832554 0.01990607 0.12852103 0.48879403]\n",
            "[0.01872367 0.21300285 0.1382969  0.23921894]\n",
            "[ 0.02298372  0.40590605  0.14308129 -0.00684339]\n",
            "[ 0.03110184  0.59871703  0.14294443 -0.25118196]\n",
            "[0.04307618 0.40187395 0.13792078 0.08295392]\n",
            "[0.05111367 0.20507212 0.13957986 0.41577372]\n",
            "[0.05521511 0.39796844 0.14789534 0.17014658]\n",
            "[0.06317448 0.20107326 0.15129827 0.5055881 ]\n",
            "[0.06719594 0.3937756  0.16141003 0.26414886]\n",
            "[0.07507145 0.19676206 0.166693   0.6030767 ]\n",
            "[0.07900669 0.38920864 0.17875454 0.3671892 ]\n",
            "[0.08679087 0.58140004 0.18609832 0.13577007]\n",
            "[0.09841887 0.38416776 0.18881372 0.48090792]\n",
            "[0.10610222 0.18695256 0.19843188 0.8266552 ]\n",
            "Finished after 36 timestep\n",
            "In episode 17\n",
            "[ 0.00043461 -0.03808929 -0.03197179  0.02304311]\n",
            "[-0.00032717  0.15747623 -0.03151092 -0.27955335]\n",
            "[ 0.00282235  0.35303319 -0.03710199 -0.58200586]\n",
            "[ 0.00988302  0.5486548  -0.04874211 -0.88614184]\n",
            "[ 0.02085611  0.35422722 -0.06646495 -0.60917133]\n",
            "[ 0.02794066  0.16009428 -0.07864837 -0.3381412 ]\n",
            "[ 0.03114254 -0.03382556 -0.08541119 -0.07125939]\n",
            "[ 0.03046603  0.16241045 -0.08683638 -0.38962075]\n",
            "[ 0.03371424  0.35865065 -0.0946288  -0.7083698 ]\n",
            "[ 0.04088725  0.16495802 -0.10879619 -0.44691002]\n",
            "[ 0.04418641 -0.02847022 -0.11773439 -0.19040616]\n",
            "[ 0.04361701  0.16812202 -0.12154251 -0.5177871 ]\n",
            "[ 0.04697945  0.36472678 -0.13189825 -0.8461642 ]\n",
            "[ 0.05427399  0.1716271  -0.14882155 -0.59769636]\n",
            "[ 0.05770653 -0.0211335  -0.16077547 -0.35534367]\n",
            "[ 0.05728386  0.17586556 -0.16788234 -0.69409597]\n",
            "[ 0.06080117  0.3728692  -0.18176426 -1.0345727 ]\n",
            "[ 0.06825855  0.5698811  -0.20245571 -1.3783672 ]\n",
            "Finished after 18 timestep\n",
            "In episode 18\n",
            "[ 0.04625218 -0.00750923  0.01117556 -0.02016648]\n",
            "[ 0.046102   -0.20278965  0.01077223  0.2760214 ]\n",
            "[ 0.0420462  -0.00782303  0.01629266 -0.01324458]\n",
            "[ 0.04188975  0.18706152  0.01602777 -0.30074278]\n",
            "[ 0.04563098  0.3819514   0.01001291 -0.58832806]\n",
            "[ 0.05327     0.5769317  -0.00175365 -0.87784016]\n",
            "[ 0.06480864  0.77207744 -0.01931045 -1.1710739 ]\n",
            "[ 0.08025019  0.57721186 -0.04273193 -0.8845069 ]\n",
            "[ 0.09179442  0.7728872  -0.06042207 -1.1903113 ]\n",
            "[ 0.10725217  0.96873784 -0.08422829 -1.5013045 ]\n",
            "[ 0.12662692  1.1647755  -0.11425439 -1.8190523 ]\n",
            "[ 0.14992243  1.3609672  -0.15063544 -2.144939  ]\n",
            "[ 0.17714177  1.55722    -0.19353421 -2.480104  ]\n",
            "Finished after 13 timestep\n",
            "In episode 19\n",
            "[-0.01993645 -0.03736181  0.00720256  0.00805151]\n",
            "[-0.02068368 -0.23258631  0.00736359  0.30299821]\n",
            "[-0.02533541 -0.42781243  0.01342355  0.5979943 ]\n",
            "[-0.03389166 -0.6231196   0.02538344  0.8948751 ]\n",
            "[-0.04635405 -0.8185764   0.04328094  1.1954278 ]\n",
            "[-0.06272558 -0.6240407   0.0671895   0.9166181 ]\n",
            "[-0.07520639 -0.42988846  0.08552186  0.64578575]\n",
            "[-0.08380416 -0.23605578  0.09843758  0.38121212]\n",
            "[-0.08852528 -0.04245935  0.10606182  0.12111721]\n",
            "[-0.08937446 -0.23892838  0.10848416  0.44528848]\n",
            "[-0.09415303 -0.04549504  0.11738993  0.18867598]\n",
            "[-0.09506293  0.14776888  0.12116345 -0.06479132]\n",
            "[-0.09210756  0.3409641   0.11986762 -0.31692463]\n",
            "[-0.08528827  0.14435694  0.11352913  0.01102674]\n",
            "[-0.08240113 -0.05219466  0.11374967  0.33726206]\n",
            "[-0.08344503  0.14114034  0.12049491  0.08250406]\n",
            "[-0.08062222  0.33434743  0.12214499 -0.16986538]\n",
            "[-0.07393527  0.13770814  0.11874768  0.15871736]\n",
            "[-0.07118111 -0.05889605  0.12192203  0.48637667]\n",
            "[-0.07235903 -0.2555084   0.13164957  0.8148623 ]\n",
            "[-0.0774692  -0.06241119  0.1479468   0.5663161 ]\n",
            "[-0.07871743 -0.25926498  0.15927313  0.90170896]\n",
            "[-0.08390272 -0.45614454  0.17730731  1.239919  ]\n",
            "[-0.09302561 -0.6530436   0.20210569  1.5824928 ]\n",
            "Finished after 24 timestep\n"
          ]
        }
      ],
      "source": [
        "# Create CartPole environment\n",
        "#https://gymnasium.farama.org/environments/classic_control/cart_pole/\n",
        "\n",
        "env = gym.make('CartPole-v0')\n",
        "env.seed = 34\n",
        "s = env.reset()\n",
        "print(\"Observation Space = \")\n",
        "print(env.observation_space)\n",
        "print(\"Action Space = \")\n",
        "print(env.action_space)\n",
        "done = False\n",
        "for episode in range(20):\n",
        "    done=False\n",
        "    s = env.reset()[0]\n",
        "    print(\"In episode {}\".format(episode))\n",
        "    for i in range(100):\n",
        "        env.render()\n",
        "        print(s)\n",
        "        a = env.action_space.sample()\n",
        "        s, r, done, _, info = env.step(a)\n",
        "        if done:\n",
        "            print(\"Finished after {} timestep\".format(i+1))\n",
        "            break\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5Ckc3MHuIl7",
        "outputId": "61e15685-ab00-4215-efb4-84c8ffd055d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "-1.0\n",
            "[-0.5784719   0.00453034]\n",
            "2\n",
            "-1.0\n",
            "[-0.57453185  0.00394004]\n",
            "0\n",
            "-1.0\n",
            "[-0.57121134  0.00332055]\n",
            "0\n",
            "-1.0\n",
            "[-0.5665349   0.00467643]\n",
            "2\n",
            "-1.0\n",
            "[-0.5625374   0.00399756]\n",
            "0\n",
            "-1.0\n",
            "[-0.5582484   0.00428894]\n",
            "1\n",
            "-1.0\n",
            "[-0.5537001   0.00454834]\n",
            "1\n",
            "-1.0\n",
            "[-0.5499263   0.00377379]\n",
            "0\n",
            "-1.0\n",
            "[-0.5469552   0.00297104]\n",
            "0\n",
            "-1.0\n",
            "[-0.54480916  0.00214608]\n",
            "0\n",
            "-1.0\n",
            "[-0.5415041   0.00330505]\n",
            "2\n",
            "-1.0\n",
            "[-0.53706485  0.00443927]\n",
            "2\n",
            "-1.0\n",
            "[-0.5335246   0.00354024]\n",
            "0\n",
            "-1.0\n",
            "[-0.5289099   0.00461467]\n",
            "2\n",
            "-1.0\n",
            "[-0.52525544  0.0036545 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.5215885   0.00366693]\n",
            "1\n",
            "-1.0\n",
            "[-0.51793665  0.00365185]\n",
            "1\n",
            "-1.0\n",
            "[-0.5143272   0.00360939]\n",
            "1\n",
            "-1.0\n",
            "[-0.5097874   0.00453986]\n",
            "2\n",
            "-1.0\n",
            "[-0.50535107  0.0044363 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.50005156  0.00529951]\n",
            "2\n",
            "-1.0\n",
            "[-0.49592853  0.00412306]\n",
            "0\n",
            "-1.0\n",
            "[-0.49301276  0.00291577]\n",
            "0\n",
            "-1.0\n",
            "[-0.49132606  0.0016867 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.489881    0.00144503]\n",
            "1\n",
            "-1.0\n",
            "[-0.48868844  0.00119258]\n",
            "1\n",
            "-1.0\n",
            "[-0.48675722  0.00193123]\n",
            "2\n",
            "-1.0\n",
            "[-0.48510173  0.00165548]\n",
            "1\n",
            "-1.0\n",
            "[-0.48373434  0.00136739]\n",
            "1\n",
            "-1.0\n",
            "[-0.48266524  0.00106912]\n",
            "1\n",
            "-1.0\n",
            "[-0.48090234  0.00176289]\n",
            "2\n",
            "-1.0\n",
            "[-0.4784588   0.00244354]\n",
            "2\n",
            "-1.0\n",
            "[-0.47735277  0.00110603]\n",
            "0\n",
            "-1.0\n",
            "[-0.47659248  0.00076029]\n",
            "1\n",
            "-1.0\n",
            "[-4.7618356e-01  4.0891199e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.47512907  0.0010545 ]\n",
            "2\n",
            "-1.0\n",
            "[-4.7543684e-01 -3.0774708e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.47610453 -0.00066771]\n",
            "1\n",
            "-1.0\n",
            "[-0.47812724 -0.00202271]\n",
            "0\n",
            "-1.0\n",
            "[-0.48048994 -0.00236269]\n",
            "1\n",
            "-1.0\n",
            "[-0.48217502 -0.0016851 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.48317    -0.00099498]\n",
            "2\n",
            "-1.0\n",
            "[-0.48546746 -0.00229746]\n",
            "0\n",
            "-1.0\n",
            "[-0.48805028 -0.00258282]\n",
            "1\n",
            "-1.0\n",
            "[-0.48989922 -0.00184893]\n",
            "2\n",
            "-1.0\n",
            "[-0.49300045 -0.00310124]\n",
            "0\n",
            "-1.0\n",
            "[-0.49533087 -0.00233041]\n",
            "2\n",
            "-1.0\n",
            "[-0.49687302 -0.00154216]\n",
            "2\n",
            "-1.0\n",
            "[-0.4986154  -0.00174239]\n",
            "1\n",
            "-1.0\n",
            "[-0.500545   -0.00192959]\n",
            "1\n",
            "-1.0\n",
            "[-0.5026474  -0.00210236]\n",
            "1\n",
            "-1.0\n",
            "[-0.50590676 -0.00325939]\n",
            "0\n",
            "-1.0\n",
            "[-0.5092988  -0.00339202]\n",
            "1\n",
            "-1.0\n",
            "[-0.513798   -0.00449923]\n",
            "0\n",
            "-1.0\n",
            "[-0.51737076 -0.00357273]\n",
            "2\n",
            "-1.0\n",
            "[-0.5209902  -0.00361944]\n",
            "1\n",
            "-1.0\n",
            "[-0.5236292 -0.002639 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.52526796 -0.00163877]\n",
            "2\n",
            "-1.0\n",
            "[-0.5268942  -0.00162625]\n",
            "1\n",
            "-1.0\n",
            "[-0.52749574 -0.00060154]\n",
            "2\n",
            "-1.0\n",
            "[-0.52906805 -0.00157231]\n",
            "0\n",
            "-1.0\n",
            "In episode 4\n",
            "(array([-0.5540557,  0.       ], dtype=float32), {})\n",
            "0\n",
            "-1.0\n",
            "[-0.5528276   0.00122811]\n",
            "2\n",
            "-1.0\n",
            "[-0.5503805   0.00244704]\n",
            "2\n",
            "-1.0\n",
            "[-0.5487328   0.00164769]\n",
            "0\n",
            "-1.0\n",
            "[-0.5478968   0.00083602]\n",
            "0\n",
            "-1.0\n",
            "[-5.4787874e-01  1.8092393e-05]\n",
            "0\n",
            "-1.0\n",
            "[-0.5486787  -0.00079997]\n",
            "0\n",
            "-1.0\n",
            "[-0.55029076 -0.00161205]\n",
            "0\n",
            "-1.0\n",
            "[-5.507028e-01 -4.120710e-04]\n",
            "2\n",
            "-1.0\n",
            "[-5.5091184e-01 -2.0901463e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5499162  0.0009956]\n",
            "2\n",
            "-1.0\n",
            "[-0.54872346  0.00119278]\n",
            "1\n",
            "-1.0\n",
            "[-0.5473424   0.00138104]\n",
            "1\n",
            "-1.0\n",
            "[-0.54678345  0.00055896]\n",
            "0\n",
            "-1.0\n",
            "[-5.470507e-01 -2.672917e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.4714227e-01 -9.1547045e-05]\n",
            "1\n",
            "-1.0\n",
            "[-0.5460574   0.00108488]\n",
            "2\n",
            "-1.0\n",
            "[-0.5438042   0.00225319]\n",
            "2\n",
            "-1.0\n",
            "[-0.5423996   0.00140464]\n",
            "0\n",
            "-1.0\n",
            "[-0.54185396  0.00054557]\n",
            "0\n",
            "-1.0\n",
            "[-5.4217160e-01 -3.1758033e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.54134995  0.00082164]\n",
            "2\n",
            "-1.0\n",
            "[-5.413952e-01 -4.528569e-05]\n",
            "0\n",
            "-1.0\n",
            "[-5.413071e-01  8.812420e-05]\n",
            "1\n",
            "-1.0\n",
            "[-0.5400862   0.00122087]\n",
            "2\n",
            "-1.0\n",
            "[-0.5377417   0.00234448]\n",
            "2\n",
            "-1.0\n",
            "[-0.5342912   0.00345052]\n",
            "2\n",
            "-1.0\n",
            "[-0.5317605  0.0025307]\n",
            "0\n",
            "-1.0\n",
            "[-0.5301686   0.00159191]\n",
            "0\n",
            "-1.0\n",
            "[-0.52852744  0.00164118]\n",
            "1\n",
            "-1.0\n",
            "[-0.5258493   0.00267814]\n",
            "2\n",
            "-1.0\n",
            "[-0.52315426  0.00269502]\n",
            "1\n",
            "-1.0\n",
            "[-0.5204626   0.00269169]\n",
            "1\n",
            "-1.0\n",
            "[-0.5187944   0.00166816]\n",
            "0\n",
            "-1.0\n",
            "[-0.5161623   0.00263213]\n",
            "2\n",
            "-1.0\n",
            "[-0.5145859   0.00157636]\n",
            "0\n",
            "-1.0\n",
            "[-5.140771e-01  5.087760e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.1363975e-01  4.3737353e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5142771  -0.00063731]\n",
            "0\n",
            "-1.0\n",
            "[-5.1398432e-01  2.9278858e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.5127636   0.00122069]\n",
            "2\n",
            "-1.0\n",
            "[-0.5106242   0.00213944]\n",
            "2\n",
            "-1.0\n",
            "[-0.508582    0.00204216]\n",
            "1\n",
            "-1.0\n",
            "[-0.50765246  0.00092957]\n",
            "0\n",
            "-1.0\n",
            "[-5.0784242e-01 -1.8998398e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.50915056 -0.00130811]\n",
            "0\n",
            "-1.0\n",
            "[-0.511567   -0.00241644]\n",
            "0\n",
            "-1.0\n",
            "[-0.51507366 -0.00350666]\n",
            "0\n",
            "-1.0\n",
            "[-0.5176442  -0.00257059]\n",
            "2\n",
            "-1.0\n",
            "[-0.51925945 -0.00161525]\n",
            "2\n",
            "-1.0\n",
            "[-0.5209073  -0.00164779]\n",
            "1\n",
            "-1.0\n",
            "[-0.52357525 -0.00266798]\n",
            "0\n",
            "-1.0\n",
            "[-0.5272434  -0.00366815]\n",
            "0\n",
            "-1.0\n",
            "[-0.5308842  -0.00364082]\n",
            "1\n",
            "-1.0\n",
            "[-0.5354704  -0.00458618]\n",
            "0\n",
            "-1.0\n",
            "[-0.53896755 -0.00349716]\n",
            "2\n",
            "-1.0\n",
            "[-0.5433495  -0.00438194]\n",
            "0\n",
            "-1.0\n",
            "[-0.5485834 -0.0052339]\n",
            "0\n",
            "-1.0\n",
            "[-0.5536301  -0.00504669]\n",
            "1\n",
            "-1.0\n",
            "[-0.5594518  -0.00582176]\n",
            "0\n",
            "-1.0\n",
            "[-0.5640052  -0.00455338]\n",
            "2\n",
            "-1.0\n",
            "[-0.5682563  -0.00425107]\n",
            "1\n",
            "-1.0\n",
            "[-0.5731734  -0.00491714]\n",
            "0\n",
            "-1.0\n",
            "[-0.5777201 -0.0045467]\n",
            "1\n",
            "-1.0\n",
            "[-0.5818627  -0.00414257]\n",
            "1\n",
            "-1.0\n",
            "[-0.5855705  -0.00370781]\n",
            "1\n",
            "-1.0\n",
            "[-0.58781624 -0.0022457 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.59058326 -0.00276704]\n",
            "0\n",
            "-1.0\n",
            "[-0.5918513  -0.00126803]\n",
            "2\n",
            "-1.0\n",
            "[-0.593611   -0.00175971]\n",
            "0\n",
            "-1.0\n",
            "[-0.59484947 -0.00123847]\n",
            "1\n",
            "-1.0\n",
            "[-0.5965576  -0.00170815]\n",
            "0\n",
            "-1.0\n",
            "[-5.9672290e-01 -1.6531421e-04]\n",
            "2\n",
            "-1.0\n",
            "[-5.9634417e-01  3.7872858e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5944242  0.00192  ]\n",
            "2\n",
            "-1.0\n",
            "[-0.590977   0.0034472]\n",
            "2\n",
            "-1.0\n",
            "[-0.58602786  0.0049491 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.57961327  0.00641459]\n",
            "2\n",
            "-1.0\n",
            "[-0.57278055  0.00683272]\n",
            "1\n",
            "-1.0\n",
            "[-0.5645803   0.00820025]\n",
            "2\n",
            "-1.0\n",
            "[-0.5560735   0.00850684]\n",
            "1\n",
            "-1.0\n",
            "[-0.54832345  0.00775001]\n",
            "0\n",
            "-1.0\n",
            "[-0.54038817  0.00793528]\n",
            "1\n",
            "-1.0\n",
            "[-0.53232706  0.00806115]\n",
            "1\n",
            "-1.0\n",
            "[-0.52420044  0.0081266 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.51706934  0.00713111]\n",
            "0\n",
            "-1.0\n",
            "[-0.5089872   0.00808215]\n",
            "2\n",
            "-1.0\n",
            "[-0.5020146   0.00697259]\n",
            "0\n",
            "-1.0\n",
            "[-0.49520376  0.00681083]\n",
            "1\n",
            "-1.0\n",
            "[-0.48960564  0.00559812]\n",
            "0\n",
            "-1.0\n",
            "[-0.48326203  0.00634361]\n",
            "2\n",
            "-1.0\n",
            "[-0.4772202   0.00604183]\n",
            "1\n",
            "-1.0\n",
            "[-0.4715251   0.00569511]\n",
            "1\n",
            "-1.0\n",
            "[-0.46721897  0.00430614]\n",
            "0\n",
            "-1.0\n",
            "[-0.46333364  0.00388531]\n",
            "1\n",
            "-1.0\n",
            "[-0.45889786  0.00443578]\n",
            "2\n",
            "-1.0\n",
            "[-0.45394433  0.00495356]\n",
            "2\n",
            "-1.0\n",
            "[-0.44850937  0.00543495]\n",
            "2\n",
            "-1.0\n",
            "[-0.44263285  0.00587653]\n",
            "2\n",
            "-1.0\n",
            "[-0.43635762  0.00627524]\n",
            "2\n",
            "-1.0\n",
            "In episode 5\n",
            "(array([-0.57829344,  0.        ], dtype=float32), {})\n",
            "1\n",
            "-1.0\n",
            "[-5.7788509e-01  4.0837194e-04]\n",
            "1\n",
            "-1.0\n",
            "[-5.7807136e-01 -1.8627809e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.7785094e-01  2.2045043e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5762254   0.00162555]\n",
            "2\n",
            "-1.0\n",
            "[-0.57520676  0.00101861]\n",
            "0\n",
            "-1.0\n",
            "[-5.7480264e-01  4.0412476e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.7501602e-01 -2.1335477e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.57584524 -0.00082925]\n",
            "0\n",
            "-1.0\n",
            "[-0.5772843  -0.00143901]\n",
            "0\n",
            "-1.0\n",
            "[-5.7732236e-01 -3.8104325e-05]\n",
            "2\n",
            "-1.0\n",
            "[-0.57595927  0.00136308]\n",
            "2\n",
            "-1.0\n",
            "[-0.5742051   0.00175417]\n",
            "1\n",
            "-1.0\n",
            "[-0.57207286  0.00213226]\n",
            "1\n",
            "-1.0\n",
            "[-0.5695783   0.00249454]\n",
            "1\n",
            "-1.0\n",
            "[-0.56674004  0.00283829]\n",
            "1\n",
            "-1.0\n",
            "[-0.56457907  0.00216095]\n",
            "0\n",
            "-1.0\n",
            "[-0.56311154  0.00146753]\n",
            "0\n",
            "-1.0\n",
            "[-0.56034833  0.00276318]\n",
            "2\n",
            "-1.0\n",
            "[-0.5573101   0.00303824]\n",
            "1\n",
            "-1.0\n",
            "[-0.5550195   0.00229065]\n",
            "0\n",
            "-1.0\n",
            "[-0.5534935   0.00152595]\n",
            "0\n",
            "-1.0\n",
            "[-0.5517436   0.00174986]\n",
            "1\n",
            "-1.0\n",
            "[-0.54878294  0.0029607 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.54463357  0.0041494 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.5413265   0.00330706]\n",
            "0\n",
            "-1.0\n",
            "[-0.53788656  0.00343995]\n",
            "1\n",
            "-1.0\n",
            "[-0.5353395   0.00254708]\n",
            "0\n",
            "-1.0\n",
            "[-0.53370434  0.00163512]\n",
            "0\n",
            "-1.0\n",
            "[-0.53099346  0.0027109 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.5272271   0.00376635]\n",
            "2\n",
            "-1.0\n",
            "[-0.52443355  0.00279356]\n",
            "0\n",
            "-1.0\n",
            "[-0.5206337   0.00379982]\n",
            "2\n",
            "-1.0\n",
            "[-0.5178561   0.00277759]\n",
            "0\n",
            "-1.0\n",
            "[-0.5141216   0.00373452]\n",
            "2\n",
            "-1.0\n",
            "[-0.51145816  0.00266345]\n",
            "0\n",
            "-1.0\n",
            "[-0.5098857   0.00157241]\n",
            "0\n",
            "-1.0\n",
            "[-0.5074161  0.0024696]\n",
            "2\n",
            "-1.0\n",
            "[-0.5060679   0.00134827]\n",
            "0\n",
            "-1.0\n",
            "[-5.0585103e-01  2.1685266e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.0576723e-01  8.3807405e-05]\n",
            "1\n",
            "-1.0\n",
            "[-5.0581706e-01 -4.9865506e-05]\n",
            "1\n",
            "-1.0\n",
            "[-0.50700027 -0.00118317]\n",
            "0\n",
            "-1.0\n",
            "[-0.5083079 -0.0013076]\n",
            "1\n",
            "-1.0\n",
            "[-0.5107301  -0.00242224]\n",
            "0\n",
            "-1.0\n",
            "[-0.5122488  -0.00151874]\n",
            "2\n",
            "-1.0\n",
            "[-0.51285267 -0.00060384]\n",
            "2\n",
            "-1.0\n",
            "[-0.5145371  -0.00168443]\n",
            "0\n",
            "-1.0\n",
            "[-0.5152895  -0.00075238]\n",
            "2\n",
            "-1.0\n",
            "[-5.1510417e-01  1.8530723e-04]\n",
            "2\n",
            "-1.0\n",
            "[-5.14982581e-01  1.21604586e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5159256  -0.00094301]\n",
            "0\n",
            "-1.0\n",
            "[-0.5169261  -0.00100055]\n",
            "1\n",
            "-1.0\n",
            "[-0.51897675 -0.0020506 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.522062   -0.00308526]\n",
            "0\n",
            "-1.0\n",
            "[-0.52615875 -0.00409679]\n",
            "0\n",
            "-1.0\n",
            "[-0.53023636 -0.00407759]\n",
            "1\n",
            "-1.0\n",
            "[-0.53426415 -0.00402781]\n",
            "1\n",
            "-1.0\n",
            "[-0.538212   -0.00394783]\n",
            "1\n",
            "-1.0\n",
            "[-0.54205024 -0.00383827]\n",
            "1\n",
            "-1.0\n",
            "[-0.5447502  -0.00269995]\n",
            "2\n",
            "-1.0\n",
            "[-0.54629165 -0.00154142]\n",
            "2\n",
            "-1.0\n",
            "[-5.466630e-01 -3.713565e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.5478615  -0.00119851]\n",
            "0\n",
            "-1.0\n",
            "[-5.4787821e-01 -1.6703101e-05]\n",
            "2\n",
            "-1.0\n",
            "[-5.4771298e-01  1.6523164e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.548367   -0.00065407]\n",
            "0\n",
            "-1.0\n",
            "[-5.4883552e-01 -4.6847848e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5481149   0.00072062]\n",
            "2\n",
            "-1.0\n",
            "[-5.4821056e-01 -9.5678442e-05]\n",
            "0\n",
            "-1.0\n",
            "[-0.5471218   0.00108874]\n",
            "2\n",
            "-1.0\n",
            "[-0.54585683  0.00126502]\n",
            "1\n",
            "-1.0\n",
            "[-0.544425    0.00143183]\n",
            "1\n",
            "-1.0\n",
            "[-0.54183704  0.00258793]\n",
            "2\n",
            "-1.0\n",
            "[-0.54011244  0.00172464]\n",
            "0\n",
            "-1.0\n",
            "[-0.537264    0.00284845]\n",
            "2\n",
            "-1.0\n",
            "[-0.53531307  0.00195091]\n",
            "0\n",
            "-1.0\n",
            "[-0.53427434  0.00103875]\n",
            "0\n",
            "-1.0\n",
            "[-5.34155548e-01  1.18798285e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.3395754e-01  1.9796067e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.53268194  0.00127564]\n",
            "2\n",
            "-1.0\n",
            "[-0.53133816  0.00134375]\n",
            "1\n",
            "-1.0\n",
            "[-0.5289364   0.00240179]\n",
            "2\n",
            "-1.0\n",
            "[-0.5254946   0.00344182]\n",
            "2\n",
            "-1.0\n",
            "[-0.5220385   0.00345604]\n",
            "1\n",
            "-1.0\n",
            "[-0.51759416  0.00444434]\n",
            "2\n",
            "-1.0\n",
            "[-0.51419485  0.00339931]\n",
            "0\n",
            "-1.0\n",
            "[-0.5118661   0.00232879]\n",
            "0\n",
            "-1.0\n",
            "[-0.50962526  0.00224081]\n",
            "1\n",
            "-1.0\n",
            "[-0.5064892   0.00313604]\n",
            "2\n",
            "-1.0\n",
            "[-0.50348145  0.00300778]\n",
            "1\n",
            "-1.0\n",
            "[-0.5006245   0.00285699]\n",
            "1\n",
            "-1.0\n",
            "[-0.49793965  0.00268482]\n",
            "1\n",
            "-1.0\n",
            "[-0.4964471   0.00149256]\n",
            "0\n",
            "-1.0\n",
            "[-0.49515793  0.00128915]\n",
            "1\n",
            "-1.0\n",
            "[-4.950818e-01  7.610247e-05]\n",
            "0\n",
            "-1.0\n",
            "[-4.9521935e-01 -1.3751390e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.49456945  0.0006499 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.49513698 -0.00056755]\n",
            "0\n",
            "-1.0\n",
            "[-4.9491775e-01  2.1924829e-04]\n",
            "2\n",
            "-1.0\n",
            "In episode 6\n",
            "(array([-0.5987849,  0.       ], dtype=float32), {})\n",
            "1\n",
            "-1.0\n",
            "[-0.5972258   0.00155913]\n",
            "2\n",
            "-1.0\n",
            "[-0.596119    0.00110685]\n",
            "0\n",
            "-1.0\n",
            "[-0.59447247  0.00164647]\n",
            "1\n",
            "-1.0\n",
            "[-0.59129846  0.00317403]\n",
            "2\n",
            "-1.0\n",
            "[-0.5886202   0.00267829]\n",
            "0\n",
            "-1.0\n",
            "[-0.5864573   0.00216287]\n",
            "0\n",
            "-1.0\n",
            "[-0.5828258   0.00363152]\n",
            "2\n",
            "-1.0\n",
            "[-0.5797524   0.00307338]\n",
            "0\n",
            "-1.0\n",
            "[-0.57525986  0.00449255]\n",
            "2\n",
            "-1.0\n",
            "[-0.5693814   0.00587846]\n",
            "2\n",
            "-1.0\n",
            "[-0.56416065  0.00522075]\n",
            "0\n",
            "-1.0\n",
            "[-0.55763644  0.00652421]\n",
            "2\n",
            "-1.0\n",
            "[-0.5518574   0.00577905]\n",
            "0\n",
            "-1.0\n",
            "[-0.5448667   0.00699074]\n",
            "2\n",
            "-1.0\n",
            "[-0.5387165   0.00615014]\n",
            "0\n",
            "-1.0\n",
            "[-0.53345305  0.00526348]\n",
            "0\n",
            "-1.0\n",
            "[-0.52811563  0.00533738]\n",
            "1\n",
            "-1.0\n",
            "[-0.5237444   0.00437125]\n",
            "0\n",
            "-1.0\n",
            "[-0.51837206  0.00537235]\n",
            "2\n",
            "-1.0\n",
            "[-0.5140389   0.00433315]\n",
            "0\n",
            "-1.0\n",
            "[-0.5107775   0.00326146]\n",
            "0\n",
            "-1.0\n",
            "[-0.5076121   0.00316532]\n",
            "1\n",
            "-1.0\n",
            "[-0.5035667   0.00404547]\n",
            "2\n",
            "-1.0\n",
            "[-0.5006713   0.00289532]\n",
            "0\n",
            "-1.0\n",
            "[-0.49894786  0.0017235 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.49840906  0.00053878]\n",
            "0\n",
            "-1.0\n",
            "[-0.49705902  0.00135004]\n",
            "2\n",
            "-1.0\n",
            "[-0.49490783  0.0021512 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.49397153  0.00093629]\n",
            "0\n",
            "-1.0\n",
            "[-0.49325716  0.00071437]\n",
            "1\n",
            "-1.0\n",
            "[-4.9277005e-01  4.8712609e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.4935138  -0.00074376]\n",
            "0\n",
            "-1.0\n",
            "[-0.4954829  -0.00196909]\n",
            "0\n",
            "-1.0\n",
            "[-0.4966626  -0.00117971]\n",
            "2\n",
            "-1.0\n",
            "[-0.4980441  -0.00138151]\n",
            "1\n",
            "-1.0\n",
            "[-0.5006171  -0.00257298]\n",
            "0\n",
            "-1.0\n",
            "[-0.5033623  -0.00274521]\n",
            "1\n",
            "-1.0\n",
            "[-0.5052592  -0.00189689]\n",
            "2\n",
            "-1.0\n",
            "[-0.5072936  -0.00203437]\n",
            "1\n",
            "-1.0\n",
            "[-0.5094502  -0.00215661]\n",
            "1\n",
            "-1.0\n",
            "[-0.51171285 -0.00226269]\n",
            "1\n",
            "-1.0\n",
            "[-0.51406467 -0.00235182]\n",
            "1\n",
            "-1.0\n",
            "[-0.51548797 -0.00142331]\n",
            "2\n",
            "-1.0\n",
            "[-5.1597214e-01 -4.8413721e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.51651347 -0.00054133]\n",
            "1\n",
            "-1.0\n",
            "[-0.5171079  -0.00059447]\n",
            "1\n",
            "-1.0\n",
            "[-0.5177511  -0.00064315]\n",
            "1\n",
            "-1.0\n",
            "[-0.5194381 -0.001687 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.52015626 -0.00071821]\n",
            "2\n",
            "-1.0\n",
            "[-0.5219003  -0.00174402]\n",
            "0\n",
            "-1.0\n",
            "[-0.5246571  -0.00275676]\n",
            "0\n",
            "-1.0\n",
            "[-0.5264059  -0.00174883]\n",
            "2\n",
            "-1.0\n",
            "[-0.5291337  -0.00272777]\n",
            "0\n",
            "-1.0\n",
            "[-0.53081995 -0.00168626]\n",
            "2\n",
            "-1.0\n",
            "[-0.53145206 -0.00063211]\n",
            "2\n",
            "-1.0\n",
            "[-0.5320253  -0.00057321]\n",
            "1\n",
            "-1.0\n",
            "[-0.5335353  -0.00151002]\n",
            "0\n",
            "-1.0\n",
            "[-0.53497076 -0.00143551]\n",
            "1\n",
            "-1.0\n",
            "[-0.53632104 -0.00135024]\n",
            "1\n",
            "-1.0\n",
            "[-0.53757584 -0.00125484]\n",
            "1\n",
            "-1.0\n",
            "[-0.5397259  -0.00215005]\n",
            "0\n",
            "-1.0\n",
            "[-0.541755   -0.00202914]\n",
            "1\n",
            "-1.0\n",
            "[-0.5446481  -0.00289303]\n",
            "0\n",
            "-1.0\n",
            "[-0.54738337 -0.00273527]\n",
            "1\n",
            "-1.0\n",
            "[-0.5509404  -0.00355704]\n",
            "0\n",
            "-1.0\n",
            "[-0.5552926 -0.0043522]\n",
            "0\n",
            "-1.0\n",
            "[-0.5584074  -0.00311486]\n",
            "2\n",
            "-1.0\n",
            "[-0.5612617  -0.00285427]\n",
            "1\n",
            "-1.0\n",
            "[-0.56383413 -0.0025724 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.5661055  -0.00227136]\n",
            "1\n",
            "-1.0\n",
            "[-0.5680589  -0.00195343]\n",
            "1\n",
            "-1.0\n",
            "[-0.56967986 -0.00162096]\n",
            "1\n",
            "-1.0\n",
            "[-5.6995630e-01 -2.7645475e-04]\n",
            "2\n",
            "-1.0\n",
            "[-5.698862e-01  7.010714e-05]\n",
            "1\n",
            "-1.0\n",
            "[-0.56847006  0.00141615]\n",
            "2\n",
            "-1.0\n",
            "[-0.5677184   0.00075167]\n",
            "0\n",
            "-1.0\n",
            "[-0.5666368  0.0010816]\n",
            "1\n",
            "-1.0\n",
            "[-5.6623334e-01  4.0348843e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.6651092e-01 -2.7762368e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.56746763 -0.00095667]\n",
            "0\n",
            "-1.0\n",
            "[-0.5690962 -0.0016286]\n",
            "0\n",
            "-1.0\n",
            "[-5.6938463e-01 -2.8843130e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.57033074 -0.00094612]\n",
            "0\n",
            "-1.0\n",
            "[-0.57192755 -0.00159677]\n",
            "0\n",
            "-1.0\n",
            "[-5.7216311e-01 -2.3557623e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.57103574  0.00112737]\n",
            "2\n",
            "-1.0\n",
            "[-0.5685538   0.00248195]\n",
            "2\n",
            "-1.0\n",
            "[-0.5657357   0.00281809]\n",
            "1\n",
            "-1.0\n",
            "[-0.5616024   0.00413327]\n",
            "2\n",
            "-1.0\n",
            "[-0.55618477  0.00541768]\n",
            "2\n",
            "-1.0\n",
            "[-0.54952306  0.00666169]\n",
            "2\n",
            "-1.0\n",
            "[-0.5416671   0.00785593]\n",
            "2\n",
            "-1.0\n",
            "[-0.53367573  0.00799137]\n",
            "1\n",
            "-1.0\n",
            "[-0.5246088   0.00906694]\n",
            "2\n",
            "-1.0\n",
            "[-0.5155343   0.00907451]\n",
            "1\n",
            "-1.0\n",
            "[-0.5065203   0.00901404]\n",
            "1\n",
            "-1.0\n",
            "[-0.49763426  0.008886  ]\n",
            "1\n",
            "-1.0\n",
            "[-0.4899428   0.00769147]\n",
            "0\n",
            "-1.0\n",
            "[-0.4835033   0.00643947]\n",
            "0\n",
            "-1.0\n",
            "In episode 7\n",
            "(array([-0.42819625,  0.        ], dtype=float32), {})\n",
            "2\n",
            "-1.0\n",
            "[-0.42890206 -0.00070579]\n",
            "1\n",
            "-1.0\n",
            "[-0.43030855 -0.0014065 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.43340564 -0.00309708]\n",
            "0\n",
            "-1.0\n",
            "[-0.43717092 -0.0037653 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.4415772  -0.00440627]\n",
            "1\n",
            "-1.0\n",
            "[-0.44759247 -0.00601525]\n",
            "0\n",
            "-1.0\n",
            "[-0.45417282 -0.00658037]\n",
            "1\n",
            "-1.0\n",
            "[-0.46227014 -0.00809731]\n",
            "0\n",
            "-1.0\n",
            "[-0.4718248  -0.00955468]\n",
            "0\n",
            "-1.0\n",
            "[-0.48176622 -0.00994143]\n",
            "1\n",
            "-1.0\n",
            "[-0.49302056 -0.01125435]\n",
            "0\n",
            "-1.0\n",
            "[-0.5035039  -0.01048336]\n",
            "2\n",
            "-1.0\n",
            "[-0.5141379  -0.01063398]\n",
            "1\n",
            "-1.0\n",
            "[-0.52584285 -0.01170493]\n",
            "0\n",
            "-1.0\n",
            "[-0.536531  -0.0106881]\n",
            "2\n",
            "-1.0\n",
            "[-0.5461221  -0.00959113]\n",
            "2\n",
            "-1.0\n",
            "[-0.5565444  -0.01042233]\n",
            "0\n",
            "-1.0\n",
            "[-0.56772006 -0.01117564]\n",
            "0\n",
            "-1.0\n",
            "[-0.5785658 -0.0108457]\n",
            "1\n",
            "-1.0\n",
            "[-0.59000105 -0.01143531]\n",
            "0\n",
            "-1.0\n",
            "[-0.60094166 -0.01094058]\n",
            "1\n",
            "-1.0\n",
            "[-0.6113074 -0.0103657]\n",
            "1\n",
            "-1.0\n",
            "[-0.6220228  -0.01071545]\n",
            "0\n",
            "-1.0\n",
            "[-0.63201076 -0.00998795]\n",
            "1\n",
            "-1.0\n",
            "[-0.6411999  -0.00918912]\n",
            "1\n",
            "-1.0\n",
            "[-0.64952517 -0.0083253 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.65692836 -0.00740315]\n",
            "1\n",
            "-1.0\n",
            "[-0.662358   -0.00542963]\n",
            "2\n",
            "-1.0\n",
            "[-0.6657767  -0.00341874]\n",
            "2\n",
            "-1.0\n",
            "[-0.66916114 -0.00338444]\n",
            "0\n",
            "-1.0\n",
            "[-0.67048824 -0.00132709]\n",
            "2\n",
            "-1.0\n",
            "[-0.671749   -0.00126073]\n",
            "0\n",
            "-1.0\n",
            "[-0.67293483 -0.00118583]\n",
            "0\n",
            "-1.0\n",
            "[-0.6720377  0.0008971]\n",
            "2\n",
            "-1.0\n",
            "[-0.66906375  0.00297396]\n",
            "2\n",
            "-1.0\n",
            "[-0.6640331   0.00503065]\n",
            "2\n",
            "-1.0\n",
            "[-0.6579801   0.00605302]\n",
            "1\n",
            "-1.0\n",
            "[-0.6499463  0.0080338]\n",
            "2\n",
            "-1.0\n",
            "[-0.6399874   0.00995888]\n",
            "2\n",
            "-1.0\n",
            "[-0.6291732   0.01081416]\n",
            "1\n",
            "-1.0\n",
            "[-0.61858046  0.0105928 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.60628486  0.01229556]\n",
            "2\n",
            "-1.0\n",
            "[-0.5943755   0.01190937]\n",
            "0\n",
            "-1.0\n",
            "[-0.58293927  0.01143621]\n",
            "0\n",
            "-1.0\n",
            "[-0.57206035  0.01087892]\n",
            "0\n",
            "-1.0\n",
            "[-0.56181926  0.0102411 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.55029213  0.01152713]\n",
            "2\n",
            "-1.0\n",
            "[-0.53856504  0.01172712]\n",
            "1\n",
            "-1.0\n",
            "[-0.5267257   0.01183932]\n",
            "1\n",
            "-1.0\n",
            "[-0.51586294  0.01086278]\n",
            "0\n",
            "-1.0\n",
            "[-0.50605816  0.00980476]\n",
            "0\n",
            "-1.0\n",
            "[-0.4973849   0.00867327]\n",
            "0\n",
            "-1.0\n",
            "[-0.48790804  0.00947687]\n",
            "2\n",
            "-1.0\n",
            "[-0.47969833  0.0082097 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.47281694  0.0068814 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.46531492  0.007502  ]\n",
            "2\n",
            "-1.0\n",
            "[-0.45824784  0.0070671 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.45166773  0.0065801 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.44462293  0.00704479]\n",
            "2\n",
            "-1.0\n",
            "[-0.43816495  0.006458  ]\n",
            "1\n",
            "-1.0\n",
            "[-0.4313407   0.00682424]\n",
            "2\n",
            "-1.0\n",
            "[-0.4261996   0.00514111]\n",
            "0\n",
            "-1.0\n",
            "[-0.42077863  0.00542096]\n",
            "2\n",
            "-1.0\n",
            "[-0.41711664  0.00366198]\n",
            "0\n",
            "-1.0\n",
            "[-0.41423976  0.00287688]\n",
            "1\n",
            "-1.0\n",
            "[-0.41216844  0.00207132]\n",
            "1\n",
            "-1.0\n",
            "[-4.1191739e-01  2.5107228e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.41248834 -0.00057095]\n",
            "1\n",
            "-1.0\n",
            "[-0.41487727 -0.00238894]\n",
            "0\n",
            "-1.0\n",
            "[-0.41706723 -0.00218997]\n",
            "2\n",
            "-1.0\n",
            "[-0.42004266 -0.00297542]\n",
            "1\n",
            "-1.0\n",
            "[-0.4227823  -0.00273966]\n",
            "2\n",
            "-1.0\n",
            "[-0.42526662 -0.00248431]\n",
            "2\n",
            "-1.0\n",
            "[-0.42947778 -0.00421115]\n",
            "0\n",
            "-1.0\n",
            "[-0.43438548 -0.00490771]\n",
            "1\n",
            "-1.0\n",
            "[-0.43895435 -0.00456885]\n",
            "2\n",
            "-1.0\n",
            "[-0.44415122 -0.00519689]\n",
            "1\n",
            "-1.0\n",
            "[-0.44993836 -0.00578712]\n",
            "1\n",
            "-1.0\n",
            "[-0.45627344 -0.00633509]\n",
            "1\n",
            "-1.0\n",
            "[-0.46311003 -0.0068366 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.4703978  -0.00728778]\n",
            "1\n",
            "-1.0\n",
            "[-0.4780829  -0.00768509]\n",
            "1\n",
            "-1.0\n",
            "[-0.48510832 -0.0070254 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.49142176 -0.00631344]\n",
            "2\n",
            "-1.0\n",
            "[-0.49897614 -0.00755439]\n",
            "0\n",
            "-1.0\n",
            "[-0.50771505 -0.0087389 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.515573   -0.00785798]\n",
            "2\n",
            "-1.0\n",
            "[-0.5244912  -0.00891817]\n",
            "0\n",
            "-1.0\n",
            "[-0.53440267 -0.00991147]\n",
            "0\n",
            "-1.0\n",
            "[-0.54423314 -0.00983046]\n",
            "1\n",
            "-1.0\n",
            "[-0.5529089 -0.0086758]\n",
            "2\n",
            "-1.0\n",
            "[-0.5623652  -0.00945626]\n",
            "0\n",
            "-1.0\n",
            "[-0.5705313  -0.00816616]\n",
            "2\n",
            "-1.0\n",
            "[-0.5773467  -0.00681533]\n",
            "2\n",
            "-1.0\n",
            "[-0.5837606  -0.00641397]\n",
            "1\n",
            "-1.0\n",
            "[-0.5887258 -0.0049652]\n",
            "2\n",
            "-1.0\n",
            "[-0.5932057  -0.00447985]\n",
            "1\n",
            "-1.0\n",
            "[-0.59616727 -0.00296158]\n",
            "2\n",
            "-1.0\n",
            "[-0.5985889  -0.00242161]\n",
            "1\n",
            "-1.0\n",
            "In episode 8\n",
            "(array([-0.5618877,  0.       ], dtype=float32), {})\n",
            "0\n",
            "-1.0\n",
            "[-0.56260115 -0.00071346]\n",
            "0\n",
            "-1.0\n",
            "[-5.6302279e-01 -4.2161337e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5641494  -0.00112662]\n",
            "0\n",
            "-1.0\n",
            "[-5.6397265e-01  1.7675778e-04]\n",
            "2\n",
            "-1.0\n",
            "[-5.6449383e-01 -5.2117812e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.563709    0.00078477]\n",
            "2\n",
            "-1.0\n",
            "[-0.56262416  0.00108487]\n",
            "1\n",
            "-1.0\n",
            "[-0.5612473   0.00137689]\n",
            "1\n",
            "-1.0\n",
            "[-0.5585886   0.00265865]\n",
            "2\n",
            "-1.0\n",
            "[-0.55566806  0.0029206 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.5515073   0.00416074]\n",
            "2\n",
            "-1.0\n",
            "[-0.5481375   0.00336981]\n",
            "0\n",
            "-1.0\n",
            "[-0.5455838   0.00255369]\n",
            "0\n",
            "-1.0\n",
            "[-0.54186535  0.00371846]\n",
            "2\n",
            "-1.0\n",
            "[-0.53800994  0.00385539]\n",
            "1\n",
            "-1.0\n",
            "[-0.53404653  0.00396344]\n",
            "1\n",
            "-1.0\n",
            "[-0.52900475  0.00504178]\n",
            "2\n",
            "-1.0\n",
            "[-0.5239224   0.00508233]\n",
            "1\n",
            "-1.0\n",
            "[-0.5198377   0.00408475]\n",
            "0\n",
            "-1.0\n",
            "[-0.5157811   0.00405654]\n",
            "1\n",
            "-1.0\n",
            "[-0.51278317  0.00299792]\n",
            "0\n",
            "-1.0\n",
            "[-0.50986636  0.00291681]\n",
            "1\n",
            "-1.0\n",
            "[-0.50605255  0.00381385]\n",
            "2\n",
            "-1.0\n",
            "[-0.5033702   0.00268231]\n",
            "0\n",
            "-1.0\n",
            "[-0.5018395   0.00153069]\n",
            "0\n",
            "-1.0\n",
            "[-0.5004719   0.00136762]\n",
            "1\n",
            "-1.0\n",
            "[-0.4992776  0.0011943]\n",
            "1\n",
            "-1.0\n",
            "[-0.49826553  0.00101206]\n",
            "1\n",
            "-1.0\n",
            "[-0.4964433   0.00182224]\n",
            "2\n",
            "-1.0\n",
            "[-0.4938245  0.0026188]\n",
            "2\n",
            "-1.0\n",
            "[-0.49042872  0.00339579]\n",
            "2\n",
            "-1.0\n",
            "[-0.4862813   0.00414742]\n",
            "2\n",
            "-1.0\n",
            "[-0.48241317  0.00386813]\n",
            "1\n",
            "-1.0\n",
            "[-0.47985315  0.00256002]\n",
            "0\n",
            "-1.0\n",
            "[-0.4786203   0.00123287]\n",
            "0\n",
            "-1.0\n",
            "[-0.47772372  0.00089655]\n",
            "1\n",
            "-1.0\n",
            "[-0.47617015  0.00155357]\n",
            "2\n",
            "-1.0\n",
            "[-0.4749711   0.00119906]\n",
            "1\n",
            "-1.0\n",
            "[-0.47313544  0.00183564]\n",
            "2\n",
            "-1.0\n",
            "[-0.47167683  0.00145861]\n",
            "1\n",
            "-1.0\n",
            "[-0.46960607  0.00207077]\n",
            "2\n",
            "-1.0\n",
            "[-0.46693847  0.00266759]\n",
            "2\n",
            "-1.0\n",
            "[-0.46469378  0.00224469]\n",
            "1\n",
            "-1.0\n",
            "[-0.46188858  0.00280519]\n",
            "2\n",
            "-1.0\n",
            "[-0.4595436   0.00234501]\n",
            "1\n",
            "-1.0\n",
            "[-0.45867604  0.00086754]\n",
            "0\n",
            "-1.0\n",
            "[-4.5829234e-01  3.8369623e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.45739532  0.00089703]\n",
            "2\n",
            "-1.0\n",
            "[-0.45799157 -0.00059624]\n",
            "0\n",
            "-1.0\n",
            "[-0.4590767  -0.00108513]\n",
            "1\n",
            "-1.0\n",
            "[-0.4616427  -0.00256603]\n",
            "0\n",
            "-1.0\n",
            "[-0.46467075 -0.00302802]\n",
            "1\n",
            "-1.0\n",
            "[-0.4691384  -0.00446769]\n",
            "0\n",
            "-1.0\n",
            "[-0.47501275 -0.00587432]\n",
            "0\n",
            "-1.0\n",
            "[-0.48225018 -0.00723743]\n",
            "0\n",
            "-1.0\n",
            "[-0.48979694 -0.00754675]\n",
            "1\n",
            "-1.0\n",
            "[-0.49659675 -0.00679983]\n",
            "2\n",
            "-1.0\n",
            "[-0.5045989  -0.00800212]\n",
            "0\n",
            "-1.0\n",
            "[-0.5117434  -0.00714455]\n",
            "2\n",
            "-1.0\n",
            "[-0.51997685 -0.00823344]\n",
            "0\n",
            "-1.0\n",
            "[-0.5292375  -0.00926061]\n",
            "0\n",
            "-1.0\n",
            "[-0.5394558  -0.01021832]\n",
            "0\n",
            "-1.0\n",
            "[-0.54955524 -0.01009944]\n",
            "1\n",
            "-1.0\n",
            "[-0.5584602  -0.00890496]\n",
            "2\n",
            "-1.0\n",
            "[-0.5661042  -0.00764397]\n",
            "2\n",
            "-1.0\n",
            "[-0.5744302  -0.00832605]\n",
            "0\n",
            "-1.0\n",
            "[-0.5813765  -0.00694629]\n",
            "2\n",
            "-1.0\n",
            "[-0.5888916  -0.00751512]\n",
            "0\n",
            "-1.0\n",
            "[-0.59492016 -0.00602855]\n",
            "2\n",
            "-1.0\n",
            "[-0.6014179  -0.00649771]\n",
            "0\n",
            "-1.0\n",
            "[-0.60733724 -0.00591935]\n",
            "1\n",
            "-1.0\n",
            "[-0.61263514 -0.0052979 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.6182732  -0.00563804]\n",
            "0\n",
            "-1.0\n",
            "[-0.6222107  -0.00393749]\n",
            "2\n",
            "-1.0\n",
            "[-0.62441933 -0.00220864]\n",
            "2\n",
            "-1.0\n",
            "[-0.6258833  -0.00146397]\n",
            "1\n",
            "-1.0\n",
            "[-0.6265921  -0.00070881]\n",
            "1\n",
            "-1.0\n",
            "[-6.2654066e-01  5.1403353e-05]\n",
            "1\n",
            "-1.0\n",
            "[-0.62572944  0.00081125]\n",
            "1\n",
            "-1.0\n",
            "[-6.2516415e-01  5.6530524e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.6228488   0.00231531]\n",
            "2\n",
            "-1.0\n",
            "[-0.6188001   0.00404874]\n",
            "2\n",
            "-1.0\n",
            "[-0.614047    0.00475308]\n",
            "1\n",
            "-1.0\n",
            "[-0.6076239   0.00642315]\n",
            "2\n",
            "-1.0\n",
            "[-0.60157716  0.00604668]\n",
            "0\n",
            "-1.0\n",
            "[-0.594951   0.0066262]\n",
            "1\n",
            "-1.0\n",
            "[-0.5867937   0.00815727]\n",
            "2\n",
            "-1.0\n",
            "[-0.5791653   0.00762839]\n",
            "0\n",
            "-1.0\n",
            "[-0.5721221   0.00704322]\n",
            "0\n",
            "-1.0\n",
            "[-0.5647162   0.00740586]\n",
            "1\n",
            "-1.0\n",
            "[-0.5570028   0.00771346]\n",
            "1\n",
            "-1.0\n",
            "[-0.5480392   0.00896357]\n",
            "2\n",
            "-1.0\n",
            "[-0.5388925   0.00914671]\n",
            "1\n",
            "-1.0\n",
            "[-0.52863115  0.01026137]\n",
            "2\n",
            "-1.0\n",
            "[-0.51933205  0.00929911]\n",
            "0\n",
            "-1.0\n",
            "[-0.5110649   0.00826711]\n",
            "0\n",
            "-1.0\n",
            "[-0.50389177  0.00717313]\n",
            "0\n",
            "-1.0\n",
            "[-0.49786636  0.00602541]\n",
            "0\n",
            "-1.0\n",
            "[-0.49303377  0.00483261]\n",
            "0\n",
            "-1.0\n",
            "In episode 9\n",
            "(array([-0.4495628,  0.       ], dtype=float32), {})\n",
            "1\n",
            "-1.0\n",
            "[-0.44911352  0.00044928]\n",
            "2\n",
            "-1.0\n",
            "[-0.45021823 -0.00110472]\n",
            "0\n",
            "-1.0\n",
            "[-0.45286888 -0.00265064]\n",
            "0\n",
            "-1.0\n",
            "[-0.455046   -0.00217714]\n",
            "2\n",
            "-1.0\n",
            "[-0.45873368 -0.00368767]\n",
            "0\n",
            "-1.0\n",
            "[-0.46190476 -0.00317109]\n",
            "2\n",
            "-1.0\n",
            "[-0.46553594 -0.00363116]\n",
            "1\n",
            "-1.0\n",
            "[-0.47060037 -0.00506443]\n",
            "0\n",
            "-1.0\n",
            "[-0.47706062 -0.00646025]\n",
            "0\n",
            "-1.0\n",
            "[-0.48386878 -0.00680815]\n",
            "1\n",
            "-1.0\n",
            "[-0.4899742  -0.00610542]\n",
            "2\n",
            "-1.0\n",
            "[-0.49733138 -0.00735718]\n",
            "0\n",
            "-1.0\n",
            "[-0.50588536 -0.00855398]\n",
            "0\n",
            "-1.0\n",
            "[-0.51557213 -0.00968677]\n",
            "0\n",
            "-1.0\n",
            "[-0.5263191  -0.01074696]\n",
            "0\n",
            "-1.0\n",
            "[-0.53804564 -0.01172656]\n",
            "0\n",
            "-1.0\n",
            "[-0.5496639  -0.01161824]\n",
            "1\n",
            "-1.0\n",
            "[-0.56108683 -0.01142295]\n",
            "1\n",
            "-1.0\n",
            "[-0.5732292  -0.01214239]\n",
            "0\n",
            "-1.0\n",
            "[-0.58400077 -0.01077153]\n",
            "2\n",
            "-1.0\n",
            "[-0.5943217  -0.01032099]\n",
            "1\n",
            "-1.0\n",
            "[-0.6031163  -0.00879454]\n",
            "2\n",
            "-1.0\n",
            "[-0.6103201 -0.0072038]\n",
            "2\n",
            "-1.0\n",
            "[-0.6158808 -0.0055607]\n",
            "2\n",
            "-1.0\n",
            "[-0.6207582  -0.00487739]\n",
            "1\n",
            "-1.0\n",
            "[-0.62391716 -0.00315897]\n",
            "2\n",
            "-1.0\n",
            "[-0.6273351  -0.00341789]\n",
            "0\n",
            "-1.0\n",
            "[-0.6309874  -0.00365237]\n",
            "0\n",
            "-1.0\n",
            "[-0.63384825 -0.00286081]\n",
            "1\n",
            "-1.0\n",
            "[-0.6348972  -0.00104894]\n",
            "2\n",
            "-1.0\n",
            "[-6.3512677e-01 -2.2962177e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.63353544  0.00159132]\n",
            "2\n",
            "-1.0\n",
            "[-0.6311345   0.00240098]\n",
            "1\n",
            "-1.0\n",
            "[-0.6269409   0.00419358]\n",
            "2\n",
            "-1.0\n",
            "[-0.6219846   0.00495629]\n",
            "1\n",
            "-1.0\n",
            "[-0.6163011   0.00568351]\n",
            "1\n",
            "-1.0\n",
            "[-0.60893124  0.00736985]\n",
            "2\n",
            "-1.0\n",
            "[-0.5999284   0.00900288]\n",
            "2\n",
            "-1.0\n",
            "[-0.58935803  0.01057036]\n",
            "2\n",
            "-1.0\n",
            "[-0.5772976   0.01206036]\n",
            "2\n",
            "-1.0\n",
            "[-0.5658363   0.01146137]\n",
            "0\n",
            "-1.0\n",
            "[-0.55505896  0.0107773 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.5450461  0.0100129]\n",
            "0\n",
            "-1.0\n",
            "[-0.53587246  0.00917364]\n",
            "0\n",
            "-1.0\n",
            "[-0.52560675  0.01026568]\n",
            "2\n",
            "-1.0\n",
            "[-0.515326    0.01028074]\n",
            "1\n",
            "-1.0\n",
            "[-0.50610733  0.0092187 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.49601975  0.01008757]\n",
            "2\n",
            "-1.0\n",
            "[-0.4871388   0.00888096]\n",
            "0\n",
            "-1.0\n",
            "[-0.47853073  0.00860806]\n",
            "1\n",
            "-1.0\n",
            "[-0.47025967  0.00827108]\n",
            "1\n",
            "-1.0\n",
            "[-0.4623869   0.00787274]\n",
            "1\n",
            "-1.0\n",
            "[-0.4539707   0.00841623]\n",
            "2\n",
            "-1.0\n",
            "[-0.44607288  0.00789781]\n",
            "1\n",
            "-1.0\n",
            "[-0.4387513   0.00732159]\n",
            "1\n",
            "-1.0\n",
            "[-0.43305922  0.00569208]\n",
            "0\n",
            "-1.0\n",
            "[-0.42903787  0.00402135]\n",
            "0\n",
            "-1.0\n",
            "[-0.42471623  0.00432162]\n",
            "2\n",
            "-1.0\n",
            "[-0.4201254   0.00459083]\n",
            "2\n",
            "-1.0\n",
            "[-0.41729823  0.00282719]\n",
            "0\n",
            "-1.0\n",
            "[-0.41425484  0.00304338]\n",
            "2\n",
            "-1.0\n",
            "[-0.41201693  0.00223792]\n",
            "1\n",
            "-1.0\n",
            "[-0.4106003  0.0014166]\n",
            "1\n",
            "-1.0\n",
            "[-0.41101506 -0.00041475]\n",
            "0\n",
            "-1.0\n",
            "[-0.41325822 -0.00224316]\n",
            "0\n",
            "-1.0\n",
            "[-0.4173139  -0.00405569]\n",
            "0\n",
            "-1.0\n",
            "[-0.4211533  -0.00383938]\n",
            "2\n",
            "-1.0\n",
            "[-0.42574897 -0.00459569]\n",
            "1\n",
            "-1.0\n",
            "[-0.43106803 -0.00531906]\n",
            "1\n",
            "-1.0\n",
            "[-0.4380722  -0.00700417]\n",
            "0\n",
            "-1.0\n",
            "[-0.4457108 -0.0076386]\n",
            "1\n",
            "-1.0\n",
            "[-0.45492828 -0.00921746]\n",
            "0\n",
            "-1.0\n",
            "[-0.46465713 -0.00972885]\n",
            "1\n",
            "-1.0\n",
            "[-0.47382575 -0.00916862]\n",
            "2\n",
            "-1.0\n",
            "[-0.48436627 -0.01054053]\n",
            "0\n",
            "-1.0\n",
            "[-0.49520037 -0.01083409]\n",
            "1\n",
            "-1.0\n",
            "[-0.50624716 -0.01104682]\n",
            "1\n",
            "-1.0\n",
            "[-0.51642406 -0.0101769 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.52765477 -0.01123071]\n",
            "0\n",
            "-1.0\n",
            "[-0.5378551  -0.01020029]\n",
            "2\n",
            "-1.0\n",
            "[-0.54894847 -0.0110934 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.55885196 -0.00990346]\n",
            "2\n",
            "-1.0\n",
            "[-0.56849146 -0.00963955]\n",
            "1\n",
            "-1.0\n",
            "[-0.5777954  -0.00930387]\n",
            "1\n",
            "-1.0\n",
            "[-0.5876945  -0.00989919]\n",
            "0\n",
            "-1.0\n",
            "[-0.598116   -0.01042143]\n",
            "0\n",
            "-1.0\n",
            "[-0.6079832  -0.00986719]\n",
            "1\n",
            "-1.0\n",
            "[-0.6172242  -0.00924105]\n",
            "1\n",
            "-1.0\n",
            "[-0.6267723  -0.00954805]\n",
            "0\n",
            "-1.0\n",
            "[-0.63655883 -0.00978655]\n",
            "0\n",
            "-1.0\n",
            "[-0.6465143  -0.00995547]\n",
            "0\n",
            "-1.0\n",
            "[-0.65556866 -0.00905435]\n",
            "1\n",
            "-1.0\n",
            "[-0.6626589  -0.00709023]\n",
            "2\n",
            "-1.0\n",
            "[-0.66873616 -0.00607727]\n",
            "1\n",
            "-1.0\n",
            "[-0.673759   -0.00502281]\n",
            "1\n",
            "-1.0\n",
            "[-0.67669326 -0.00293432]\n",
            "2\n",
            "-1.0\n",
            "[-0.6785193  -0.00182605]\n",
            "1\n",
            "-1.0\n",
            "[-0.68022484 -0.00170553]\n",
            "0\n",
            "-1.0\n",
            "[-6.797984e-01  4.264156e-04]\n",
            "2\n",
            "-1.0\n",
            "In episode 10\n",
            "(array([-0.58082324,  0.        ], dtype=float32), {})\n",
            "0\n",
            "-1.0\n",
            "[-5.8139616e-01 -5.7292153e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.5825378  -0.00114161]\n",
            "0\n",
            "-1.0\n",
            "[-0.5832396  -0.00070187]\n",
            "1\n",
            "-1.0\n",
            "[-0.58449656 -0.00125694]\n",
            "0\n",
            "-1.0\n",
            "[-0.5852993  -0.00080275]\n",
            "1\n",
            "-1.0\n",
            "[-0.58664197 -0.00134263]\n",
            "0\n",
            "-1.0\n",
            "[-5.8651459e-01  1.2737981e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.58491814  0.00159645]\n",
            "2\n",
            "-1.0\n",
            "[-0.5838644   0.00105376]\n",
            "0\n",
            "-1.0\n",
            "[-5.8336109e-01  5.0329085e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.58241194  0.00094911]\n",
            "1\n",
            "-1.0\n",
            "[-5.8202404e-01  3.8792467e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.5802002   0.00182387]\n",
            "2\n",
            "-1.0\n",
            "[-0.5789538   0.00124635]\n",
            "0\n",
            "-1.0\n",
            "[-0.57629424  0.0026596 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.57324106  0.00305318]\n",
            "1\n",
            "-1.0\n",
            "[-0.56981695  0.00342412]\n",
            "1\n",
            "-1.0\n",
            "[-0.5670473   0.00276965]\n",
            "0\n",
            "-1.0\n",
            "[-0.5649527   0.00209459]\n",
            "0\n",
            "-1.0\n",
            "[-0.56354874  0.00140395]\n",
            "0\n",
            "-1.0\n",
            "[-0.5618459   0.00170285]\n",
            "1\n",
            "-1.0\n",
            "[-0.55985683  0.00198908]\n",
            "1\n",
            "-1.0\n",
            "[-0.5575963   0.00226048]\n",
            "1\n",
            "-1.0\n",
            "[-0.5560813   0.00151502]\n",
            "0\n",
            "-1.0\n",
            "[-0.5543231   0.00175825]\n",
            "1\n",
            "-1.0\n",
            "[-0.5513347   0.00298836]\n",
            "2\n",
            "-1.0\n",
            "[-0.54913855  0.00219614]\n",
            "0\n",
            "-1.0\n",
            "[-0.5467511  0.0023875]\n",
            "1\n",
            "-1.0\n",
            "[-0.54419005  0.002561  ]\n",
            "1\n",
            "-1.0\n",
            "[-0.54247475  0.00171534]\n",
            "0\n",
            "-1.0\n",
            "[-0.54161793  0.00085683]\n",
            "0\n",
            "-1.0\n",
            "[-0.540626    0.00099191]\n",
            "1\n",
            "-1.0\n",
            "[-5.4050642e-01  1.1955774e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.53926015  0.00124631]\n",
            "2\n",
            "-1.0\n",
            "[-0.5378964   0.00136373]\n",
            "1\n",
            "-1.0\n",
            "[-0.5364255   0.00147093]\n",
            "1\n",
            "-1.0\n",
            "[-0.53385836  0.0025671 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.53121436  0.00264404]\n",
            "1\n",
            "-1.0\n",
            "[-0.5285132   0.00270115]\n",
            "1\n",
            "-1.0\n",
            "[-0.52477515  0.00373801]\n",
            "2\n",
            "-1.0\n",
            "[-0.52002835  0.00474683]\n",
            "2\n",
            "-1.0\n",
            "[-0.51530826  0.00472005]\n",
            "1\n",
            "-1.0\n",
            "[-0.5116504   0.00365788]\n",
            "0\n",
            "-1.0\n",
            "[-0.5070821   0.00456829]\n",
            "2\n",
            "-1.0\n",
            "[-0.50163764  0.00544446]\n",
            "2\n",
            "-1.0\n",
            "[-0.4963578   0.00527987]\n",
            "1\n",
            "-1.0\n",
            "[-0.491282    0.00507579]\n",
            "1\n",
            "-1.0\n",
            "[-0.48744822  0.0038338 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.484885   0.0025632]\n",
            "0\n",
            "-1.0\n",
            "[-0.4826115  0.0022735]\n",
            "1\n",
            "-1.0\n",
            "[-0.48064464  0.00196687]\n",
            "1\n",
            "-1.0\n",
            "[-0.47899905  0.0016456 ]\n",
            "1\n",
            "-1.0\n",
            "[-4.7868693e-01  3.1210069e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.47771066  0.00097628]\n",
            "2\n",
            "-1.0\n",
            "[-0.47707745  0.00063321]\n",
            "1\n",
            "-1.0\n",
            "[-0.47579202  0.00128543]\n",
            "2\n",
            "-1.0\n",
            "[-0.47486392  0.0009281 ]\n",
            "1\n",
            "-1.0\n",
            "[-4.7530001e-01 -4.3610643e-04]\n",
            "0\n",
            "-1.0\n",
            "[-4.7509712e-01  2.0291917e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.47425666  0.00084044]\n",
            "2\n",
            "-1.0\n",
            "[-0.47278494  0.00147172]\n",
            "2\n",
            "-1.0\n",
            "[-0.47169286  0.00109209]\n",
            "1\n",
            "-1.0\n",
            "[-0.4699885   0.00170437]\n",
            "2\n",
            "-1.0\n",
            "[-0.46868446  0.00130402]\n",
            "1\n",
            "-1.0\n",
            "[-0.46679044  0.00189403]\n",
            "2\n",
            "-1.0\n",
            "[-0.4653204   0.00147002]\n",
            "1\n",
            "-1.0\n",
            "[-0.46428525  0.00103516]\n",
            "1\n",
            "-1.0\n",
            "[-4.6469259e-01 -4.0734754e-04]\n",
            "0\n",
            "-1.0\n",
            "[-4.6453944e-01  1.5315200e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.46382692  0.00071252]\n",
            "2\n",
            "-1.0\n",
            "[-0.4645603  -0.00073337]\n",
            "0\n",
            "-1.0\n",
            "[-4.6473414e-01 -1.7384680e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.46534717 -0.00061304]\n",
            "1\n",
            "-1.0\n",
            "[-0.46639487 -0.00104771]\n",
            "1\n",
            "-1.0\n",
            "[-0.46786952 -0.00147463]\n",
            "1\n",
            "-1.0\n",
            "[-0.47076017 -0.00289066]\n",
            "0\n",
            "-1.0\n",
            "[-0.47504547 -0.00428529]\n",
            "0\n",
            "-1.0\n",
            "[-0.4806936  -0.00564815]\n",
            "0\n",
            "-1.0\n",
            "[-0.48766267 -0.00696906]\n",
            "0\n",
            "-1.0\n",
            "[-0.49390072 -0.00623805]\n",
            "2\n",
            "-1.0\n",
            "[-0.5003612  -0.00646049]\n",
            "1\n",
            "-1.0\n",
            "[-0.50699586 -0.00663464]\n",
            "1\n",
            "-1.0\n",
            "[-0.512755   -0.00575911]\n",
            "2\n",
            "-1.0\n",
            "[-0.5175954  -0.00484042]\n",
            "2\n",
            "-1.0\n",
            "[-0.52248085 -0.00488544]\n",
            "1\n",
            "-1.0\n",
            "[-0.5283747  -0.00589383]\n",
            "0\n",
            "-1.0\n",
            "[-0.5342327  -0.00585801]\n",
            "1\n",
            "-1.0\n",
            "[-0.53901094 -0.00477827]\n",
            "2\n",
            "-1.0\n",
            "[-0.54367363 -0.00466272]\n",
            "1\n",
            "-1.0\n",
            "[-0.5481859  -0.00451225]\n",
            "1\n",
            "-1.0\n",
            "[-0.5515139  -0.00332801]\n",
            "2\n",
            "-1.0\n",
            "[-0.5546328  -0.00311889]\n",
            "1\n",
            "-1.0\n",
            "[-0.55751926 -0.00288647]\n",
            "1\n",
            "-1.0\n",
            "[-0.5611518  -0.00363251]\n",
            "0\n",
            "-1.0\n",
            "[-0.56450325 -0.00335146]\n",
            "1\n",
            "-1.0\n",
            "[-0.5675487  -0.00304544]\n",
            "1\n",
            "-1.0\n",
            "[-0.57126546 -0.00371677]\n",
            "0\n",
            "-1.0\n",
            "[-0.57562596 -0.00436049]\n",
            "0\n",
            "-1.0\n",
            "[-0.57959783 -0.00397187]\n",
            "1\n",
            "-1.0\n",
            "In episode 11\n",
            "(array([-0.5422039,  0.       ], dtype=float32), {})\n",
            "1\n",
            "-1.0\n",
            "[-0.54106444  0.00113947]\n",
            "2\n",
            "-1.0\n",
            "[-0.539794   0.0012704]\n",
            "1\n",
            "-1.0\n",
            "[-0.5374022   0.00239182]\n",
            "2\n",
            "-1.0\n",
            "[-0.53390694  0.00349531]\n",
            "2\n",
            "-1.0\n",
            "[-0.5293343   0.00457261]\n",
            "2\n",
            "-1.0\n",
            "[-0.5257187   0.00361562]\n",
            "0\n",
            "-1.0\n",
            "[-0.52308714  0.00263152]\n",
            "0\n",
            "-1.0\n",
            "[-0.5194595   0.00362769]\n",
            "2\n",
            "-1.0\n",
            "[-0.51486284  0.00459664]\n",
            "2\n",
            "-1.0\n",
            "[-0.5113317   0.00353113]\n",
            "0\n",
            "-1.0\n",
            "[-0.50889254  0.00243915]\n",
            "0\n",
            "-1.0\n",
            "[-0.50656366  0.00232889]\n",
            "1\n",
            "-1.0\n",
            "[-0.5053625   0.00120118]\n",
            "0\n",
            "-1.0\n",
            "[-0.50429803  0.00106448]\n",
            "1\n",
            "-1.0\n",
            "[-0.5023782  0.0019198]\n",
            "2\n",
            "-1.0\n",
            "[-0.50161743  0.00076075]\n",
            "0\n",
            "-1.0\n",
            "[-5.0202143e-01 -4.0398590e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.50258714 -0.0005657 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.5033103  -0.00072319]\n",
            "1\n",
            "-1.0\n",
            "[-0.50418556 -0.00087526]\n",
            "1\n",
            "-1.0\n",
            "[-5.0420636e-01 -2.0771957e-05]\n",
            "2\n",
            "-1.0\n",
            "[-5.0437248e-01 -1.6613309e-04]\n",
            "1\n",
            "-1.0\n",
            "[-5.0468272e-01 -3.1025033e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5061348  -0.00145204]\n",
            "0\n",
            "-1.0\n",
            "[-0.5087178  -0.00258296]\n",
            "0\n",
            "-1.0\n",
            "[-0.5104123  -0.00169454]\n",
            "2\n",
            "-1.0\n",
            "[-0.5112057  -0.00079341]\n",
            "2\n",
            "-1.0\n",
            "[-0.51309204 -0.00188633]\n",
            "0\n",
            "-1.0\n",
            "[-0.51505715 -0.00196512]\n",
            "1\n",
            "-1.0\n",
            "[-0.51608634 -0.00102918]\n",
            "2\n",
            "-1.0\n",
            "[-5.1617181e-01 -8.5516214e-05]\n",
            "2\n",
            "-1.0\n",
            "[-0.515313    0.00085879]\n",
            "2\n",
            "-1.0\n",
            "[-0.5135164   0.00179665]\n",
            "2\n",
            "-1.0\n",
            "[-0.5127954   0.00072104]\n",
            "0\n",
            "-1.0\n",
            "[-0.5111553   0.00164003]\n",
            "2\n",
            "-1.0\n",
            "[-0.5106086   0.00054673]\n",
            "0\n",
            "-1.0\n",
            "[-0.5111593  -0.00055067]\n",
            "0\n",
            "-1.0\n",
            "[-5.1080322e-01  3.5605175e-04]\n",
            "2\n",
            "-1.0\n",
            "[-5.1054311e-01  2.6010867e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5113809  -0.00083778]\n",
            "0\n",
            "-1.0\n",
            "[-0.51231027 -0.0009294 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.5133243  -0.00101404]\n",
            "1\n",
            "-1.0\n",
            "[-0.51541543 -0.00209109]\n",
            "0\n",
            "-1.0\n",
            "[-0.5185679  -0.00315246]\n",
            "0\n",
            "-1.0\n",
            "[-0.5217581  -0.00319019]\n",
            "1\n",
            "-1.0\n",
            "[-0.5239621 -0.002204 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.52616334 -0.00220127]\n",
            "1\n",
            "-1.0\n",
            "[-0.5283454  -0.00218204]\n",
            "1\n",
            "-1.0\n",
            "[-0.5314918  -0.00314644]\n",
            "0\n",
            "-1.0\n",
            "[-0.53457904 -0.00308725]\n",
            "1\n",
            "-1.0\n",
            "[-0.53758395 -0.00300491]\n",
            "1\n",
            "-1.0\n",
            "[-0.540484   -0.00290005]\n",
            "1\n",
            "-1.0\n",
            "[-0.54425746 -0.00377346]\n",
            "0\n",
            "-1.0\n",
            "[-0.54687613 -0.00261862]\n",
            "2\n",
            "-1.0\n",
            "[-0.5493203  -0.00244419]\n",
            "1\n",
            "-1.0\n",
            "[-0.5515718  -0.00225147]\n",
            "1\n",
            "-1.0\n",
            "[-0.55461365 -0.00304191]\n",
            "0\n",
            "-1.0\n",
            "[-0.5574233  -0.00280964]\n",
            "1\n",
            "-1.0\n",
            "[-0.5609797  -0.00355639]\n",
            "0\n",
            "-1.0\n",
            "[-0.5652563  -0.00427662]\n",
            "0\n",
            "-1.0\n",
            "[-0.5692213 -0.003965 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.5728452 -0.0036239]\n",
            "1\n",
            "-1.0\n",
            "[-0.5761011  -0.00325589]\n",
            "1\n",
            "-1.0\n",
            "[-0.57796484 -0.00186375]\n",
            "2\n",
            "-1.0\n",
            "[-0.57942265 -0.00145781]\n",
            "1\n",
            "-1.0\n",
            "[-0.58046377 -0.00104109]\n",
            "1\n",
            "-1.0\n",
            "[-0.5820804  -0.00161666]\n",
            "0\n",
            "-1.0\n",
            "[-5.8226073e-01 -1.8029822e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.58300334 -0.0007426 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.5843027  -0.00129942]\n",
            "0\n",
            "-1.0\n",
            "[-0.5851494  -0.00084665]\n",
            "1\n",
            "-1.0\n",
            "[-5.8553702e-01 -3.8764332e-04]\n",
            "1\n",
            "-1.0\n",
            "[-5.8546281e-01  7.4225114e-05]\n",
            "1\n",
            "-1.0\n",
            "[-5.8492726e-01  5.3554645e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.58393437  0.00099292]\n",
            "1\n",
            "-1.0\n",
            "[-0.5814914   0.00244297]\n",
            "2\n",
            "-1.0\n",
            "[-0.5786164   0.00287498]\n",
            "1\n",
            "-1.0\n",
            "[-0.5753307   0.00328575]\n",
            "1\n",
            "-1.0\n",
            "[-0.5716585   0.00367218]\n",
            "1\n",
            "-1.0\n",
            "[-0.5676271   0.00403138]\n",
            "1\n",
            "-1.0\n",
            "[-0.56426644  0.00336063]\n",
            "0\n",
            "-1.0\n",
            "[-0.5596016   0.00466488]\n",
            "2\n",
            "-1.0\n",
            "[-0.5546672   0.00493438]\n",
            "1\n",
            "-1.0\n",
            "[-0.54950017  0.00516706]\n",
            "1\n",
            "-1.0\n",
            "[-0.545139    0.00436112]\n",
            "0\n",
            "-1.0\n",
            "[-0.53961647  0.00552256]\n",
            "2\n",
            "-1.0\n",
            "[-0.5349738   0.00464265]\n",
            "0\n",
            "-1.0\n",
            "[-0.5312459   0.00372794]\n",
            "0\n",
            "-1.0\n",
            "[-0.5264606   0.00478529]\n",
            "2\n",
            "-1.0\n",
            "[-0.52165383  0.00480675]\n",
            "1\n",
            "-1.0\n",
            "[-0.5168617   0.00479217]\n",
            "1\n",
            "-1.0\n",
            "[-0.51312     0.00374164]\n",
            "0\n",
            "-1.0\n",
            "[-0.510457    0.00266306]\n",
            "0\n",
            "-1.0\n",
            "[-0.50789243  0.00256453]\n",
            "1\n",
            "-1.0\n",
            "[-0.50644565  0.00144677]\n",
            "0\n",
            "-1.0\n",
            "[-5.0612748e-01  3.1818103e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.50694025 -0.00081279]\n",
            "0\n",
            "-1.0\n",
            "[-0.50787795 -0.00093768]\n",
            "1\n",
            "-1.0\n",
            "[-0.5099335  -0.00205554]\n",
            "0\n",
            "-1.0\n",
            "In episode 12\n",
            "(array([-0.5029107,  0.       ], dtype=float32), {})\n",
            "1\n",
            "-1.0\n",
            "[-5.0306571e-01 -1.5506134e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.50237465  0.00069104]\n",
            "2\n",
            "-1.0\n",
            "[-0.5008427   0.00153196]\n",
            "2\n",
            "-1.0\n",
            "[-0.49848127  0.00236143]\n",
            "2\n",
            "-1.0\n",
            "[-0.49530807  0.00317322]\n",
            "2\n",
            "-1.0\n",
            "[-0.49134675  0.0039613 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.488627    0.00271979]\n",
            "0\n",
            "-1.0\n",
            "[-0.485169    0.00345798]\n",
            "2\n",
            "-1.0\n",
            "[-0.4809986   0.00417039]\n",
            "2\n",
            "-1.0\n",
            "[-0.47714683  0.00385176]\n",
            "1\n",
            "-1.0\n",
            "[-0.47364235  0.0035045 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.47151113  0.00213123]\n",
            "0\n",
            "-1.0\n",
            "[-0.46976897  0.00174216]\n",
            "1\n",
            "-1.0\n",
            "[-4.6942878e-01  3.4018446e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.46849307  0.0009357 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.4669688   0.00152428]\n",
            "2\n",
            "-1.0\n",
            "[-0.4648672  0.0021016]\n",
            "2\n",
            "-1.0\n",
            "[-0.46320382  0.00166339]\n",
            "1\n",
            "-1.0\n",
            "[-0.4609909  0.0022129]\n",
            "2\n",
            "-1.0\n",
            "[-0.45824483  0.0027461 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.45498574  0.00325908]\n",
            "2\n",
            "-1.0\n",
            "[-0.45223764  0.0027481 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.44902068  0.00321697]\n",
            "2\n",
            "-1.0\n",
            "[-0.44735837  0.00166229]\n",
            "0\n",
            "-1.0\n",
            "[-4.472629e-01  9.546301e-05]\n",
            "0\n",
            "-1.0\n",
            "[-0.44873497 -0.00147206]\n",
            "0\n",
            "-1.0\n",
            "[-0.4497638  -0.00102883]\n",
            "2\n",
            "-1.0\n",
            "[-0.45034188 -0.00057808]\n",
            "2\n",
            "-1.0\n",
            "[-0.45146498 -0.00112309]\n",
            "1\n",
            "-1.0\n",
            "[-0.45412487 -0.00265989]\n",
            "0\n",
            "-1.0\n",
            "[-0.45830205 -0.00417717]\n",
            "0\n",
            "-1.0\n",
            "[-0.46396583 -0.00566377]\n",
            "0\n",
            "-1.0\n",
            "[-0.47007447 -0.00610864]\n",
            "1\n",
            "-1.0\n",
            "[-0.4755828  -0.00550835]\n",
            "2\n",
            "-1.0\n",
            "[-0.48145005 -0.00586723]\n",
            "1\n",
            "-1.0\n",
            "[-0.48663253 -0.0051825 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.4930917  -0.00645918]\n",
            "0\n",
            "-1.0\n",
            "[-0.4987794  -0.00568766]\n",
            "2\n",
            "-1.0\n",
            "[-0.50465304 -0.00587363]\n",
            "1\n",
            "-1.0\n",
            "[-0.51066864 -0.00601565]\n",
            "1\n",
            "-1.0\n",
            "[-0.5157813 -0.0051126]\n",
            "2\n",
            "-1.0\n",
            "[-0.5209525  -0.00517123]\n",
            "1\n",
            "-1.0\n",
            "[-0.52614355 -0.00519108]\n",
            "1\n",
            "-1.0\n",
            "[-0.53231555 -0.00617199]\n",
            "0\n",
            "-1.0\n",
            "[-0.53942215 -0.00710662]\n",
            "0\n",
            "-1.0\n",
            "[-0.5474102  -0.00798799]\n",
            "0\n",
            "-1.0\n",
            "[-0.55621976 -0.00880956]\n",
            "0\n",
            "-1.0\n",
            "[-0.563785   -0.00756529]\n",
            "2\n",
            "-1.0\n",
            "[-0.57104963 -0.00726462]\n",
            "1\n",
            "-1.0\n",
            "[-0.5789596  -0.00790994]\n",
            "0\n",
            "-1.0\n",
            "[-0.5874562  -0.00849664]\n",
            "0\n",
            "-1.0\n",
            "[-0.5944769  -0.00702064]\n",
            "2\n",
            "-1.0\n",
            "[-0.5999699  -0.00549305]\n",
            "2\n",
            "-1.0\n",
            "[-0.60589516 -0.00592526]\n",
            "0\n",
            "-1.0\n",
            "[-0.61220944 -0.00631429]\n",
            "0\n",
            "-1.0\n",
            "[-0.61686695 -0.00465751]\n",
            "2\n",
            "-1.0\n",
            "[-0.62183404 -0.00496709]\n",
            "0\n",
            "-1.0\n",
            "[-0.625075   -0.00324094]\n",
            "2\n",
            "-1.0\n",
            "[-0.6275666  -0.00249157]\n",
            "1\n",
            "-1.0\n",
            "[-0.629291  -0.0017244]\n",
            "1\n",
            "-1.0\n",
            "[-6.2923592e-01  5.5079403e-05]\n",
            "2\n",
            "-1.0\n",
            "[-0.62840176  0.00083416]\n",
            "1\n",
            "-1.0\n",
            "[-0.6257944  0.0026073]\n",
            "2\n",
            "-1.0\n",
            "[-0.62343264  0.00236181]\n",
            "0\n",
            "-1.0\n",
            "[-0.6213332   0.00209942]\n",
            "0\n",
            "-1.0\n",
            "[-0.6185112   0.00282198]\n",
            "1\n",
            "-1.0\n",
            "[-0.61498696  0.00352424]\n",
            "1\n",
            "-1.0\n",
            "[-0.6097859  0.0052011]\n",
            "2\n",
            "-1.0\n",
            "[-0.60294557  0.00684032]\n",
            "2\n",
            "-1.0\n",
            "[-0.5965158   0.00642982]\n",
            "0\n",
            "-1.0\n",
            "[-0.5885434   0.00797234]\n",
            "2\n",
            "-1.0\n",
            "[-0.58008707  0.00845635]\n",
            "1\n",
            "-1.0\n",
            "[-0.57220906  0.00787799]\n",
            "0\n",
            "-1.0\n",
            "[-0.56396776  0.00824128]\n",
            "1\n",
            "-1.0\n",
            "[-0.55542445  0.0085433 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.54664284  0.00878163]\n",
            "1\n",
            "-1.0\n",
            "[-0.5376885   0.00895433]\n",
            "1\n",
            "-1.0\n",
            "[-0.52762854  0.01005997]\n",
            "2\n",
            "-1.0\n",
            "[-0.51753837  0.01009019]\n",
            "1\n",
            "-1.0\n",
            "[-0.5064936   0.01104474]\n",
            "2\n",
            "-1.0\n",
            "[-0.4965771   0.00991651]\n",
            "0\n",
            "-1.0\n",
            "[-0.48686305  0.00971407]\n",
            "1\n",
            "-1.0\n",
            "[-0.47842392  0.00843911]\n",
            "0\n",
            "-1.0\n",
            "[-0.4713226   0.00710133]\n",
            "0\n",
            "-1.0\n",
            "[-0.46561173  0.00571087]\n",
            "0\n",
            "-1.0\n",
            "[-0.4603336   0.00527815]\n",
            "1\n",
            "-1.0\n",
            "[-0.45652708  0.00380651]\n",
            "0\n",
            "-1.0\n",
            "[-0.4542202   0.00230686]\n",
            "0\n",
            "-1.0\n",
            "[-0.45242995  0.00179027]\n",
            "1\n",
            "-1.0\n",
            "[-0.4511694   0.00126055]\n",
            "1\n",
            "-1.0\n",
            "[-0.4494478   0.00172159]\n",
            "2\n",
            "-1.0\n",
            "[-4.492778e-01  1.700347e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.44866055  0.00061723]\n",
            "2\n",
            "-1.0\n",
            "[-4.4860062e-01  5.9919788e-05]\n",
            "1\n",
            "-1.0\n",
            "[-0.45009845 -0.00149783]\n",
            "0\n",
            "-1.0\n",
            "[-0.4531431  -0.00304463]\n",
            "0\n",
            "-1.0\n",
            "[-0.45671222 -0.00356912]\n",
            "1\n",
            "-1.0\n",
            "[-0.4607796  -0.00406741]\n",
            "1\n",
            "-1.0\n",
            "[-0.4663154  -0.00553577]\n",
            "0\n",
            "-1.0\n",
            "In episode 13\n",
            "(array([-0.56399655,  0.        ], dtype=float32), {})\n",
            "2\n",
            "-1.0\n",
            "[-0.5626943   0.00130224]\n",
            "2\n",
            "-1.0\n",
            "[-0.56009954  0.00259479]\n",
            "2\n",
            "-1.0\n",
            "[-0.55623156  0.003868  ]\n",
            "2\n",
            "-1.0\n",
            "[-0.5521192   0.00411235]\n",
            "1\n",
            "-1.0\n",
            "[-0.5487932   0.00332599]\n",
            "0\n",
            "-1.0\n",
            "[-0.54427844  0.00451477]\n",
            "2\n",
            "-1.0\n",
            "[-0.53960866  0.00466977]\n",
            "1\n",
            "-1.0\n",
            "[-0.5358189  0.0037898]\n",
            "0\n",
            "-1.0\n",
            "[-0.5319374   0.00388143]\n",
            "1\n",
            "-1.0\n",
            "[-0.5279935   0.00394396]\n",
            "1\n",
            "-1.0\n",
            "[-0.52501655  0.00297692]\n",
            "0\n",
            "-1.0\n",
            "[-0.522029    0.00298755]\n",
            "1\n",
            "-1.0\n",
            "[-0.51805323  0.00397578]\n",
            "2\n",
            "-1.0\n",
            "[-0.514119    0.00393419]\n",
            "1\n",
            "-1.0\n",
            "[-0.50925595  0.0048631 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.5045004   0.00475556]\n",
            "1\n",
            "-1.0\n",
            "[-0.49888796  0.0056124 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.4934607   0.00542724]\n",
            "1\n",
            "-1.0\n",
            "[-0.4892592   0.00420152]\n",
            "0\n",
            "-1.0\n",
            "[-0.4853148   0.00394442]\n",
            "1\n",
            "-1.0\n",
            "[-0.48065686  0.00465792]\n",
            "2\n",
            "-1.0\n",
            "[-0.4763201   0.00433675]\n",
            "1\n",
            "-1.0\n",
            "[-0.47233674  0.00398335]\n",
            "1\n",
            "-1.0\n",
            "[-0.46973637  0.0026004 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.46653816  0.00319818]\n",
            "2\n",
            "-1.0\n",
            "[-0.46476585  0.00177232]\n",
            "0\n",
            "-1.0\n",
            "[-4.6443251e-01  3.3335673e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.46354055  0.00089194]\n",
            "2\n",
            "-1.0\n",
            "[-0.46409664 -0.00055607]\n",
            "0\n",
            "-1.0\n",
            "[-0.4660966  -0.00199997]\n",
            "0\n",
            "-1.0\n",
            "[-0.4675257 -0.0014291]\n",
            "2\n",
            "-1.0\n",
            "[-0.46837336 -0.00084767]\n",
            "2\n",
            "-1.0\n",
            "[-4.6863332e-01 -2.5996356e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.46930367 -0.00067034]\n",
            "1\n",
            "-1.0\n",
            "[-0.4703794  -0.00107575]\n",
            "1\n",
            "-1.0\n",
            "[-0.47285262 -0.00247321]\n",
            "0\n",
            "-1.0\n",
            "[-0.47470495 -0.00185233]\n",
            "2\n",
            "-1.0\n",
            "[-0.47592267 -0.00121772]\n",
            "2\n",
            "-1.0\n",
            "[-0.47849676 -0.00257408]\n",
            "0\n",
            "-1.0\n",
            "[-0.48140806 -0.00291131]\n",
            "1\n",
            "-1.0\n",
            "[-0.48463497 -0.0032269 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.48815343 -0.00351846]\n",
            "1\n",
            "-1.0\n",
            "[-0.4929372 -0.0047838]\n",
            "0\n",
            "-1.0\n",
            "[-0.49795064 -0.00501344]\n",
            "1\n",
            "-1.0\n",
            "[-0.5041563  -0.00620561]\n",
            "0\n",
            "-1.0\n",
            "[-0.5105076  -0.00635134]\n",
            "1\n",
            "-1.0\n",
            "[-0.5159571 -0.0054495]\n",
            "2\n",
            "-1.0\n",
            "[-0.52146393 -0.00550681]\n",
            "1\n",
            "-1.0\n",
            "[-0.52798676 -0.00652282]\n",
            "0\n",
            "-1.0\n",
            "[-0.53347665 -0.00548991]\n",
            "2\n",
            "-1.0\n",
            "[-0.5388925  -0.00541584]\n",
            "1\n",
            "-1.0\n",
            "[-0.5431937  -0.00430118]\n",
            "2\n",
            "-1.0\n",
            "[-0.54834795 -0.0051543 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.5543168  -0.00596885]\n",
            "0\n",
            "-1.0\n",
            "[-0.5610556  -0.00673879]\n",
            "0\n",
            "-1.0\n",
            "[-0.56851405 -0.00745846]\n",
            "0\n",
            "-1.0\n",
            "[-0.5756367  -0.00712261]\n",
            "1\n",
            "-1.0\n",
            "[-0.58337057 -0.00773391]\n",
            "0\n",
            "-1.0\n",
            "[-0.5906586  -0.00728802]\n",
            "1\n",
            "-1.0\n",
            "[-0.5984471  -0.00778846]\n",
            "0\n",
            "-1.0\n",
            "[-0.60467887 -0.0062318 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.6103085  -0.00562968]\n",
            "1\n",
            "-1.0\n",
            "[-0.6162952  -0.00598666]\n",
            "0\n",
            "-1.0\n",
            "[-0.6205956  -0.00430037]\n",
            "2\n",
            "-1.0\n",
            "[-0.62317866 -0.00258311]\n",
            "2\n",
            "-1.0\n",
            "[-0.624026   -0.00084732]\n",
            "2\n",
            "-1.0\n",
            "[-6.2413144e-01 -1.0546280e-04]\n",
            "1\n",
            "-1.0\n",
            "[-6.2449431e-01 -3.6284648e-04]\n",
            "0\n",
            "-1.0\n",
            "[-6.2511194e-01 -6.1763206e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.6239799  0.001132 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.6211064   0.00287353]\n",
            "2\n",
            "-1.0\n",
            "[-0.6175119   0.00359446]\n",
            "1\n",
            "-1.0\n",
            "[-0.61222243  0.00528952]\n",
            "2\n",
            "-1.0\n",
            "[-0.60627604  0.0059464 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.5987159   0.00756014]\n",
            "2\n",
            "-1.0\n",
            "[-0.5895971   0.00911876]\n",
            "2\n",
            "-1.0\n",
            "[-0.57998663  0.00961052]\n",
            "1\n",
            "-1.0\n",
            "[-0.56995517  0.01003142]\n",
            "1\n",
            "-1.0\n",
            "[-0.55857724  0.01137797]\n",
            "2\n",
            "-1.0\n",
            "[-0.5459374   0.01263983]\n",
            "2\n",
            "-1.0\n",
            "[-0.53413016  0.01180724]\n",
            "0\n",
            "-1.0\n",
            "[-0.522244    0.01188621]\n",
            "1\n",
            "-1.0\n",
            "[-0.5103679   0.01187605]\n",
            "1\n",
            "-1.0\n",
            "[-0.49759105  0.01277685]\n",
            "2\n",
            "-1.0\n",
            "[-0.48500907  0.01258199]\n",
            "1\n",
            "-1.0\n",
            "[-0.47171587  0.01329321]\n",
            "2\n",
            "-1.0\n",
            "[-0.4598102   0.01190566]\n",
            "0\n",
            "-1.0\n",
            "[-0.44938004  0.01043016]\n",
            "0\n",
            "-1.0\n",
            "[-0.43950194  0.0098781 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.4312479   0.00825405]\n",
            "0\n",
            "-1.0\n",
            "[-0.42267764  0.00857024]\n",
            "2\n",
            "-1.0\n",
            "[-0.4158528   0.00682485]\n",
            "0\n",
            "-1.0\n",
            "[-0.41082203  0.00503075]\n",
            "0\n",
            "-1.0\n",
            "[-0.40662107  0.00420097]\n",
            "1\n",
            "-1.0\n",
            "[-0.40327954  0.00334153]\n",
            "1\n",
            "-1.0\n",
            "[-0.40082094  0.00245861]\n",
            "1\n",
            "-1.0\n",
            "[-0.40026248  0.00055845]\n",
            "0\n",
            "-1.0\n",
            "[-4.006081e-01 -3.456052e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.40285534 -0.00224725]\n",
            "0\n",
            "-1.0\n",
            "In episode 14\n",
            "(array([-0.4454654,  0.       ], dtype=float32), {})\n",
            "0\n",
            "-1.0\n",
            "[-0.44704604 -0.00158065]\n",
            "0\n",
            "-1.0\n",
            "[-0.4501958  -0.00314976]\n",
            "0\n",
            "-1.0\n",
            "[-0.45489165 -0.00469584]\n",
            "0\n",
            "-1.0\n",
            "[-0.46009916 -0.00520751]\n",
            "1\n",
            "-1.0\n",
            "[-0.46678004 -0.00668088]\n",
            "0\n",
            "-1.0\n",
            "[-0.473885   -0.00710496]\n",
            "1\n",
            "-1.0\n",
            "[-0.48036143 -0.00647643]\n",
            "2\n",
            "-1.0\n",
            "[-0.48816124 -0.0077998 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.4972263  -0.00906508]\n",
            "0\n",
            "-1.0\n",
            "[-0.506489   -0.00926267]\n",
            "1\n",
            "-1.0\n",
            "[-0.51487994 -0.00839094]\n",
            "2\n",
            "-1.0\n",
            "[-0.52333623 -0.00845632]\n",
            "1\n",
            "-1.0\n",
            "[-0.53079456 -0.00745829]\n",
            "2\n",
            "-1.0\n",
            "[-0.5391989  -0.00840433]\n",
            "0\n",
            "-1.0\n",
            "[-0.54748625 -0.00828737]\n",
            "1\n",
            "-1.0\n",
            "[-0.5545946  -0.00710837]\n",
            "2\n",
            "-1.0\n",
            "[-0.5604708  -0.00587623]\n",
            "2\n",
            "-1.0\n",
            "[-0.5650711  -0.00460026]\n",
            "2\n",
            "-1.0\n",
            "[-0.5683611  -0.00329002]\n",
            "2\n",
            "-1.0\n",
            "[-0.5713164  -0.00295531]\n",
            "1\n",
            "-1.0\n",
            "[-0.57491505 -0.00359865]\n",
            "0\n",
            "-1.0\n",
            "[-0.57813036 -0.00321529]\n",
            "1\n",
            "-1.0\n",
            "[-0.58093846 -0.00280813]\n",
            "1\n",
            "-1.0\n",
            "[-0.5843187 -0.0033802]\n",
            "0\n",
            "-1.0\n",
            "[-0.587246   -0.00292731]\n",
            "1\n",
            "-1.0\n",
            "[-0.59069884 -0.00345285]\n",
            "0\n",
            "-1.0\n",
            "[-0.59365183 -0.00295299]\n",
            "1\n",
            "-1.0\n",
            "[-0.5970833  -0.00343146]\n",
            "0\n",
            "-1.0\n",
            "[-0.60096806 -0.00388478]\n",
            "0\n",
            "-1.0\n",
            "[-0.60327774 -0.0023097 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.60599554 -0.00271778]\n",
            "0\n",
            "-1.0\n",
            "[-0.60910165 -0.00310608]\n",
            "0\n",
            "-1.0\n",
            "[-0.61257344 -0.00347182]\n",
            "0\n",
            "-1.0\n",
            "[-0.6163859  -0.00381241]\n",
            "0\n",
            "-1.0\n",
            "[-0.6205113  -0.00412546]\n",
            "0\n",
            "-1.0\n",
            "[-0.62392014 -0.00340881]\n",
            "1\n",
            "-1.0\n",
            "[-0.6255878  -0.00166771]\n",
            "2\n",
            "-1.0\n",
            "[-6.2550247e-01  8.5333530e-05]\n",
            "2\n",
            "-1.0\n",
            "[-0.6246647   0.00083776]\n",
            "1\n",
            "-1.0\n",
            "[-0.6220805  0.0025842]\n",
            "2\n",
            "-1.0\n",
            "[-0.6177684   0.00431211]\n",
            "2\n",
            "-1.0\n",
            "[-0.6117594   0.00600903]\n",
            "2\n",
            "-1.0\n",
            "[-0.60609686  0.00566255]\n",
            "0\n",
            "-1.0\n",
            "[-0.60082185  0.00527499]\n",
            "0\n",
            "-1.0\n",
            "[-0.5959729   0.00484899]\n",
            "0\n",
            "-1.0\n",
            "[-0.5895853   0.00638754]\n",
            "2\n",
            "-1.0\n",
            "[-0.5837061   0.00587922]\n",
            "0\n",
            "-1.0\n",
            "[-0.5763785   0.00732758]\n",
            "2\n",
            "-1.0\n",
            "[-0.56765676  0.00872178]\n",
            "2\n",
            "-1.0\n",
            "[-0.5586055   0.00905125]\n",
            "1\n",
            "-1.0\n",
            "[-0.54929215  0.00931332]\n",
            "1\n",
            "-1.0\n",
            "[-0.53978634  0.00950583]\n",
            "1\n",
            "-1.0\n",
            "[-0.5301592   0.00962719]\n",
            "1\n",
            "-1.0\n",
            "[-0.51948273  0.01067639]\n",
            "2\n",
            "-1.0\n",
            "[-0.5098372   0.00964552]\n",
            "0\n",
            "-1.0\n",
            "[-0.4992949   0.01054234]\n",
            "2\n",
            "-1.0\n",
            "[-0.4889347   0.01036022]\n",
            "1\n",
            "-1.0\n",
            "[-0.47983396  0.00910071]\n",
            "0\n",
            "-1.0\n",
            "[-0.47206056  0.00777341]\n",
            "0\n",
            "-1.0\n",
            "[-0.46567214  0.00638842]\n",
            "0\n",
            "-1.0\n",
            "[-0.460716    0.00495615]\n",
            "0\n",
            "-1.0\n",
            "[-0.4552287   0.00548732]\n",
            "2\n",
            "-1.0\n",
            "[-0.45125055  0.00397813]\n",
            "0\n",
            "-1.0\n",
            "[-0.44781077  0.00343977]\n",
            "1\n",
            "-1.0\n",
            "[-0.44393453  0.00387625]\n",
            "2\n",
            "-1.0\n",
            "[-0.4396501   0.00428444]\n",
            "2\n",
            "-1.0\n",
            "[-0.43498865  0.00466145]\n",
            "2\n",
            "-1.0\n",
            "[-0.42998394  0.00500468]\n",
            "2\n",
            "-1.0\n",
            "[-0.4266722   0.00331176]\n",
            "0\n",
            "-1.0\n",
            "[-0.42407718  0.00259501]\n",
            "1\n",
            "-1.0\n",
            "[-0.42121753  0.00285964]\n",
            "2\n",
            "-1.0\n",
            "[-0.42011374  0.0011038 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.42077368 -0.00065993]\n",
            "0\n",
            "-1.0\n",
            "[-4.2119262e-01 -4.1894839e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.4233676  -0.00217497]\n",
            "0\n",
            "-1.0\n",
            "[-0.42728302 -0.00391543]\n",
            "0\n",
            "-1.0\n",
            "[-0.4309108  -0.00362778]\n",
            "2\n",
            "-1.0\n",
            "[-0.43622482 -0.00531402]\n",
            "0\n",
            "-1.0\n",
            "[-0.44118667 -0.00496185]\n",
            "2\n",
            "-1.0\n",
            "[-0.44576034 -0.00457366]\n",
            "2\n",
            "-1.0\n",
            "[-0.4499125  -0.00415216]\n",
            "2\n",
            "-1.0\n",
            "[-0.4536128  -0.00370031]\n",
            "2\n",
            "-1.0\n",
            "[-0.45783415 -0.00422136]\n",
            "1\n",
            "-1.0\n",
            "[-0.46254557 -0.0047114 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.46671233 -0.00416675]\n",
            "2\n",
            "-1.0\n",
            "[-0.47130364 -0.00459133]\n",
            "1\n",
            "-1.0\n",
            "[-0.47628558 -0.00498193]\n",
            "1\n",
            "-1.0\n",
            "[-0.48062116 -0.00433559]\n",
            "2\n",
            "-1.0\n",
            "[-0.4842782  -0.00365703]\n",
            "2\n",
            "-1.0\n",
            "[-0.48722944 -0.00295125]\n",
            "2\n",
            "-1.0\n",
            "[-0.48945293 -0.00222348]\n",
            "2\n",
            "-1.0\n",
            "[-0.49293205 -0.00347913]\n",
            "0\n",
            "-1.0\n",
            "[-0.49564084 -0.0027088 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.4995591  -0.00391824]\n",
            "0\n",
            "-1.0\n",
            "[-0.5026575  -0.00309838]\n",
            "2\n",
            "-1.0\n",
            "[-0.5049128  -0.00225534]\n",
            "2\n",
            "-1.0\n",
            "[-0.50730824 -0.00239541]\n",
            "1\n",
            "-1.0\n",
            "[-0.5088258  -0.00151754]\n",
            "2\n",
            "-1.0\n",
            "[-0.51045406 -0.0016283 ]\n",
            "1\n",
            "-1.0\n",
            "In episode 15\n",
            "(array([-0.5373097,  0.       ], dtype=float32), {})\n",
            "0\n",
            "-1.0\n",
            "[-0.5382069 -0.0008972]\n",
            "0\n",
            "-1.0\n",
            "[-0.53899455 -0.00078767]\n",
            "1\n",
            "-1.0\n",
            "[-0.53966683 -0.00067224]\n",
            "1\n",
            "-1.0\n",
            "[-0.5402186  -0.00055178]\n",
            "1\n",
            "-1.0\n",
            "[-0.5396458   0.00057282]\n",
            "2\n",
            "-1.0\n",
            "[-5.3995264e-01 -3.0687696e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.5411369  -0.00118427]\n",
            "0\n",
            "-1.0\n",
            "[-0.5431897 -0.0020528]\n",
            "0\n",
            "-1.0\n",
            "[-0.5440957  -0.00090595]\n",
            "2\n",
            "-1.0\n",
            "[-0.545848   -0.00175232]\n",
            "0\n",
            "-1.0\n",
            "[-0.54643357 -0.00058557]\n",
            "2\n",
            "-1.0\n",
            "[-0.547848   -0.00141445]\n",
            "0\n",
            "-1.0\n",
            "[-0.5490807  -0.00123274]\n",
            "1\n",
            "-1.0\n",
            "[-0.55112255 -0.00204181]\n",
            "0\n",
            "-1.0\n",
            "[-0.5529582  -0.00183562]\n",
            "1\n",
            "-1.0\n",
            "[-0.5535739 -0.0006157]\n",
            "2\n",
            "-1.0\n",
            "[-5.539651e-01 -3.911939e-04]\n",
            "1\n",
            "-1.0\n",
            "[-5.5412883e-01 -1.6376152e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.55506396 -0.00093511]\n",
            "0\n",
            "-1.0\n",
            "[-0.5567634  -0.00169947]\n",
            "0\n",
            "-1.0\n",
            "[-0.55821455 -0.00145114]\n",
            "1\n",
            "-1.0\n",
            "[-5.5840653e-01 -1.9199106e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.55733794  0.00106859]\n",
            "2\n",
            "-1.0\n",
            "[-0.55601674  0.00132121]\n",
            "1\n",
            "-1.0\n",
            "[-0.55545276  0.00056396]\n",
            "0\n",
            "-1.0\n",
            "[-0.5546503  0.0008025]\n",
            "1\n",
            "-1.0\n",
            "[-0.5526152   0.00203505]\n",
            "2\n",
            "-1.0\n",
            "[-0.5513629  0.0012524]\n",
            "0\n",
            "-1.0\n",
            "[-0.54990244  0.00146039]\n",
            "1\n",
            "-1.0\n",
            "[-0.549245    0.00065746]\n",
            "0\n",
            "-1.0\n",
            "[-0.5483954   0.00084962]\n",
            "1\n",
            "-1.0\n",
            "[-0.54635996  0.00203542]\n",
            "2\n",
            "-1.0\n",
            "[-0.54315394  0.003206  ]\n",
            "2\n",
            "-1.0\n",
            "[-0.5388014   0.00435258]\n",
            "2\n",
            "-1.0\n",
            "[-0.5353348   0.00346656]\n",
            "0\n",
            "-1.0\n",
            "[-0.5327803   0.00255456]\n",
            "0\n",
            "-1.0\n",
            "[-0.52915686  0.00362341]\n",
            "2\n",
            "-1.0\n",
            "[-0.52649176  0.00266509]\n",
            "0\n",
            "-1.0\n",
            "[-0.522805    0.00368679]\n",
            "2\n",
            "-1.0\n",
            "[-0.51912415  0.00368084]\n",
            "1\n",
            "-1.0\n",
            "[-0.51447684  0.00464728]\n",
            "2\n",
            "-1.0\n",
            "[-0.508898    0.00557887]\n",
            "2\n",
            "-1.0\n",
            "[-0.50442934  0.00446865]\n",
            "0\n",
            "-1.0\n",
            "[-0.50010437  0.00432496]\n",
            "1\n",
            "-1.0\n",
            "[-0.49595547  0.0041489 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.49201366  0.00394181]\n",
            "1\n",
            "-1.0\n",
            "[-0.48730838  0.00470528]\n",
            "2\n",
            "-1.0\n",
            "[-0.48287475  0.00443364]\n",
            "1\n",
            "-1.0\n",
            "[-0.47974578  0.00312897]\n",
            "0\n",
            "-1.0\n",
            "[-0.47794476  0.00180102]\n",
            "0\n",
            "-1.0\n",
            "[-4.7748509e-01  4.5968193e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.47837016 -0.00088507]\n",
            "0\n",
            "-1.0\n",
            "[-0.48059338 -0.00222324]\n",
            "0\n",
            "-1.0\n",
            "[-0.4831383  -0.00254489]\n",
            "1\n",
            "-1.0\n",
            "[-0.48598588 -0.0028476 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.48911497 -0.0031291 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.49350223 -0.00438726]\n",
            "0\n",
            "-1.0\n",
            "[-0.4981149  -0.00461268]\n",
            "1\n",
            "-1.0\n",
            "[-0.5039185  -0.00580363]\n",
            "0\n",
            "-1.0\n",
            "[-0.5088697  -0.00495114]\n",
            "2\n",
            "-1.0\n",
            "[-0.51493126 -0.00606157]\n",
            "0\n",
            "-1.0\n",
            "[-0.52005786 -0.00512657]\n",
            "2\n",
            "-1.0\n",
            "[-0.52621096 -0.00615313]\n",
            "0\n",
            "-1.0\n",
            "[-0.5323445  -0.00613354]\n",
            "1\n",
            "-1.0\n",
            "[-0.53941244 -0.00706795]\n",
            "0\n",
            "-1.0\n",
            "[-0.5453619  -0.00594939]\n",
            "2\n",
            "-1.0\n",
            "[-0.55214816 -0.00678629]\n",
            "0\n",
            "-1.0\n",
            "[-0.5597206  -0.00757243]\n",
            "0\n",
            "-1.0\n",
            "[-0.5680226  -0.00830205]\n",
            "0\n",
            "-1.0\n",
            "[-0.5749925  -0.00696985]\n",
            "2\n",
            "-1.0\n",
            "[-0.5805784  -0.00558592]\n",
            "2\n",
            "-1.0\n",
            "[-0.58673906 -0.00616066]\n",
            "0\n",
            "-1.0\n",
            "[-0.592429   -0.00568993]\n",
            "1\n",
            "-1.0\n",
            "[-0.59860635 -0.00617736]\n",
            "0\n",
            "-1.0\n",
            "[-0.6032259  -0.00461954]\n",
            "2\n",
            "-1.0\n",
            "[-0.6082539 -0.005028 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.6136538  -0.00539989]\n",
            "0\n",
            "-1.0\n",
            "[-0.61738646 -0.00373267]\n",
            "2\n",
            "-1.0\n",
            "[-0.61942494 -0.0020385 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.6207546  -0.00132967]\n",
            "1\n",
            "-1.0\n",
            "[-0.6223659  -0.00161127]\n",
            "0\n",
            "-1.0\n",
            "[-0.6242472  -0.00188131]\n",
            "0\n",
            "-1.0\n",
            "[-6.2438506e-01 -1.3786413e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.6227785   0.00160657]\n",
            "2\n",
            "-1.0\n",
            "[-0.621439    0.00133949]\n",
            "0\n",
            "-1.0\n",
            "[-0.6183762  0.0030628]\n",
            "2\n",
            "-1.0\n",
            "[-0.6146121   0.00376409]\n",
            "1\n",
            "-1.0\n",
            "[-0.6091739   0.00543824]\n",
            "2\n",
            "-1.0\n",
            "[-0.6041008   0.00507303]\n",
            "0\n",
            "-1.0\n",
            "[-0.5994299   0.00467094]\n",
            "0\n",
            "-1.0\n",
            "[-0.5941951   0.00523478]\n",
            "1\n",
            "-1.0\n",
            "[-0.5894348  0.0047603]\n",
            "0\n",
            "-1.0\n",
            "[-0.5851839   0.00425087]\n",
            "0\n",
            "-1.0\n",
            "[-0.5814738   0.00371014]\n",
            "0\n",
            "-1.0\n",
            "[-0.57833177  0.00314202]\n",
            "0\n",
            "-1.0\n",
            "[-0.5747811   0.00355068]\n",
            "1\n",
            "-1.0\n",
            "[-0.56984806  0.00493304]\n",
            "2\n",
            "-1.0\n",
            "[-0.5655693  0.0042788]\n",
            "0\n",
            "-1.0\n",
            "[-0.56197655  0.00359274]\n",
            "0\n",
            "-1.0\n",
            "In episode 16\n",
            "(array([-0.4862542,  0.       ], dtype=float32), {})\n",
            "0\n",
            "-1.0\n",
            "[-0.48553368  0.0007205 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.48609805 -0.00056437]\n",
            "0\n",
            "-1.0\n",
            "[-4.8594311e-01  1.5497082e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.48506993  0.00087315]\n",
            "2\n",
            "-1.0\n",
            "[-0.48448512  0.00058483]\n",
            "1\n",
            "-1.0\n",
            "[-0.48319295  0.00129215]\n",
            "2\n",
            "-1.0\n",
            "[-4.8320311e-01 -1.0151524e-05]\n",
            "0\n",
            "-1.0\n",
            "[-0.48251548  0.00068762]\n",
            "2\n",
            "-1.0\n",
            "[-0.48113522  0.00138028]\n",
            "2\n",
            "-1.0\n",
            "[-4.8107255e-01  6.2660860e-05]\n",
            "0\n",
            "-1.0\n",
            "[-0.48232797 -0.00125542]\n",
            "0\n",
            "-1.0\n",
            "[-0.48389214 -0.00156416]\n",
            "1\n",
            "-1.0\n",
            "[-0.4847534  -0.00086126]\n",
            "2\n",
            "-1.0\n",
            "[-0.48590532 -0.00115194]\n",
            "1\n",
            "-1.0\n",
            "[-0.48833936 -0.00243404]\n",
            "0\n",
            "-1.0\n",
            "[-0.49203736 -0.00369799]\n",
            "0\n",
            "-1.0\n",
            "[-0.4969717  -0.00493435]\n",
            "0\n",
            "-1.0\n",
            "[-0.5031055  -0.00613384]\n",
            "0\n",
            "-1.0\n",
            "[-0.51039296 -0.00728744]\n",
            "0\n",
            "-1.0\n",
            "[-0.5167794  -0.00638646]\n",
            "2\n",
            "-1.0\n",
            "[-0.523217  -0.0064376]\n",
            "1\n",
            "-1.0\n",
            "[-0.5286575  -0.00544046]\n",
            "2\n",
            "-1.0\n",
            "[-0.53406006 -0.00540252]\n",
            "1\n",
            "-1.0\n",
            "[-0.53838414 -0.00432408]\n",
            "2\n",
            "-1.0\n",
            "[-0.54259735 -0.00421322]\n",
            "1\n",
            "-1.0\n",
            "[-0.54766816 -0.00507081]\n",
            "0\n",
            "-1.0\n",
            "[-0.5525586  -0.00489045]\n",
            "1\n",
            "-1.0\n",
            "[-0.5562321  -0.00367352]\n",
            "2\n",
            "-1.0\n",
            "[-0.56066126 -0.00442916]\n",
            "0\n",
            "-1.0\n",
            "[-0.56381303 -0.00315177]\n",
            "2\n",
            "-1.0\n",
            "[-0.5666639  -0.00285089]\n",
            "1\n",
            "-1.0\n",
            "[-0.57019275 -0.0035288 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.5733732  -0.00318048]\n",
            "1\n",
            "-1.0\n",
            "[-0.57718176 -0.00380856]\n",
            "0\n",
            "-1.0\n",
            "[-0.5805902  -0.00340842]\n",
            "1\n",
            "-1.0\n",
            "[-0.58257324 -0.00198306]\n",
            "2\n",
            "-1.0\n",
            "[-0.5851163  -0.00254305]\n",
            "0\n",
            "-1.0\n",
            "[-0.5862006  -0.00108429]\n",
            "2\n",
            "-1.0\n",
            "[-0.58781815 -0.00161753]\n",
            "0\n",
            "-1.0\n",
            "[-0.589957   -0.00213886]\n",
            "0\n",
            "-1.0\n",
            "[-0.5926014  -0.00264445]\n",
            "0\n",
            "-1.0\n",
            "[-0.59473205 -0.00213062]\n",
            "1\n",
            "-1.0\n",
            "[-0.5953332  -0.00060116]\n",
            "2\n",
            "-1.0\n",
            "[-0.5964005 -0.0010673]\n",
            "0\n",
            "-1.0\n",
            "[-5.9692615e-01 -5.2561332e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5959062   0.00101992]\n",
            "2\n",
            "-1.0\n",
            "[-5.9534824e-01  5.5797969e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.5942563   0.00109195]\n",
            "1\n",
            "-1.0\n",
            "[-0.5926384   0.00161793]\n",
            "1\n",
            "-1.0\n",
            "[-0.5905063   0.00213203]\n",
            "1\n",
            "-1.0\n",
            "[-0.58887583  0.00163047]\n",
            "0\n",
            "-1.0\n",
            "[-0.5867589   0.00211693]\n",
            "1\n",
            "-1.0\n",
            "[-0.5851711  0.0015878]\n",
            "0\n",
            "-1.0\n",
            "[-0.58412415  0.00104697]\n",
            "0\n",
            "-1.0\n",
            "[-0.58162576  0.00249842]\n",
            "2\n",
            "-1.0\n",
            "[-0.5786943   0.00293143]\n",
            "1\n",
            "-1.0\n",
            "[-0.57435155  0.00434277]\n",
            "2\n",
            "-1.0\n",
            "[-0.5686296   0.00572194]\n",
            "2\n",
            "-1.0\n",
            "[-0.563571    0.00505865]\n",
            "0\n",
            "-1.0\n",
            "[-0.55721325  0.00635772]\n",
            "2\n",
            "-1.0\n",
            "[-0.55160385  0.0056094 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.5447846   0.00681919]\n",
            "2\n",
            "-1.0\n",
            "[-0.53780663  0.00697798]\n",
            "1\n",
            "-1.0\n",
            "[-0.5317221   0.00608451]\n",
            "0\n",
            "-1.0\n",
            "[-0.5255767   0.00614543]\n",
            "1\n",
            "-1.0\n",
            "[-0.51941645  0.00616026]\n",
            "1\n",
            "-1.0\n",
            "[-0.51328754  0.00612889]\n",
            "1\n",
            "-1.0\n",
            "[-0.508236    0.00505157]\n",
            "0\n",
            "-1.0\n",
            "[-0.5022996   0.00593639]\n",
            "2\n",
            "-1.0\n",
            "[-0.49552286  0.00677676]\n",
            "2\n",
            "-1.0\n",
            "[-0.4879564   0.00756644]\n",
            "2\n",
            "-1.0\n",
            "[-0.4796568   0.00829963]\n",
            "2\n",
            "-1.0\n",
            "[-0.47268578  0.00697102]\n",
            "0\n",
            "-1.0\n",
            "[-0.4670951   0.00559065]\n",
            "0\n",
            "-1.0\n",
            "[-0.46192622  0.0051689 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.45721722  0.00470899]\n",
            "1\n",
            "-1.0\n",
            "[-0.4530028   0.00421441]\n",
            "1\n",
            "-1.0\n",
            "[-0.4493139   0.00368889]\n",
            "1\n",
            "-1.0\n",
            "[-0.44617757  0.00313636]\n",
            "1\n",
            "-1.0\n",
            "[-0.44261667  0.0035609 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.44065717  0.0019595 ]\n",
            "0\n",
            "-1.0\n",
            "[-4.4031334e-01  3.4383289e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.43958765  0.00072567]\n",
            "2\n",
            "-1.0\n",
            "[-0.44048542 -0.00089776]\n",
            "0\n",
            "-1.0\n",
            "[-0.4420001  -0.00151467]\n",
            "1\n",
            "-1.0\n",
            "[-0.44312066 -0.00112057]\n",
            "2\n",
            "-1.0\n",
            "[-0.445839   -0.00271831]\n",
            "0\n",
            "-1.0\n",
            "[-0.4501352  -0.00429623]\n",
            "0\n",
            "-1.0\n",
            "[-0.45397797 -0.00384276]\n",
            "2\n",
            "-1.0\n",
            "[-0.4583391  -0.00436113]\n",
            "1\n",
            "-1.0\n",
            "[-0.46418655 -0.00584745]\n",
            "0\n",
            "-1.0\n",
            "[-0.46947724 -0.00529069]\n",
            "2\n",
            "-1.0\n",
            "[-0.47517207 -0.00569482]\n",
            "1\n",
            "-1.0\n",
            "[-0.48222882 -0.00705675]\n",
            "0\n",
            "-1.0\n",
            "[-0.48959503 -0.00736622]\n",
            "1\n",
            "-1.0\n",
            "[-0.49821585 -0.00862081]\n",
            "0\n",
            "-1.0\n",
            "[-0.50602686 -0.007811  ]\n",
            "2\n",
            "-1.0\n",
            "[-0.51396954 -0.00794273]\n",
            "1\n",
            "-1.0\n",
            "[-0.5229845  -0.00901494]\n",
            "0\n",
            "-1.0\n",
            "In episode 17\n",
            "(array([-0.44814014,  0.        ], dtype=float32), {})\n",
            "2\n",
            "-1.0\n",
            "[-0.44870126 -0.00056112]\n",
            "1\n",
            "-1.0\n",
            "[-0.4508194  -0.00211814]\n",
            "0\n",
            "-1.0\n",
            "[-0.45247903 -0.00165965]\n",
            "2\n",
            "-1.0\n",
            "[-0.45566806 -0.00318901]\n",
            "0\n",
            "-1.0\n",
            "[-0.46036303 -0.00469498]\n",
            "0\n",
            "-1.0\n",
            "[-0.46652943 -0.0061664 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.47212178 -0.00559234]\n",
            "2\n",
            "-1.0\n",
            "[-0.47809866 -0.00597688]\n",
            "1\n",
            "-1.0\n",
            "[-0.48441574 -0.00631707]\n",
            "1\n",
            "-1.0\n",
            "[-0.492026   -0.00761027]\n",
            "0\n",
            "-1.0\n",
            "[-0.50087273 -0.00884671]\n",
            "0\n",
            "-1.0\n",
            "[-0.50888973 -0.00801702]\n",
            "2\n",
            "-1.0\n",
            "[-0.51701707 -0.00812731]\n",
            "1\n",
            "-1.0\n",
            "[-0.5261937  -0.00917667]\n",
            "0\n",
            "-1.0\n",
            "[-0.53435093 -0.0081572 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.54342747 -0.00907658]\n",
            "0\n",
            "-1.0\n",
            "[-0.55235547 -0.00892795]\n",
            "1\n",
            "-1.0\n",
            "[-0.561068   -0.00871254]\n",
            "1\n",
            "-1.0\n",
            "[-0.5695001  -0.00843211]\n",
            "1\n",
            "-1.0\n",
            "[-0.578589   -0.00908894]\n",
            "0\n",
            "-1.0\n",
            "[-0.5872674  -0.00867838]\n",
            "1\n",
            "-1.0\n",
            "[-0.5944712  -0.00720377]\n",
            "2\n",
            "-1.0\n",
            "[-0.6011474  -0.00667622]\n",
            "1\n",
            "-1.0\n",
            "[-0.60724723 -0.00609984]\n",
            "1\n",
            "-1.0\n",
            "[-0.61372626 -0.00647904]\n",
            "0\n",
            "-1.0\n",
            "[-0.6205376  -0.00681129]\n",
            "0\n",
            "-1.0\n",
            "[-0.625632   -0.00509445]\n",
            "2\n",
            "-1.0\n",
            "[-0.6309731 -0.0053411]\n",
            "0\n",
            "-1.0\n",
            "[-0.63652277 -0.00554964]\n",
            "0\n",
            "-1.0\n",
            "[-0.64124155 -0.00471882]\n",
            "1\n",
            "-1.0\n",
            "[-0.6460963 -0.0048547]\n",
            "0\n",
            "-1.0\n",
            "[-0.6500528  -0.00395651]\n",
            "1\n",
            "-1.0\n",
            "[-0.65208346 -0.00203069]\n",
            "2\n",
            "-1.0\n",
            "[-6.5217423e-01 -9.0741443e-05]\n",
            "2\n",
            "-1.0\n",
            "[-0.6513244   0.00084984]\n",
            "1\n",
            "-1.0\n",
            "[-0.6485399   0.00278451]\n",
            "2\n",
            "-1.0\n",
            "[-0.6458401   0.00269978]\n",
            "0\n",
            "-1.0\n",
            "[-0.6422439   0.00359618]\n",
            "1\n",
            "-1.0\n",
            "[-0.63777655  0.00446735]\n",
            "1\n",
            "-1.0\n",
            "[-0.63246953  0.00530703]\n",
            "1\n",
            "-1.0\n",
            "[-0.6263604   0.00610912]\n",
            "1\n",
            "-1.0\n",
            "[-0.6194927   0.00686769]\n",
            "1\n",
            "-1.0\n",
            "[-0.6129157   0.00657701]\n",
            "0\n",
            "-1.0\n",
            "[-0.60567683  0.0072389 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.59882855  0.00684828]\n",
            "0\n",
            "-1.0\n",
            "[-0.59142077  0.00740773]\n",
            "1\n",
            "-1.0\n",
            "[-0.5835079   0.00791289]\n",
            "1\n",
            "-1.0\n",
            "[-0.5751481  0.0083598]\n",
            "1\n",
            "-1.0\n",
            "[-0.5664032   0.00874488]\n",
            "1\n",
            "-1.0\n",
            "[-0.5563382   0.01006503]\n",
            "2\n",
            "-1.0\n",
            "[-0.547028    0.00931018]\n",
            "0\n",
            "-1.0\n",
            "[-0.53654224  0.01048575]\n",
            "2\n",
            "-1.0\n",
            "[-0.52495944  0.01158281]\n",
            "2\n",
            "-1.0\n",
            "[-0.5123665   0.01259301]\n",
            "2\n",
            "-1.0\n",
            "[-0.49985766  0.01250879]\n",
            "1\n",
            "-1.0\n",
            "[-0.48752677  0.01233088]\n",
            "1\n",
            "-1.0\n",
            "[-0.47446594  0.01306086]\n",
            "2\n",
            "-1.0\n",
            "[-0.46077222  0.0136937 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.44854695  0.01222529]\n",
            "0\n",
            "-1.0\n",
            "[-0.4358798   0.01266714]\n",
            "2\n",
            "-1.0\n",
            "[-0.42486298  0.01101682]\n",
            "0\n",
            "-1.0\n",
            "[-0.4145759   0.01028708]\n",
            "1\n",
            "-1.0\n",
            "[-0.40509197  0.00948391]\n",
            "1\n",
            "-1.0\n",
            "[-0.39547828  0.00961371]\n",
            "2\n",
            "-1.0\n",
            "[-0.386802    0.00867629]\n",
            "1\n",
            "-1.0\n",
            "[-0.3781231   0.00867888]\n",
            "2\n",
            "-1.0\n",
            "[-0.37050098  0.00762212]\n",
            "1\n",
            "-1.0\n",
            "[-0.36498716  0.00551383]\n",
            "0\n",
            "-1.0\n",
            "[-0.36061853  0.00436863]\n",
            "1\n",
            "-1.0\n",
            "[-0.35842413  0.0021944 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.35641846  0.00200567]\n",
            "2\n",
            "-1.0\n",
            "[-0.35461473  0.00180373]\n",
            "2\n",
            "-1.0\n",
            "[-0.3540248   0.00058994]\n",
            "1\n",
            "-1.0\n",
            "[-0.35465252 -0.00062772]\n",
            "1\n",
            "-1.0\n",
            "[-0.35649377 -0.00184126]\n",
            "1\n",
            "-1.0\n",
            "[-0.3605365 -0.0040427]\n",
            "0\n",
            "-1.0\n",
            "[-0.36675394 -0.00621747]\n",
            "0\n",
            "-1.0\n",
            "[-0.37410483 -0.00735088]\n",
            "1\n",
            "-1.0\n",
            "[-0.3815397  -0.00743488]\n",
            "2\n",
            "-1.0\n",
            "[-0.38900807 -0.00746836]\n",
            "2\n",
            "-1.0\n",
            "[-0.39845866 -0.00945058]\n",
            "0\n",
            "-1.0\n",
            "[-0.4098259  -0.01136724]\n",
            "0\n",
            "-1.0\n",
            "[-0.42302996 -0.01320407]\n",
            "0\n",
            "-1.0\n",
            "[-0.4369769  -0.01394694]\n",
            "1\n",
            "-1.0\n",
            "[-0.45056623 -0.01358932]\n",
            "2\n",
            "-1.0\n",
            "[-0.4646989  -0.01413269]\n",
            "1\n",
            "-1.0\n",
            "[-0.48027107 -0.01557215]\n",
            "0\n",
            "-1.0\n",
            "[-0.49616724 -0.01589619]\n",
            "1\n",
            "-1.0\n",
            "[-0.51226896 -0.01610169]\n",
            "1\n",
            "-1.0\n",
            "[-0.52745557 -0.01518665]\n",
            "2\n",
            "-1.0\n",
            "[-0.5426133  -0.01515773]\n",
            "1\n",
            "-1.0\n",
            "[-0.5586285  -0.01601519]\n",
            "0\n",
            "-1.0\n",
            "[-0.57538146 -0.01675295]\n",
            "0\n",
            "-1.0\n",
            "[-0.5927476  -0.01736614]\n",
            "0\n",
            "-1.0\n",
            "[-0.6095989  -0.01685124]\n",
            "1\n",
            "-1.0\n",
            "[-0.62481225 -0.01521337]\n",
            "2\n",
            "-1.0\n",
            "[-0.6392781  -0.01446588]\n",
            "1\n",
            "-1.0\n",
            "[-0.6518937 -0.0126156]\n",
            "2\n",
            "-1.0\n",
            "[-0.66357064 -0.01167697]\n",
            "1\n",
            "-1.0\n",
            "In episode 18\n",
            "(array([-0.54151475,  0.        ], dtype=float32), {})\n",
            "2\n",
            "-1.0\n",
            "[-0.54238045 -0.00086569]\n",
            "0\n",
            "-1.0\n",
            "[-0.54410535 -0.00172491]\n",
            "0\n",
            "-1.0\n",
            "[-0.5456766 -0.0015712]\n",
            "1\n",
            "-1.0\n",
            "[-5.4608232e-01 -4.0574194e-04]\n",
            "2\n",
            "-1.0\n",
            "[-5.4631954e-01 -2.3724329e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5473865  -0.00106697]\n",
            "0\n",
            "-1.0\n",
            "[-0.5492752  -0.00188871]\n",
            "0\n",
            "-1.0\n",
            "[-0.55097157 -0.00169633]\n",
            "1\n",
            "-1.0\n",
            "[-5.514628e-01 -4.912644e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.55274534 -0.00128253]\n",
            "0\n",
            "-1.0\n",
            "[-0.5538096  -0.00106421]\n",
            "1\n",
            "-1.0\n",
            "[-0.5556475  -0.00183794]\n",
            "0\n",
            "-1.0\n",
            "[-0.55724543 -0.00159794]\n",
            "1\n",
            "-1.0\n",
            "[-5.5759144e-01 -3.4601870e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.558683   -0.00109152]\n",
            "0\n",
            "-1.0\n",
            "[-0.55951184 -0.00082887]\n",
            "1\n",
            "-1.0\n",
            "[-5.6007189e-01 -5.6004216e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5613589  -0.00128704]\n",
            "0\n",
            "-1.0\n",
            "[-0.5633634  -0.00200444]\n",
            "0\n",
            "-1.0\n",
            "[-0.5650703  -0.00170692]\n",
            "1\n",
            "-1.0\n",
            "[-0.566467   -0.00139668]\n",
            "1\n",
            "-1.0\n",
            "[-5.6654304e-01 -7.6055650e-05]\n",
            "2\n",
            "-1.0\n",
            "[-5.6629789e-01  2.4513592e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5647334  0.0015645]\n",
            "2\n",
            "-1.0\n",
            "[-0.56386113  0.00087223]\n",
            "0\n",
            "-1.0\n",
            "[-5.636877e-01  1.734653e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.56221426  0.00147341]\n",
            "2\n",
            "-1.0\n",
            "[-0.5614519   0.00076238]\n",
            "0\n",
            "-1.0\n",
            "[-0.5594062   0.00204567]\n",
            "2\n",
            "-1.0\n",
            "[-0.5560925   0.00331371]\n",
            "2\n",
            "-1.0\n",
            "[-0.5535355   0.00255702]\n",
            "0\n",
            "-1.0\n",
            "[-0.55175424  0.00178125]\n",
            "0\n",
            "-1.0\n",
            "[-0.5487621   0.00299216]\n",
            "2\n",
            "-1.0\n",
            "[-0.5465814   0.00218071]\n",
            "0\n",
            "-1.0\n",
            "[-0.5452284   0.00135294]\n",
            "0\n",
            "-1.0\n",
            "[-0.5437134   0.00151505]\n",
            "1\n",
            "-1.0\n",
            "[-0.54204756  0.00166582]\n",
            "1\n",
            "-1.0\n",
            "[-0.53924346  0.00280411]\n",
            "2\n",
            "-1.0\n",
            "[-0.53532207  0.0039214 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.53231275  0.00300931]\n",
            "0\n",
            "-1.0\n",
            "[-0.5292381   0.00307466]\n",
            "1\n",
            "-1.0\n",
            "[-0.52512115  0.00411695]\n",
            "2\n",
            "-1.0\n",
            "[-0.51999277  0.00512837]\n",
            "2\n",
            "-1.0\n",
            "[-0.51489145  0.00510132]\n",
            "1\n",
            "-1.0\n",
            "[-0.5088554   0.00603603]\n",
            "2\n",
            "-1.0\n",
            "[-0.5039299   0.00492549]\n",
            "0\n",
            "-1.0\n",
            "[-0.5001519   0.00377806]\n",
            "0\n",
            "-1.0\n",
            "[-0.49754953  0.00260235]\n",
            "0\n",
            "-1.0\n",
            "[-0.49614236  0.00140718]\n",
            "0\n",
            "-1.0\n",
            "[-0.49494085  0.00120149]\n",
            "1\n",
            "-1.0\n",
            "[-0.49395403  0.00098682]\n",
            "1\n",
            "-1.0\n",
            "[-4.9418926e-01 -2.3522253e-04]\n",
            "0\n",
            "-1.0\n",
            "[-4.9464476e-01 -4.5550783e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.49631715 -0.00167239]\n",
            "0\n",
            "-1.0\n",
            "[-0.49819392 -0.00187677]\n",
            "1\n",
            "-1.0\n",
            "[-0.50126106 -0.00306713]\n",
            "0\n",
            "-1.0\n",
            "[-0.5054956  -0.00423453]\n",
            "0\n",
            "-1.0\n",
            "[-0.5108658  -0.00537024]\n",
            "0\n",
            "-1.0\n",
            "[-0.51733154 -0.00646571]\n",
            "0\n",
            "-1.0\n",
            "[-0.52284425 -0.00551272]\n",
            "2\n",
            "-1.0\n",
            "[-0.52836263 -0.00551837]\n",
            "1\n",
            "-1.0\n",
            "[-0.5348453  -0.00648265]\n",
            "0\n",
            "-1.0\n",
            "[-0.5402436  -0.00539831]\n",
            "2\n",
            "-1.0\n",
            "[-0.5445171  -0.00427353]\n",
            "2\n",
            "-1.0\n",
            "[-0.54963386 -0.00511674]\n",
            "0\n",
            "-1.0\n",
            "[-0.55455554 -0.00492168]\n",
            "1\n",
            "-1.0\n",
            "[-0.55824536 -0.00368984]\n",
            "2\n",
            "-1.0\n",
            "[-0.56167585 -0.00343046]\n",
            "1\n",
            "-1.0\n",
            "[-0.5638213 -0.0021455]\n",
            "2\n",
            "-1.0\n",
            "[-0.5656659  -0.00184456]\n",
            "1\n",
            "-1.0\n",
            "[-0.5671958  -0.00152989]\n",
            "1\n",
            "-1.0\n",
            "[-0.56839967 -0.00120385]\n",
            "1\n",
            "-1.0\n",
            "[-0.5692685  -0.00086885]\n",
            "1\n",
            "-1.0\n",
            "[-0.5707959 -0.0015274]\n",
            "0\n",
            "-1.0\n",
            "[-5.709705e-01 -1.746030e-04]\n",
            "2\n",
            "-1.0\n",
            "[-0.569791    0.00117949]\n",
            "2\n",
            "-1.0\n",
            "[-5.6926620e-01  5.2482425e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.6939995e-01 -1.3374063e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.6919122e-01  2.0868814e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5676417   0.00154957]\n",
            "2\n",
            "-1.0\n",
            "[-0.56676275  0.00087893]\n",
            "0\n",
            "-1.0\n",
            "[-5.6656098e-01  2.0175369e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.6703794e-01 -4.7692104e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.56819    -0.00115205]\n",
            "0\n",
            "-1.0\n",
            "[-5.6800860e-01  1.8138846e-04]\n",
            "2\n",
            "-1.0\n",
            "[-5.674951e-01  5.134775e-04]\n",
            "1\n",
            "-1.0\n",
            "[-5.6765336e-01 -1.5825087e-04]\n",
            "0\n",
            "-1.0\n",
            "[-5.6748217e-01  1.7119736e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.56598276  0.00149937]\n",
            "2\n",
            "-1.0\n",
            "[-0.56416637  0.0018164 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.56304646  0.0011199 ]\n",
            "0\n",
            "-1.0\n",
            "[-5.6263143e-01  4.1507106e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.56092423  0.00170715]\n",
            "2\n",
            "-1.0\n",
            "[-0.5589377  0.0019865]\n",
            "1\n",
            "-1.0\n",
            "[-0.5576867   0.00125105]\n",
            "0\n",
            "-1.0\n",
            "[-0.5561804   0.00150626]\n",
            "1\n",
            "-1.0\n",
            "[-0.5554302   0.00075024]\n",
            "0\n",
            "-1.0\n",
            "[-0.5544416   0.00098861]\n",
            "1\n",
            "-1.0\n",
            "[-0.552222   0.0022196]\n",
            "2\n",
            "-1.0\n",
            "In episode 19\n",
            "(array([-0.593624,  0.      ], dtype=float32), {})\n",
            "1\n",
            "-1.0\n",
            "[-5.9310263e-01  5.2133464e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.5920638   0.00103884]\n",
            "1\n",
            "-1.0\n",
            "[-0.5905151   0.00154873]\n",
            "1\n",
            "-1.0\n",
            "[-0.58846784  0.00204724]\n",
            "1\n",
            "-1.0\n",
            "[-0.58493716  0.00353069]\n",
            "2\n",
            "-1.0\n",
            "[-0.579949    0.00498814]\n",
            "2\n",
            "-1.0\n",
            "[-0.57454026  0.00540875]\n",
            "1\n",
            "-1.0\n",
            "[-0.5697509   0.00478933]\n",
            "0\n",
            "-1.0\n",
            "[-0.56561655  0.00413436]\n",
            "0\n",
            "-1.0\n",
            "[-0.5601679   0.00544866]\n",
            "2\n",
            "-1.0\n",
            "[-0.5534455   0.00672238]\n",
            "2\n",
            "-1.0\n",
            "[-0.54549956  0.00794593]\n",
            "2\n",
            "-1.0\n",
            "[-0.5363895   0.00911007]\n",
            "2\n",
            "-1.0\n",
            "[-0.52618355  0.01020598]\n",
            "2\n",
            "-1.0\n",
            "[-0.5169582   0.00922536]\n",
            "0\n",
            "-1.0\n",
            "[-0.5087826   0.00817556]\n",
            "0\n",
            "-1.0\n",
            "[-0.49971813  0.00906448]\n",
            "2\n",
            "-1.0\n",
            "[-0.4908326   0.00888553]\n",
            "1\n",
            "-1.0\n",
            "[-0.48219243  0.00864018]\n",
            "1\n",
            "-1.0\n",
            "[-0.472862    0.00933043]\n",
            "2\n",
            "-1.0\n",
            "[-0.4639106   0.00895137]\n",
            "1\n",
            "-1.0\n",
            "[-0.45540452  0.0085061 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.44840634  0.0069982 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.4409673   0.00743903]\n",
            "2\n",
            "-1.0\n",
            "[-0.43314168  0.00782562]\n",
            "2\n",
            "-1.0\n",
            "[-0.42498618  0.00815549]\n",
            "2\n",
            "-1.0\n",
            "[-0.41855955  0.00642663]\n",
            "0\n",
            "-1.0\n",
            "[-0.41390774  0.00465181]\n",
            "0\n",
            "-1.0\n",
            "[-0.40906385  0.0048439 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.40406215  0.00500169]\n",
            "2\n",
            "-1.0\n",
            "[-0.3989379   0.00512426]\n",
            "2\n",
            "-1.0\n",
            "[-0.39472696  0.00421094]\n",
            "1\n",
            "-1.0\n",
            "[-0.39245865  0.0022683 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.39114875  0.00130993]\n",
            "1\n",
            "-1.0\n",
            "[-3.9080626e-01  3.4248832e-04]\n",
            "1\n",
            "-1.0\n",
            "[-0.39143357 -0.00062732]\n",
            "1\n",
            "-1.0\n",
            "[-0.39402637 -0.00259279]\n",
            "0\n",
            "-1.0\n",
            "[-0.39856666 -0.0045403 ]\n",
            "0\n",
            "-1.0\n",
            "[-0.40402284 -0.0054562 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.40935677 -0.00533391]\n",
            "2\n",
            "-1.0\n",
            "[-0.41653082 -0.00717405]\n",
            "0\n",
            "-1.0\n",
            "[-0.42349413 -0.00696332]\n",
            "2\n",
            "-1.0\n",
            "[-0.431197   -0.00770287]\n",
            "1\n",
            "-1.0\n",
            "[-0.43858403 -0.00738704]\n",
            "2\n",
            "-1.0\n",
            "[-0.44560182 -0.00701776]\n",
            "2\n",
            "-1.0\n",
            "[-0.45219922 -0.00659742]\n",
            "2\n",
            "-1.0\n",
            "[-0.46032804 -0.00812883]\n",
            "0\n",
            "-1.0\n",
            "[-0.46792856 -0.00760051]\n",
            "2\n",
            "-1.0\n",
            "[-0.47494468 -0.0070161 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.4823244  -0.00737971]\n",
            "1\n",
            "-1.0\n",
            "[-0.49101287 -0.00868848]\n",
            "0\n",
            "-1.0\n",
            "[-0.5009453  -0.00993249]\n",
            "0\n",
            "-1.0\n",
            "[-0.5100476  -0.00910226]\n",
            "2\n",
            "-1.0\n",
            "[-0.51925147 -0.00920386]\n",
            "1\n",
            "-1.0\n",
            "[-0.52948797 -0.01023647]\n",
            "0\n",
            "-1.0\n",
            "[-0.53868026 -0.0091923 ]\n",
            "2\n",
            "-1.0\n",
            "[-0.5467595  -0.00807923]\n",
            "2\n",
            "-1.0\n",
            "[-0.55566514 -0.00890566]\n",
            "0\n",
            "-1.0\n",
            "[-0.5653307  -0.00966554]\n",
            "0\n",
            "-1.0\n",
            "[-0.57368404 -0.00835336]\n",
            "2\n",
            "-1.0\n",
            "[-0.58066314 -0.00697914]\n",
            "2\n",
            "-1.0\n",
            "[-0.5882164  -0.00755324]\n",
            "0\n",
            "-1.0\n",
            "[-0.59528804 -0.00707164]\n",
            "1\n",
            "-1.0\n",
            "[-0.60182613 -0.0065381 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.6067829  -0.00495677]\n",
            "2\n",
            "-1.0\n",
            "[-0.61012226 -0.00333934]\n",
            "2\n",
            "-1.0\n",
            "[-0.61281997 -0.00269768]\n",
            "1\n",
            "-1.0\n",
            "[-0.6158564  -0.00303648]\n",
            "0\n",
            "-1.0\n",
            "[-0.6182098  -0.00235335]\n",
            "1\n",
            "-1.0\n",
            "[-0.61886305 -0.00065326]\n",
            "2\n",
            "-1.0\n",
            "[-0.6198115  -0.00094846]\n",
            "0\n",
            "-1.0\n",
            "[-0.61904836  0.00076316]\n",
            "2\n",
            "-1.0\n",
            "[-6.1857903e-01  4.6928451e-04]\n",
            "0\n",
            "-1.0\n",
            "[-0.61640704  0.00217204]\n",
            "2\n",
            "-1.0\n",
            "[-0.61454785  0.00185914]\n",
            "0\n",
            "-1.0\n",
            "[-0.61301506  0.00153283]\n",
            "0\n",
            "-1.0\n",
            "[-0.6118196   0.00119543]\n",
            "0\n",
            "-1.0\n",
            "[-0.6109702   0.00084939]\n",
            "0\n",
            "-1.0\n",
            "[-0.60947305  0.0014972 ]\n",
            "1\n",
            "-1.0\n",
            "[-0.6083389   0.00113416]\n",
            "0\n",
            "-1.0\n",
            "[-0.605576    0.00276288]\n",
            "2\n",
            "-1.0\n",
            "[-0.60220444  0.00337153]\n",
            "1\n",
            "-1.0\n",
            "[-0.5972488   0.00495563]\n",
            "2\n",
            "-1.0\n",
            "[-0.5917453   0.00550352]\n",
            "1\n",
            "-1.0\n",
            "[-0.58573425  0.00601107]\n",
            "1\n",
            "-1.0\n",
            "[-0.5792599   0.00647439]\n",
            "1\n",
            "-1.0\n",
            "[-0.5733699   0.00588991]\n",
            "0\n",
            "-1.0\n",
            "[-0.56810814  0.00526181]\n",
            "0\n",
            "-1.0\n",
            "[-0.5635135   0.00459464]\n",
            "0\n",
            "-1.0\n",
            "[-0.5586202   0.00489328]\n",
            "1\n",
            "-1.0\n",
            "[-0.55446476  0.00415546]\n",
            "0\n",
            "-1.0\n",
            "[-0.55107814  0.00338662]\n",
            "0\n",
            "-1.0\n",
            "[-0.54748565  0.00359248]\n",
            "1\n",
            "-1.0\n",
            "[-0.5427142   0.00477148]\n",
            "2\n",
            "-1.0\n",
            "[-0.5377994   0.00491477]\n",
            "1\n",
            "-1.0\n",
            "[-0.53277814  0.00502124]\n",
            "1\n",
            "-1.0\n",
            "[-0.5276881   0.00509008]\n",
            "1\n",
            "-1.0\n",
            "[-0.52256733  0.00512075]\n",
            "1\n",
            "-1.0\n",
            "[-0.5174543   0.00511301]\n",
            "1\n",
            "-1.0\n"
          ]
        }
      ],
      "source": [
        "# Create MountainCar environment:\n",
        "# https://gymnasium.farama.org/environments/classic_control/mountain_car/\n",
        "\n",
        "env = gym.make('MountainCar-v0')\n",
        "env.seed =45\n",
        "s = env.reset()\n",
        "print(\"Observation Space = \")\n",
        "print(env.observation_space)\n",
        "print(\"Action Space = \")\n",
        "print(env.action_space)\n",
        "done = False\n",
        "for episode in range(20):\n",
        "    done = False\n",
        "    s = env.reset()\n",
        "    print(\"In episode {}\".format(episode))\n",
        "    for i in range(100):\n",
        "        env.render()\n",
        "        print(s)\n",
        "        print(a)\n",
        "        a = env.action_space.sample()\n",
        "        s, r, done, _, info = env.step(a)\n",
        "        print(r)\n",
        "        if done:\n",
        "            print(\"Finished after {} timestep\".format(i+1))\n",
        "            break\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env1 = gym.make('CartPole-v0')\n",
        "env2 = gym.make('MountainCar-v0')"
      ],
      "metadata": {
        "id": "_oXbyjqLU6ni"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW0e7NcquIl8"
      },
      "source": [
        "# Hyperparameters\n",
        "<a id=\"Hyperparameters\"></a>\n",
        "\n",
        "All your hyperparameters should be stated here. We will change their value here and your code should work  accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XB4l9hmnuIl8"
      },
      "outputs": [],
      "source": [
        "# mention the values of all the hyperparameters (you can add more hyper-paramters as well) to be used in the entire notebook, put the values that gave the best\n",
        "# performance and were finally used for the agent\n",
        "\n",
        "gamma =  0.99\n",
        "epsilon = 0.5#epsilon greedy strategy\n",
        "temp = 10#softmax strategy\n",
        "delta = 2 #huber loss\n",
        "tau = 1#D3QN\n",
        "alpha = 1#D3QN-PER\n",
        "beta = 1#D3QN-PER\n",
        "beta_rate = 1#D3QN-PER\n",
        "MAX_TRAIN_EPISODES = 30\n",
        "MAX_EVAL_EPISODES = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDHSV1S9uIl8"
      },
      "source": [
        "# Helper Functions\n",
        "<a id=\"helper\"></a>\n",
        "\n",
        "Write all the helper functions that will be used for value-based and policy based algorithms below. In case you want to add more helper functions, please feel free to add."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c7fBV-q4uIl8"
      },
      "outputs": [],
      "source": [
        "def selectGreedyAction(net, state):\n",
        "    #this function gets q-values via the network and selects greedy action from q-values and returns it\n",
        "\n",
        "    a = net(state)\n",
        "\n",
        "    greedyAction = int(torch.argmax(a))\n",
        "\n",
        "\n",
        "    #Your code goes in here\n",
        "\n",
        "    return greedyAction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rtLszUD4uIl8"
      },
      "outputs": [],
      "source": [
        "def selectEpsilonGreedyAction(net,  state, epsilon):\n",
        "    #this function gets q-values via the network and selects an action from q-values using epsilon greedy strategy\n",
        "    #and returns it\n",
        "    #note this function can be used for decaying epsilon greedy strategy,\n",
        "    #you would need to create a wrapper function that will handle decaying epsilon\n",
        "    #you can create this wrapper in this helper function section\n",
        "    #for the agents you would be implementing it would be nice to play with decaying parameter to get optimal results\n",
        "\n",
        "    #Your code goes in here\n",
        "\n",
        "    if random.random()>epsilon:\n",
        "      eGreedyAction = selectGreedyAction(net,state)\n",
        "    else:\n",
        "      eGreedyAction = random.randint(0, net(state).nelement()-1)\n",
        "\n",
        "    return eGreedyAction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Jv66wXwhuIl9"
      },
      "outputs": [],
      "source": [
        "def selectSoftMaxAction(net, state, temp):\n",
        "    #this function gets q-values via the network and selects an action from q-values using softmax strategy\n",
        "    #and returns it\n",
        "    #note this function can be used for decaying temperature softmax strategy,\n",
        "    #you would need to create a wrapper function that will handle decaying temperature\n",
        "    #you can create this wrapper in this helper function section\n",
        "    #for the agents you would be implementing it would be nice to play with decaying parameter to get optimal results\n",
        "\n",
        "    #Your code goes in here\n",
        "\n",
        "    Q = np.array(net(state))[0]\n",
        "    eQ = np.exp(Q/temp)\n",
        "    sum=0\n",
        "    for i in range(np.size(Q)):\n",
        "      sum+=eQ\n",
        "    sQ = eQ/sum\n",
        "    softAction = np.argmax(sQ)\n",
        "    return softAction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YaW4iIO-uIl9"
      },
      "outputs": [],
      "source": [
        "#Value Network\n",
        "def createValueNetwork(inDim, outDim, hDim = [32,32], activation = F.relu):\n",
        "    #this creates a Feed Forward Neural Network class and instantiates it and returns the class\n",
        "    #the class should be derived from torch nn.Module and it should have init and forward method at the very least\n",
        "    #the forward function should return q-value for each possible action\n",
        "\n",
        "    #Your code goes in here\n",
        "\n",
        "    class valueNetwork(nn.Module):\n",
        "      def __init__(self,inDim=inDim,outDim=outDim,hDim=hDim, activation=activation):\n",
        "        super(valueNetwork, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        nHid = len(hDim)\n",
        "        for i in range(nHid):\n",
        "          self.layers.append(nn.Linear(inDim,hDim[i]))\n",
        "          inDim = hDim[i]\n",
        "        self.layers.append(nn.Linear(inDim,outDim))\n",
        "        self.activation = activation\n",
        "\n",
        "      def forward(self,state):\n",
        "        try:\n",
        "          x = torch.Tensor(state)\n",
        "        except:\n",
        "          x = torch.Tensor(state[0])\n",
        "        for layer in self.layers[:-1]:\n",
        "          x = self.activation(layer(x))\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n",
        "\n",
        "    return valueNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VvI-qxf7uIl9"
      },
      "outputs": [],
      "source": [
        "#Dueling Network\n",
        "def createDuelingNetwork(inDim, outDim, hDim = [32,32], activation = F.relu):\n",
        "    #this creates a Feed Forward Neural Network class and instantiates it and returns the class\n",
        "    #the class should be derived from torch nn.Module and it should have init and forward method at the very least\n",
        "    #the forward function should return q-value which is derived\n",
        "    #internally from action-advantage function and v-function,\n",
        "    #Note we center the advantage values, basically we subtract the mean from each state-action value\n",
        "\n",
        "    #Your code goes in here\n",
        "    class duelNetwork(nn.Module):\n",
        "      def __init__(self,inDim=inDim,outDim=outDim,hDim=hDim, activation=activation):\n",
        "        super(duelNetwork, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        prev_dim = inDim\n",
        "        for i in hDim:\n",
        "          self.layers.append(nn.Linear(prev_dim,i))\n",
        "          prev_dim = i\n",
        "        self.value_stream = nn.Linear(prev_dim,1)\n",
        "        self.advantage_stream = nn.Linear(prev_dim, outDim)\n",
        "        self.activation = activation\n",
        "\n",
        "      def forward(self,state):\n",
        "        try:\n",
        "          x = torch.Tensor(state)\n",
        "        except:\n",
        "          x = torch.Tensor(state[0])\n",
        "        for layer in self.layers:\n",
        "          x = self.activation(layer(x))\n",
        "        value = self.value_stream(x)\n",
        "        advantage = self.advantage_stream(x)\n",
        "        sum=0\n",
        "        for i in advantage:\n",
        "          sum+=i\n",
        "        mean = sum/len(advantage)\n",
        "        q_values = value+(advantage-mean)\n",
        "\n",
        "        return q_values\n",
        "\n",
        "    return duelNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XruHE4uvuIl9"
      },
      "outputs": [],
      "source": [
        "#Policy Network\n",
        "def createPolicyNetwork(inDim, outDim, hDim = [32,32], activation = F.relu):\n",
        "    #this creates a Feed Forward Neural Network class and instantiates it and returns the class\n",
        "    #the class should be derived from torch nn.Module and it should have init and forward method at the very least\n",
        "    #the forward function should return action logit vector\n",
        "    #Your code goes in here\n",
        "\n",
        "    class policyNetwork(nn.Module):\n",
        "      def __init__(self):\n",
        "        super(policyNetwork, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        prev_dim = inDim\n",
        "        for hid_dim in hDim:\n",
        "          self.layers.append(nn.Linear(prev_dim, hid_dim))\n",
        "          prev_dim = hid_dim\n",
        "        self.output_layer = nn.Linear(prev_dim, outDim)\n",
        "\n",
        "      def forward(self, state):\n",
        "        try:\n",
        "          x = torch.Tensor(state)\n",
        "        except:\n",
        "          x = torch.Tensor(state[0])\n",
        "        for layer in self.layers:\n",
        "          x = activation(layer(x))\n",
        "        action_logits = self.output_layer(x)\n",
        "        return action_logits\n",
        "\n",
        "      def selectAction(self,state):\n",
        "        action_logits = self.forward(state)\n",
        "        action_logits = action_logits/torch.sum(action_logits)\n",
        "        action = random.choices(range(outDim), weights=abs(action_logits))[0]\n",
        "        log_prob = math.log(abs(action_logits[action]))\n",
        "        return action, log_prob\n",
        "\n",
        "\n",
        "    return policyNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "j1qpWjKNuIl-"
      },
      "outputs": [],
      "source": [
        "def plotQuantity(quantityListDict, totalEpisodeCount, descriptionList):\n",
        "    #this function takes in the quantityListDict and plots quantity vs episodes.\n",
        "    #quantityListListDict = {envInstanceCount: quantityList}\n",
        "    #quantityList is list of the qunatity per episode,\n",
        "    #for example it could be mean reward per episode, traintime per episode, etc.\n",
        "    #\n",
        "    #NOTE: len(quantityList) == totalEpisodeCount\n",
        "    #\n",
        "    #Since we run multiple instances of the environment, there will be variance across environments\n",
        "    #so in the plot, you will plot per episode maximum, minimum and average value across all env instances\n",
        "    #Basically, you need to envelop (e.g., via color) the quantity between max and min with mean value in between\n",
        "    #\n",
        "    #use the descriptionList parameter to put legends, title, etc.\n",
        "    #For each of the plot, create the legend on the left/right side so that it doesn't overlay on the plot lines/envelop.\n",
        "    #\n",
        "    #this is a generic function and can be used to plot any of the quantity of interest\n",
        "    #In particular we will be using this function to plot:\n",
        "    #        mean train rewards vs episodes\n",
        "    #        mean evaluation rewards vs episodes\n",
        "    #        total steps vs episode\n",
        "    #        train time vs episode\n",
        "    #        wall clock time vs episode\n",
        "    #\n",
        "    #\n",
        "    #this function doesn't return anything\n",
        "\n",
        "    #Your code goes in here\n",
        "    e = range(totalEpisodeCount)+1\n",
        "    plt.figure()\n",
        "    for i in quantityListDict:\n",
        "      plt.plot(e,i)\n",
        "      plt.title(descriptionList)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Nn42yumiuIl-"
      },
      "outputs": [],
      "source": [
        "def huberLoss(error, delta):\n",
        "    #this function calculates the huber loss for the error using the delta parameter\n",
        "\n",
        "    #Your code goes in here\n",
        "\n",
        "    hLoss = 0\n",
        "\n",
        "    if abs(error)<delta:\n",
        "      hLoss = error**2/2\n",
        "    else:\n",
        "      hLoss = delta*(abs(error)-delta/2)\n",
        "\n",
        "    return hLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGICxRZtuIl-"
      },
      "outputs": [],
      "source": [
        "#in case you want to create any other helper function, the code goes in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uaL5q_ouIl-"
      },
      "outputs": [],
      "source": [
        "#in case you want to create any other helper function, the code goes in here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtzF3uKKuIl-"
      },
      "source": [
        "# Deep Value Based RL agents.\n",
        "<a id=\"deep-value-based\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yasVdR1uIl-"
      },
      "source": [
        "### The purpose of this part is to learn about different Deep Value Based RL agents.\n",
        "\n",
        "In this part of the assignment you will be implementing Deep RL algorithms we learnt in Lectures. Namely, we will be implementing NFQ, DQN, Double DQN (DDQN), Duelling Double DQN (D3QN), and Duelling Double DQN with Prioritized Experience Replay (D3QN-PER). For all the algorithms below, this time we will not be specifying the hyper-parameters, please play with the hyper-params to come up with the best values. This way you will learn to tune the model. Some of the values were specified in the lecture, that would be a good starting point. Your aim is to develop the best NFQ/DQN/DDQN/D3QN/D3QN-PER agent for each of the setting.  \n",
        "\n",
        "For those of you who follow TEDEd, here is an interesting video by TED on DQN and Atari Games: https://www.youtube.com/watch?v=PP8Zc778B8s\n",
        "\n",
        "Also since these environments are available in Gymanasium, there are public leaderboards (https://github.com/openai/gym/wiki/Leaderboard) for each of these environments. Compare where does your agent stand on these leaderboard for each of these environments, try to tune your agents so that it is on the top of the leaderboard. In fact, if your agent performs well on these environments, you can alse make your entry on the leaderboard.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05_HuqSfuIl_"
      },
      "source": [
        "## <font color='green'> Do not change any Class/Methods definition. We have split the class methods across cells for code readibility purposes. This requires to inherit the same class, please do not change it. </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P57saSpxuIl_"
      },
      "source": [
        "## ReplayBuffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wo0_MoDuIl_"
      },
      "source": [
        "In next few cells, you will implement replaybuffer class.\n",
        "\n",
        "This class creates a buffer for storing and retrieving experiences. This is a generic class and can be used\n",
        "for different agents like NFQ, DQN, DDQN, PER_DDQN, etc.\n",
        "Following are the methods for this class which are implemented in subsequent cells\n",
        "\n",
        "```\n",
        "class ReplayBuffer():\n",
        "    def __init__(self, bufferSize, **kwargs)\n",
        "    def store(self, experience)\n",
        "    def update(self, indices, priorities)\n",
        "    def collectExperiences(env, state, explorationStrategy, net = None)\n",
        "    def sample(self, batchSize, **kwargs)\n",
        "    def splitExperiences(self, experiences)\n",
        "    def length(self)\n",
        "```   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ULesnjw6uIl_"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, bufferSize, bufferType = 'DQN', **kwargs):\n",
        "        # this function creates the relevant data-structures, and intializes all relevant variables\n",
        "        # it can take variable number of parameters like alpha, beta, beta_rate (required for PER)\n",
        "        # here the bufferType variable can be used to maintain one class for all types of agents\n",
        "        # using the bufferType parameter in the methods below, you can implement all possible functionalities\n",
        "        # that could be used for different types of agents\n",
        "        # permissible values for bufferType = NFQ, DQN, DDQN, D3QN and PER-D3QN\n",
        "\n",
        "        #Your code goes in here\n",
        "\n",
        "        self.bufferSize = bufferSize\n",
        "        self.buffer = []\n",
        "\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uGPdeQbruImA"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "    def store(self, experience):\n",
        "        #stores the experiences, based on parameters in init it can assign priorities, etc.\n",
        "        #\n",
        "        #this function does not return anything\n",
        "        #\n",
        "        #Your code goes in here\n",
        "\n",
        "        if self.length()>self.bufferSize:\n",
        "          self.buffer.pop(0)\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3Dd7FLl4uImA"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "    def update(self, indices, priorities):\n",
        "        #this is mainly used for PER-DDQN\n",
        "        #otherwise just have a pass in this method\n",
        "        #\n",
        "        #this function does not return anything\n",
        "        #\n",
        "        #Your code goes in here\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b6iEcpEtuImA"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "    def collectExperiences(self, env, net, state, explorationStrategy, countExperiences):\n",
        "        #this method allows the agent to interact with the environment starting from a state and it collects\n",
        "        #experiences during the interaction, it uses network to get the value function and uses exploration strategy\n",
        "        #to select action. It collects countExperiences and in case the environment terminates before that it returns\n",
        "        #the function calling this method needs to handle early termination accordingly.\n",
        "        #\n",
        "        #this function does not return anything\n",
        "        #\n",
        "        #Your code goes in here\n",
        "\n",
        "        experiences = []\n",
        "        curr_state = state\n",
        "        done=False\n",
        "        epsilon = explorationStrategy\n",
        "        i=0\n",
        "        t_r=0\n",
        "        while not done and  i<countExperiences:\n",
        "          i+=1\n",
        "          action = selectEpsilonGreedyAction(net, state, epsilon)\n",
        "          ns, r, done, _, info = env.step(action)\n",
        "          self.store((curr_state, action, r, ns, done))\n",
        "          curr_state = ns\n",
        "          t_r+=r\n",
        "          if done:\n",
        "            curr_state = env.reset()\n",
        "\n",
        "        return t_r\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SYUg9JwUuImA"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "    def sample(self, batchSize, **kwargs):\n",
        "        # this method returns batchSize number of experiences\n",
        "        # based on extra arguments, it could do sampling or it could return the latest batchSize experiences or\n",
        "        # via some other strategy\n",
        "        #\n",
        "        # in the case of Prioritized Experience Replay (PER) the sampling needs to take into account the priorities\n",
        "        #\n",
        "        # this function returns experiences samples\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        experiencesList = random.sample(self.buffer, batchSize)\n",
        "        return experiencesList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-swBgyJOuImB"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "    def splitExperiences(self, experiences):\n",
        "        #it takes in experiences and gives the following:\n",
        "        #states, actions, rewards, nextStates, dones\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #\n",
        "        states, actions, rewards, nextStates, dones = zip(*experiences)\n",
        "\n",
        "        return states, actions, rewards, nextStates, dones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FB2EDX8huImB"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "    def length(self):\n",
        "        #tells the number of experiences stored in the internal buffer\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #\n",
        "        bufferSize = len(self.buffer)\n",
        "        return bufferSize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE3YXIJhuImB"
      },
      "source": [
        "## Neural Fitted Q (NFQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmwhOuepuImB"
      },
      "source": [
        "Implement the Neural Fitted Q algorithm. We have studied about NFQ algorithm in the Lecture. Use the function definitions (given below).\n",
        "\n",
        "This class implements the NFQ Agent, you are required to implement the various methods of this class\n",
        "as outlined below. Note this class is generic and should work with any permissible Gym environment.\n",
        "Also please feel free to play with different exploration strategies with decaying paramters (epsilon/temperature)\n",
        "\n",
        "```\n",
        "class NFQ():\n",
        "    def __init__(env, seed, gamma, epochs,\n",
        "                 bufferSize,\n",
        "                 batchSize,\n",
        "                 optimizerFn,\n",
        "                 optimizerLR,\n",
        "                 MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn,\n",
        "                 explorationStrategyEvalFn)\n",
        "    def initBookKeeping(self)\n",
        "    def performBookKeeping(self, train = True)\n",
        "    def runNFQ(self)\n",
        "    def trainAgent(self)\n",
        "    def trainNetwork(self, experiences, epochs)\n",
        "    def evaluateAgent(self)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "CkQUOXSjuImM"
      },
      "outputs": [],
      "source": [
        "class NFQ():\n",
        "    def __init__(self, env, seed=69, gamma=gamma, epochs=100,\n",
        "                 bufferSize=100,\n",
        "                 batchSize=50,\n",
        "                 optimizerFn=torch.optim.Adam,\n",
        "                 optimizerLR=0.01,\n",
        "                 MAX_TRAIN_EPISODES=25, MAX_EVAL_EPISODES=1,\n",
        "                 explorationStrategyTrainFn=None,\n",
        "                 explorationStrategyEvalFn=None):\n",
        "        #this NFQ method\n",
        "        # 1. creates and initializes (with seed) the environment, train/eval episodes, gamma, etc.\n",
        "        self.env = env\n",
        "        self.seed = seed\n",
        "        self.env.seed = self.seed\n",
        "        self.gamma = gamma\n",
        "        self.epochs = epochs\n",
        "        self.bufferSize = bufferSize\n",
        "        self.batchSize = batchSize\n",
        "        self.optimizerFn = optimizerFn\n",
        "        self.optimizerLR = optimizerLR\n",
        "        self.MAX_TRAIN_EPISODES = MAX_TRAIN_EPISODES\n",
        "        self.MAX_EVAL_EPISODES = MAX_EVAL_EPISODES\n",
        "        self.explorationStrategyTrainFn = explorationStrategyTrainFn\n",
        "        self.explorationStrategyEvalFn = explorationStrategyEvalFn\n",
        "        # 2. creates and intializes all the variables required for book-keeping values via the initBookKeeping method\n",
        "        self.initBookKeeping()\n",
        "        # 3. creates Q-network using the createValueNetwork above\n",
        "        self.net = createValueNetwork(inDim = np.size(env.reset()[0]), outDim=env.action_space.n)()\n",
        "        # 4. creates and initializes (with network params) the optimizer function\n",
        "        # 5. sets the explorationStartegy variables/functions for train and evaluation\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.epsilon_min = 0.01\n",
        "        # 6. sets the batchSize for the number of experiences\n",
        "        # 7. Creates the replayBuffer\n",
        "        self.buffer = ReplayBuffer(bufferSize)\n",
        "\n",
        "\n",
        "\n",
        "        return\n",
        "    #Your code goes in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "b1W6vw_YuImM"
      },
      "outputs": [],
      "source": [
        "class NFQ(NFQ):\n",
        "    def initBookKeeping(self):\n",
        "        #this method creates and intializes all the variables required for book-keeping values and it is called\n",
        "        #init method\n",
        "        self.trainRewardList = []\n",
        "        self.trainTimeList = []\n",
        "        self.evalRewardsList = []\n",
        "        self.wallClockTimeList = []\n",
        "        return\n",
        "\n",
        "\n",
        "    #Your code goes in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "JtpOyXJIuImM"
      },
      "outputs": [],
      "source": [
        "class NFQ(NFQ):\n",
        "    def performBookKeeping(self, train = True):\n",
        "        #this method updates relevant variables for the bookKeeping, this can be called\n",
        "        #multiple times during training\n",
        "        #if you want you can print information using this, so it may help to monitor progress and also help to debug\n",
        "        #Your code goes in here\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "YdEpcfe7uImM"
      },
      "outputs": [],
      "source": [
        "class NFQ(NFQ):\n",
        "    def runNFQ(self):\n",
        "        #this is the main method, it trains the agent, performs bookkeeping while training and finally evaluates\n",
        "        #the agent and returns the following quantities:\n",
        "        #1. episode wise mean train rewards\n",
        "        #2. epsiode wise mean eval rewards\n",
        "        #2. episode wise trainTime (in seconds): time elapsed during training since the start of the first episode\n",
        "        #3. episode wise wallClockTime (in seconds): actual time elapsed since the start of training,\n",
        "        #                               note this will include time for BookKeeping and evaluation\n",
        "        # Note both trainTime and wallClockTime get accumulated as episodes proceed.\n",
        "\n",
        "        trainRewardsList, trainTimeList, evalRewardsList, wallClockTimeList = self.trainAgent()\n",
        "\n",
        "        meanTrainRewards = []\n",
        "        meanEvalRewards = []\n",
        "        sum1=0\n",
        "        sum2=0\n",
        "        for i in range(len(trainRewardsList)):\n",
        "          sum1+=trainRewardsList[i]\n",
        "          meanTrainRewards.append(sum1/(i+1))\n",
        "        for i in range(len(evalRewardsList)):\n",
        "          sum2+=evalRewardsList[i]\n",
        "          meanEvalRewards.append(sum2/(i+1))\n",
        "\n",
        "        return meanTrainRewards, trainTimeList, meanEvalRewards, wallClockTimeList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "F6fyd4XkuImM"
      },
      "outputs": [],
      "source": [
        "class NFQ(NFQ):\n",
        "    def trainAgent(self):\n",
        "        #this method collects experiences and trains the NFQ agent and does BookKeeping while training.\n",
        "        #this calls the trainNetwork() method internally, it also evaluates the agent per episode\n",
        "        #it trains the agent for MAX_TRAIN_EPISODES\n",
        "\n",
        "        #Your code goes in here\n",
        "        trainRewardsList=[]\n",
        "        trainTimeList = []\n",
        "        evalRewardsList = []\n",
        "        wallClockTimeList = []\n",
        "        finalEvalReward=None\n",
        "        for e in range(self.MAX_TRAIN_EPISODES):\n",
        "          start_time = time.time()\n",
        "          #print(\"Episode Number \", e+1)\n",
        "          s = self.env.reset()[0]\n",
        "          done=False\n",
        "          i=0\n",
        "          total_reward = self.buffer.collectExperiences(self.env,self.net,s,self.epsilon,self.bufferSize)\n",
        "\n",
        "          if self.buffer.length()>=self.batchSize:\n",
        "            for j in range(self.epochs):\n",
        "              self.trainNetwork()\n",
        "\n",
        "          trainRewardsList.append(total_reward)\n",
        "          trainTimeList.append(time.time()-start_time)\n",
        "\n",
        "\n",
        "          eval_reward = np.mean(self.evaluateAgent())\n",
        "          evalRewardsList.append(eval_reward)\n",
        "\n",
        "          if finalEvalReward is None or eval_reward>finalEvalReward:\n",
        "            finalEvalReward = eval_reward\n",
        "\n",
        "          wallClockTimeList.append(time.time())\n",
        "\n",
        "\n",
        "        return trainRewardsList, trainTimeList, evalRewardsList, wallClockTimeList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "HY7LSxJUuImN"
      },
      "outputs": [],
      "source": [
        "class NFQ(NFQ):\n",
        "    def trainNetwork(self):\n",
        "        # this method trains the value network epoch number of times and is called by the trainAgent function\n",
        "        # it essentially uses the experiences to calculate target, using the targets it calculates the error, which\n",
        "        # is further used for calulating the loss. It then uses the optimizer over the loss\n",
        "        # to update the params of the network by backpropagating through the network\n",
        "        # this function does not return anything\n",
        "        # you can try out other loss functions other than MSE like Huber loss, MAE, etc.\n",
        "\n",
        "        #Your code goes in here\n",
        "        experiences = self.buffer\n",
        "        epochs = self.epochs\n",
        "        batch =self.buffer.sample(self.batchSize)\n",
        "        s, a, r, ns, dones = self.buffer.splitExperiences(batch)\n",
        "        states = torch.tensor(s)\n",
        "        actions = torch.tensor(a)\n",
        "        rewards = torch.tensor(r)\n",
        "        next_states = torch.tensor(ns)\n",
        "        dones = torch.tensor(dones)\n",
        "        done_b = []\n",
        "        for i in range(len(dones)):\n",
        "          done_b.append(1 if dones[i] else 0)\n",
        "        dones = torch.tensor(done_b)\n",
        "        Q_ns=[]\n",
        "        for i in next_states:\n",
        "          Q_ns.append(self.net.forward(i))\n",
        "        #print(Q_ns)\n",
        "        maxQ=[]\n",
        "        for j in Q_ns:\n",
        "          maxQ.append(torch.max(j))\n",
        "        maxQ = torch.tensor(maxQ)\n",
        "        with torch.no_grad():\n",
        "          target_values = rewards+self.gamma*(1-dones)*maxQ\n",
        "        target_values.requires_grad = True\n",
        "        Q_ns=[]\n",
        "        for i in states:\n",
        "          Q_ns.append(self.net.forward(i))\n",
        "        maxQ=[]\n",
        "        for j in Q_ns:\n",
        "          maxQ.append(torch.max(j))\n",
        "        maxQ = torch.tensor(maxQ)\n",
        "        current_values = maxQ\n",
        "        current_values.requires_grad = True\n",
        "        loss = nn.functional.mse_loss(current_values, target_values)\n",
        "        optimizer = self.optimizerFn(self.net.parameters(), lr = self.optimizerLR)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "3_bLTt8buImN"
      },
      "outputs": [],
      "source": [
        "class NFQ(NFQ):\n",
        "    def evaluateAgent(self):\n",
        "        #this function evaluates the agent using the value network, it evaluates agent for MAX_EVAL_EPISODES\n",
        "        #typcially MAX_EVAL_EPISODES = 1\n",
        "\n",
        "        #Your code goes in here\n",
        "\n",
        "        finalEvalRewardsList = []\n",
        "        for _ in range(self.MAX_EVAL_EPISODES):\n",
        "          state = self.env.reset()\n",
        "          done = False\n",
        "          total_reward = 0\n",
        "          i=0\n",
        "          while not done and i<self.epochs:\n",
        "            i+=1\n",
        "            action = selectEpsilonGreedyAction(self.net,state,self.epsilon)\n",
        "            ns, r, done, _, info = self.env.step(action)\n",
        "            state = ns\n",
        "            total_reward += r\n",
        "          finalEvalRewardsList.append(total_reward)\n",
        "\n",
        "        return finalEvalRewardsList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 467,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azOrHqPQyvd8",
        "outputId": "b91d7219-ccc3-4cfe-9f24-925edcd77d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode Number  1\n",
            "Episode Number  2\n",
            "Episode Number  3\n",
            "Episode Number  4\n",
            "Episode Number  5\n",
            "Episode Number  6\n",
            "Episode Number  7\n",
            "Episode Number  8\n",
            "Episode Number  9\n",
            "Episode Number  10\n",
            "Episode Number  11\n",
            "Episode Number  12\n",
            "Episode Number  13\n",
            "Episode Number  14\n",
            "Episode Number  15\n",
            "Episode Number  16\n",
            "Episode Number  17\n",
            "Episode Number  18\n",
            "Episode Number  19\n",
            "Episode Number  20\n",
            "Episode Number  21\n",
            "Episode Number  22\n",
            "Episode Number  23\n",
            "Episode Number  24\n",
            "Episode Number  25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([25.0,\n",
              "  20.0,\n",
              "  21.666666666666668,\n",
              "  19.5,\n",
              "  24.6,\n",
              "  31.5,\n",
              "  29.285714285714285,\n",
              "  27.0,\n",
              "  27.11111111111111,\n",
              "  25.5,\n",
              "  30.545454545454547,\n",
              "  29.916666666666668,\n",
              "  28.307692307692307,\n",
              "  27.0,\n",
              "  26.4,\n",
              "  25.8125,\n",
              "  25.941176470588236,\n",
              "  25.77777777777778,\n",
              "  25.105263157894736,\n",
              "  24.3,\n",
              "  24.0,\n",
              "  24.59090909090909,\n",
              "  25.608695652173914,\n",
              "  25.291666666666668,\n",
              "  25.44],\n",
              " [0.015694379806518555,\n",
              "  0.004895210266113281,\n",
              "  1.8380706310272217,\n",
              "  2.487758159637451,\n",
              "  1.612489938735962,\n",
              "  1.6942682266235352,\n",
              "  1.6422760486602783,\n",
              "  1.6600511074066162,\n",
              "  1.652517318725586,\n",
              "  1.8243134021759033,\n",
              "  2.4482178688049316,\n",
              "  1.6668212413787842,\n",
              "  1.657125473022461,\n",
              "  1.7413978576660156,\n",
              "  1.7552943229675293,\n",
              "  1.675255537033081,\n",
              "  2.0711240768432617,\n",
              "  2.0629799365997314,\n",
              "  1.6250636577606201,\n",
              "  1.6475160121917725,\n",
              "  1.728877305984497,\n",
              "  1.6545908451080322,\n",
              "  1.6757559776306152,\n",
              "  3.1224734783172607,\n",
              "  1.6831309795379639],\n",
              " [44.0,\n",
              "  32.5,\n",
              "  29.333333333333332,\n",
              "  25.75,\n",
              "  25.4,\n",
              "  23.333333333333332,\n",
              "  22.285714285714285,\n",
              "  20.875,\n",
              "  22.333333333333332,\n",
              "  22.7,\n",
              "  22.636363636363637,\n",
              "  23.25,\n",
              "  22.23076923076923,\n",
              "  21.714285714285715,\n",
              "  20.933333333333334,\n",
              "  20.625,\n",
              "  20.352941176470587,\n",
              "  20.72222222222222,\n",
              "  20.57894736842105,\n",
              "  21.05,\n",
              "  21.952380952380953,\n",
              "  21.545454545454547,\n",
              "  21.217391304347824,\n",
              "  20.916666666666668,\n",
              "  20.64],\n",
              " [1711254519.1484156,\n",
              "  1711254519.1572688,\n",
              "  1711254521.000173,\n",
              "  1711254523.4914448,\n",
              "  1711254525.1088235,\n",
              "  1711254526.8060915,\n",
              "  1711254528.4518986,\n",
              "  1711254530.114547,\n",
              "  1711254531.7737541,\n",
              "  1711254533.605066,\n",
              "  1711254536.0577393,\n",
              "  1711254537.730408,\n",
              "  1711254539.3899333,\n",
              "  1711254541.134704,\n",
              "  1711254542.8924482,\n",
              "  1711254544.5710893,\n",
              "  1711254546.64691,\n",
              "  1711254548.7152457,\n",
              "  1711254550.3474557,\n",
              "  1711254552.0010378,\n",
              "  1711254553.7375429,\n",
              "  1711254555.3951836,\n",
              "  1711254557.0740962,\n",
              "  1711254560.199665,\n",
              "  1711254561.8858635])"
            ]
          },
          "metadata": {},
          "execution_count": 467
        }
      ],
      "source": [
        "obj = NFQ(env=env1)\n",
        "obj.runNFQ()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3cmBfwauImN"
      },
      "source": [
        "## Deep Q-Network (DQN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JTFEpScuImN"
      },
      "source": [
        "Implement the Deep Q algorithm. We have studied about DQN algorithm in the Lecture. Use the function definitions (given below).\n",
        "\n",
        "This class implements the DQN Agent, you are required to implement the various methods of this class\n",
        "as outlined below. Note this class is generic and should work with any permissible Gym environment\n",
        "\n",
        "```\n",
        "class DQN():\n",
        "    def __init__(env, seed, gamma,\n",
        "                 bufferSize,\n",
        "                 batchSize,\n",
        "                 optimizerFn,\n",
        "                 optimizerLR,\n",
        "                 MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn,\n",
        "                 explorationStrategyEvalFn,\n",
        "                 updateFrequency)\n",
        "    def initBookKeeping(self)\n",
        "    def performBookKeeping(self, train = True)\n",
        "    def runDQN(self)\n",
        "    def trainAgent(self)\n",
        "    def trainNetwork(self, experiences)\n",
        "    def updateNetwork(self, onlineNet, targetNet)\n",
        "    def evaluateAgent(self)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "LjPWeWdMuImN"
      },
      "outputs": [],
      "source": [
        "class DQN():\n",
        "    def __init__(self,env, seed=69, gamma=0.99,\n",
        "                 bufferSize=100,\n",
        "                 batchSize=50,\n",
        "                 epochs=100,\n",
        "                 optimizerFn=torch.optim.Adam ,\n",
        "                 optimizerLR=0.01,\n",
        "                 MAX_TRAIN_EPISODES=MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES=MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn=None,\n",
        "                 explorationStrategyEvalFn=None,\n",
        "                 updateFrequency=5):\n",
        "        #this DQN method\n",
        "        # 1. creates and initializes (with seed) the environment, train/eval episodes, gamma, etc.\n",
        "        # 2. creates and intializes all the variables required for book-keeping values via the initBookKeeping method\n",
        "        # 3. creates traget and online Q-networks using the createValueNetwork above\n",
        "        # 4. creates and initializes (with network params) the optimizer function\n",
        "        # 5. sets the explorationStartegy variables/functions for train and evaluation\n",
        "        # 6. sets the batchSize for the number of experiences\n",
        "        # 7. Creates the replayBuffer\n",
        "\n",
        "        self.env = env\n",
        "        self.seed = seed\n",
        "        self.env.seed = self.seed\n",
        "        self.gamma = gamma\n",
        "        self.epochs = epochs\n",
        "        self.bufferSize = bufferSize\n",
        "        self.batchSize = batchSize\n",
        "        self.optimizerFn = optimizerFn\n",
        "        self.optimizerLR = optimizerLR\n",
        "        self.MAX_TRAIN_EPISODES = MAX_TRAIN_EPISODES\n",
        "        self.MAX_EVAL_EPISODES = MAX_EVAL_EPISODES\n",
        "        self.updateFrequency = updateFrequency\n",
        "        self.explorationStrategyTrainFn = explorationStrategyTrainFn\n",
        "        self.explorationStrategyEvalFn = explorationStrategyEvalFn\n",
        "        self.initBookKeeping()\n",
        "        self.online_net = createValueNetwork(inDim = np.size(env.reset()[0]), outDim=env.action_space.n)()\n",
        "        self.target_net = createValueNetwork(inDim = np.size(env.reset()[0]), outDim=env.action_space.n)()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.epsilon_min = 0.01\n",
        "        self.buffer = ReplayBuffer(bufferSize)\n",
        "\n",
        "        return\n",
        "        #Your code goes in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "tP9kxOfpuImN"
      },
      "outputs": [],
      "source": [
        "class DQN(DQN):\n",
        "    def initBookKeeping(self):\n",
        "        #this method creates and intializes all the variables required for book-keeping values and it is called\n",
        "        #init method\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "        self.trainRewardList=[]\n",
        "        self.trainTimeList = []\n",
        "        self.evalRewardList = []\n",
        "        self.wallClockTimeList = []\n",
        "        self.finalEvalReward = None\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "snfDYXmtuImN"
      },
      "outputs": [],
      "source": [
        "class DQN(DQN):\n",
        "    def performBookKeeping(self, train = True):\n",
        "        #this method updates relevant variables for the bookKeeping, this can be called\n",
        "        #multiple times during training\n",
        "        #if you want you can print information using this, so it may help to monitor progress and also help to debug\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "K19WyHHxuImO"
      },
      "outputs": [],
      "source": [
        "class DQN(DQN):\n",
        "    def runDQN(self):\n",
        "        #this is the main method, it trains the agent, performs bookkeeping while training and finally evaluates\n",
        "        #the agent and returns the following quantities:\n",
        "        #1. episode wise mean train rewards\n",
        "        #2. epsiode wise mean eval rewards\n",
        "        #2. episode wise trainTime (in seconds): time elapsed during training since the start of the first episode\n",
        "        #3. episode wise wallClockTime (in seconds): actual time elapsed since the start of training,\n",
        "        #                               note this will include time for BookKeeping and evaluation\n",
        "        # Note both trainTime and wallClockTime get accumulated as episodes proceed.\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #\n",
        "        trainRewardsList, trainTimeList, evalRewardsList, wallClockTimeList = self.trainAgent()\n",
        "\n",
        "        meanTrainRewards = []\n",
        "        meanEvalRewards = []\n",
        "        sum1=0\n",
        "        sum2=0\n",
        "        for i in range(len(trainRewardsList)):\n",
        "          sum1+=trainRewardsList[i]\n",
        "          meanTrainRewards.append(sum1/(i+1))\n",
        "        for i in range(len(evalRewardsList)):\n",
        "          sum2+=evalRewardsList[i]\n",
        "          meanEvalRewards.append(sum2/(i+1))\n",
        "\n",
        "        return meanTrainRewards, trainTimeList, meanEvalRewards, wallClockTimeList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "UzbBV5qtuImO"
      },
      "outputs": [],
      "source": [
        "class DQN(DQN):\n",
        "    def trainAgent(self):\n",
        "        #this method collects experiences and trains the agent and does BookKeeping while training.\n",
        "        #this calls the trainNetwork() method internally, it also evaluates the agent per episode\n",
        "        #it trains the agent for MAX_TRAIN_EPISODES\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #\n",
        "\n",
        "        for e in range(self.MAX_TRAIN_EPISODES):\n",
        "          start_time = time.time()\n",
        "          s = self.env.reset()[0]\n",
        "          done = False\n",
        "          total_reward = 0\n",
        "          i=0\n",
        "          total_reward = self.buffer.collectExperiences(self.env,self.online_net, s, self.epsilon, self.bufferSize)\n",
        "          if self.buffer.length()>=self.batchSize:\n",
        "            for j in range(100):\n",
        "              self.trainNetwork()\n",
        "\n",
        "\n",
        "          self.trainRewardList.append(total_reward)\n",
        "          self.trainTimeList.append(time.time()-start_time)\n",
        "          eval_reward = np.mean(self.evaluateAgent())\n",
        "          self.evalRewardList.append(eval_reward)\n",
        "\n",
        "          if self.finalEvalReward is None or eval_reward>self.finalEvalReward:\n",
        "            self.finalEvalReward = eval_reward\n",
        "\n",
        "          self.wallClockTimeList.append(time.time())\n",
        "\n",
        "          if e%self.updateFrequency:\n",
        "            self.updateNetwork()\n",
        "\n",
        "        return self.trainRewardList, self.trainTimeList, self.evalRewardList, self.wallClockTimeList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "o-9otCV3uImO"
      },
      "outputs": [],
      "source": [
        "class DQN(DQN):\n",
        "    def trainNetwork(self):\n",
        "        # this method trains the value network epoch number of times and is called by the trainAgent function\n",
        "        # it essentially uses the experiences to calculate target, using the targets it calculates the error, which\n",
        "        # is further used for calulating the loss. It then uses the optimizer over the loss\n",
        "        # to update the params of the network by backpropagating through the network\n",
        "        # this function does not return anything\n",
        "        # you can try out other loss functions other than MSE like Huber loss, MAE, etc.\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #\n",
        "        experiences = self.buffer\n",
        "        epochs = self.epochs\n",
        "        batch =self.buffer.sample(self.batchSize)\n",
        "        s, a, r, ns, dones = self.buffer.splitExperiences(batch)\n",
        "        states = torch.tensor(s)\n",
        "        actions = torch.tensor(a)\n",
        "        rewards = torch.tensor(r)\n",
        "        next_states = torch.tensor(ns)\n",
        "        dones = torch.tensor(dones)\n",
        "        done_b = []\n",
        "        for i in range(len(dones)):\n",
        "          done_b.append(1 if dones[i] else 0)\n",
        "        dones = torch.tensor(done_b)\n",
        "        Q_ns=[]\n",
        "        for i in next_states:\n",
        "          Q_ns.append(self.target_net.forward(i))\n",
        "        #print(Q_ns)\n",
        "        maxQ=[]\n",
        "        for j in Q_ns:\n",
        "          maxQ.append(torch.max(j))\n",
        "        maxQ = torch.tensor(maxQ)\n",
        "        with torch.no_grad():\n",
        "          target_values = rewards+self.gamma*(1-dones)*maxQ\n",
        "        target_values.requires_grad = True\n",
        "        Q_ns=[]\n",
        "        for i in states:\n",
        "          Q_ns.append(self.online_net.forward(i))\n",
        "        maxQ=[]\n",
        "        for j in Q_ns:\n",
        "          maxQ.append(torch.max(j))\n",
        "        maxQ = torch.tensor(maxQ)\n",
        "        current_values = maxQ\n",
        "        current_values.requires_grad = True\n",
        "        loss = nn.functional.mse_loss(current_values, target_values)\n",
        "        optimizer = self.optimizerFn(self.online_net.parameters(), lr = self.optimizerLR)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "xghEqcdKuImO"
      },
      "outputs": [],
      "source": [
        "class DQN(DQN):\n",
        "    def updateNetwork(self):\n",
        "        #this function updates the onlineNetwork with the target network\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "        self.target_net.load_state_dict(self.online_net.state_dict())\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Jlu-WlgEuImO"
      },
      "outputs": [],
      "source": [
        "class DQN(DQN):\n",
        "    def evaluateAgent(self):\n",
        "        #this function evaluates the agent using the value network, it evaluates agent for MAX_EVAL_EPISODES\n",
        "        #typcially MAX_EVAL_EPISODES = 1\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #\n",
        "        finalEvalRewardsList = []\n",
        "        for _ in range(self.MAX_EVAL_EPISODES):\n",
        "          state = self.env.reset()\n",
        "          done = False\n",
        "          total_reward = 0\n",
        "          i=0\n",
        "          while not done and i<self.epochs:\n",
        "            i+=1\n",
        "            action = selectEpsilonGreedyAction(self.online_net,state,self.epsilon)\n",
        "            ns, r, done, _, info = self.env.step(action)\n",
        "            state = ns\n",
        "            total_reward += r\n",
        "          finalEvalRewardsList.append(total_reward)\n",
        "\n",
        "        return finalEvalRewardsList"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj2 = DQN(env1)\n",
        "obj2.runDQN()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Zxr6e4QFvbhK",
        "outputId": "e194de90-1c5e-440f-adea-9c9287191337"
      },
      "execution_count": 507,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ArrayRef: invalid index Index = 18446744073709551615; Length = 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-507-ab121041f6eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mobj2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobj2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-454-7c46c480be3b>\u001b[0m in \u001b[0;36mrunDQN\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#Your code goes in here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrainRewardsList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTimeList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalRewardsList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwallClockTimeList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmeanTrainRewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-506-3b45df904447>\u001b[0m in \u001b[0;36mtrainAgent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-478-9bc1b44f10dc>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mQ_ns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m           \u001b[0mQ_ns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monline_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mmaxQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQ_ns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-225-7d3945ac40cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m           \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: ArrayRef: invalid index Index = 18446744073709551615; Length = 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCV973ZauImP"
      },
      "source": [
        "## Double DQN (DDQN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQQnwn-uuImP"
      },
      "source": [
        "Implement the Double DQN agent. We have studied about Double DQN agent in the Lecture. Use the function definitions (given below).\n",
        "\n",
        "This class implements the Double DQN agent, you are required to implement the various methods of this class\n",
        "as outlined below. Note this class is generic and should work with any permissible Gym environment\n",
        "\n",
        "```\n",
        "class DDQN():\n",
        "    def __init__(env, seed, gamma,\n",
        "                 bufferSize,\n",
        "                 batchSize,\n",
        "                 optimizerFn,\n",
        "                 optimizerLR,\n",
        "                 MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn,\n",
        "                 explorationStrategyEvalFn,\n",
        "                 updateFrequency)\n",
        "    def initBookKeeping(self)\n",
        "    def performBookKeeping(self, train = True)\n",
        "    def runDDQN(self)\n",
        "    def trainAgent(self)\n",
        "    def trainNetwork(self, experiences)\n",
        "    def updateNetwork(self, onlineNet, targetNet)\n",
        "    def evaluateAgent(self)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "4Zuimo1EuImP"
      },
      "outputs": [],
      "source": [
        "class DDQN():\n",
        "    def __init__(self, env, seed=69, gamma=0.99,\n",
        "                 bufferSize=100,\n",
        "                 batchSize=50,\n",
        "                 optimizerFn=torch.optim.Adam,\n",
        "                 optimizerLR=0.01,\n",
        "                 MAX_TRAIN_EPISODES=MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES=MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn=None,\n",
        "                 explorationStrategyEvalFn=None,\n",
        "                 updateFrequency=5):\n",
        "        #this DDQN method\n",
        "        # 1. creates and initializes (with seed) the environment, train/eval episodes, gamma, etc.\n",
        "        # 2. creates and intializes all the variables required for book-keeping values via the initBookKeeping method\n",
        "        # 3. creates tareget and online Q-networks using the createValueNetwork above\n",
        "        # 4. creates and initializes (with network params) the optimizer function\n",
        "        # 5. sets the explorationStartegy variables/functions for train and evaluation\n",
        "        # 6. sets the batchSize for the number of experiences\n",
        "        # 7. Creates the replayBuffer\n",
        "\n",
        "        self.env = env\n",
        "        self.seed = seed\n",
        "        self.env.seed = self.seed\n",
        "        self.gamma = gamma\n",
        "        self.bufferSize = bufferSize\n",
        "        self.batchSize = batchSize\n",
        "        self.optimizerFn = optimizerFn\n",
        "        self.optimizerLR = optimizerLR\n",
        "        self.MAX_TRAIN_EPISODES = MAX_TRAIN_EPISODES\n",
        "        self.MAX_EVAL_EPISODES = MAX_EVAL_EPISODES\n",
        "        self.updateFrequency = updateFrequency\n",
        "        self.explorationStrategyTrainFn = explorationStrategyTrainFn\n",
        "        self.explorationStrategyEvalFn = explorationStrategyEvalFn\n",
        "        self.initBookKeeping()\n",
        "        self.online_net = createValueNetwork(inDim = np.size(env.reset()[0]), outDim=env.action_space.n)()\n",
        "        self.target_net = createValueNetwork(inDim = np.size(env.reset()[0]), outDim=env.action_space.n)()\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.epsilon_min = 0.01\n",
        "        self.buffer = ReplayBuffer(bufferSize)\n",
        "        return\n",
        "\n",
        "        #Your code goes in here\n",
        "\n",
        "        #Your code goes in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "-p2poZycuImP"
      },
      "outputs": [],
      "source": [
        "class DDQN(DDQN):\n",
        "    def initBookKeeping(self):\n",
        "        #this method creates and intializes all the variables required for book-keeping values and it is called\n",
        "        #init method\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "        self.trainRewardList=[]\n",
        "        self.trainTimeList = []\n",
        "        self.evalRewardList = []\n",
        "        self.wallClockTimeList = []\n",
        "        self.finalEvalReward = None\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "9q8jv5d8uImP"
      },
      "outputs": [],
      "source": [
        "class DDQN(DDQN):\n",
        "    def performBookKeeping(self, train = True):\n",
        "        #this method updates relevant variables for the bookKeeping, this can be called\n",
        "        #multiple times during training\n",
        "        #if you want you can print information using this, so it may help to monitor progress and also help to debug\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ad8TzMf-uImP"
      },
      "outputs": [],
      "source": [
        "class DDQN(DDQN):\n",
        "    def runDDQN(self):\n",
        "        #this is the main method, it trains the agent, performs bookkeeping while training and finally evaluates\n",
        "        #the agent and returns the following quantities:\n",
        "        #1. episode wise mean train rewards\n",
        "        #2. epsiode wise mean eval rewards\n",
        "        #2. episode wise trainTime (in seconds): time elapsed during training since the start of the first episode\n",
        "        #3. episode wise wallClockTime (in seconds): actual time elapsed since the start of training,\n",
        "        #                               note this will include time for BookKeeping and evaluation\n",
        "        # Note both trainTime and wallClockTime get accumulated as episodes proceed.\n",
        "\n",
        "        #Your code goes in here\n",
        "        trainRewardsList, trainTimeList, evalRewardsList, wallClockTimeList = self.trainAgent()\n",
        "\n",
        "        meanTrainRewards = []\n",
        "        meanEvalRewards = []\n",
        "        sum1=0\n",
        "        sum2=0\n",
        "        for i in range(len(trainRewardsList)):\n",
        "          sum1+=trainRewardsList[i]\n",
        "          meanTrainRewards.append(sum1/(i+1))\n",
        "        for i in range(len(evalRewardsList)):\n",
        "          sum2+=evalRewardsList[i]\n",
        "          meanEvalRewards.append(sum2/(i+1))\n",
        "\n",
        "        return meanTrainRewards, trainTimeList, meanEvalRewards, wallClockTimeList\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Hqn0nHSfuImP"
      },
      "outputs": [],
      "source": [
        "class DDQN(DDQN):\n",
        "    def trainAgent(self):\n",
        "        #this method collects experiences and trains the agent and does BookKeeping while training.\n",
        "        #this calls the trainNetwork() method internally, it also evaluates the agent per episode\n",
        "        #it trains the agent for MAX_TRAIN_EPISODES\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        i=0\n",
        "        for e in range(self.MAX_TRAIN_EPISODES):\n",
        "          i+=1\n",
        "          #print(\"Episode \",i)\n",
        "          start_time = time.time()\n",
        "          s = self.env.reset()[0]\n",
        "          done = False\n",
        "          total_reward = 0\n",
        "          j=0\n",
        "          total_reward = self.buffer.collectExperiences(self.env,self.online_net, s, self.epsilon, self.bufferSize)\n",
        "          if self.buffer.length()>=self.batchSize:\n",
        "            for j in range(100):\n",
        "              self.trainNetwork()\n",
        "\n",
        "\n",
        "          self.trainRewardList.append(total_reward)\n",
        "          self.trainTimeList.append(time.time()-start_time)\n",
        "          eval_reward = np.mean(self.evaluateAgent())\n",
        "          self.evalRewardList.append(eval_reward)\n",
        "\n",
        "          if self.finalEvalReward is None or eval_reward>self.finalEvalReward:\n",
        "            self.finalEvalReward = eval_reward\n",
        "\n",
        "          self.wallClockTimeList.append(time.time())\n",
        "\n",
        "          if e%self.updateFrequency:\n",
        "            self.updateNetwork()\n",
        "        return self.trainRewardList, self.trainTimeList, self.evalRewardList, self.wallClockTimeList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "SjStZtn4uImQ"
      },
      "outputs": [],
      "source": [
        "class DDQN(DDQN):\n",
        "    def trainNetwork(self):\n",
        "        # this method trains the value network epoch number of times and is called by the trainAgent function\n",
        "        # it essentially uses the experiences to calculate target, using the targets it calculates the error, which\n",
        "        # is further used for calulating the loss. It then uses the optimizer over the loss\n",
        "        # to update the params of the network by backpropagating through the network\n",
        "        # this function does not return anything\n",
        "        # you can try out other loss functions other than MSE like Huber loss, MAE, etc.\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        experiences = self.buffer\n",
        "        batch =self.buffer.sample(self.batchSize)\n",
        "        s, a, r, ns, dones = self.buffer.splitExperiences(batch)\n",
        "        states = torch.tensor(s)\n",
        "        actions = torch.tensor(a)\n",
        "        rewards = torch.tensor(r)\n",
        "        next_states = torch.tensor(ns)\n",
        "        dones = torch.tensor(dones)\n",
        "        done_b = []\n",
        "        for i in range(len(dones)):\n",
        "          done_b.append(1 if dones[i] else 0)\n",
        "        dones = torch.tensor(done_b)\n",
        "        Q_ns=[]\n",
        "        Q_ns2=[]\n",
        "        for i in next_states:\n",
        "          Q_ns.append(self.online_net.forward(i))\n",
        "        for i in next_states:\n",
        "          Q_ns2.append(self.target_net.forward(i))\n",
        "        maxAct=[]\n",
        "        for j in Q_ns:\n",
        "          maxAct.append(torch.argmax(j))\n",
        "        maxQ=[]\n",
        "        for j in range(len(Q_ns)):\n",
        "          maxQ.append(Q_ns2[j][maxAct[j]])\n",
        "        maxQ = torch.tensor(maxQ)\n",
        "        with torch.no_grad():\n",
        "          target_values = rewards+self.gamma*(1-dones)*maxQ\n",
        "        target_values.requires_grad = True\n",
        "        Q_ns=[]\n",
        "        for i in states:\n",
        "          Q_ns.append(self.online_net.forward(i))\n",
        "        maxQ=[]\n",
        "        for j in Q_ns:\n",
        "          maxQ.append(torch.max(j))\n",
        "        maxQ = torch.tensor(maxQ)\n",
        "        current_values = maxQ\n",
        "        current_values.requires_grad = True\n",
        "        loss = nn.functional.mse_loss(current_values, target_values)\n",
        "        optimizer = self.optimizerFn(self.online_net.parameters(), lr = self.optimizerLR)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "LaX0XpF8uImQ"
      },
      "outputs": [],
      "source": [
        "class DDQN(DDQN):\n",
        "    def updateNetwork(self):\n",
        "        #this function updates the onlineNetwork with the target network\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "        self.target_net.load_state_dict(self.online_net.state_dict())\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Im9wbMjguImQ"
      },
      "outputs": [],
      "source": [
        "class DDQN(DDQN):\n",
        "    def evaluateAgent(self):\n",
        "        #this function evaluates the agent using the value network, it evaluates agent for MAX_EVAL_EPISODES\n",
        "        #typcially MAX_EVAL_EPISODES = 1\n",
        "\n",
        "        #Your code goes in here\n",
        "        finalEvalRewardsList = []\n",
        "        for _ in range(self.MAX_EVAL_EPISODES):\n",
        "          state = self.env.reset()\n",
        "          done = False\n",
        "          total_reward = 0\n",
        "          i=0\n",
        "          while not done and i<100:\n",
        "            i+=1\n",
        "            action = selectEpsilonGreedyAction(self.online_net,state,self.epsilon)\n",
        "            ns, r, done, _, info = self.env.step(action)\n",
        "            state = ns\n",
        "            total_reward += r\n",
        "          finalEvalRewardsList.append(total_reward)\n",
        "\n",
        "        return finalEvalRewardsList"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj3 = DDQN(env1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b0havI4u2Y8r",
        "outputId": "dd18f76a-f843-46a3-9442-3e594a7c216a"
      },
      "execution_count": 670,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode  1\n",
            "Episode  2\n",
            "Episode  3\n",
            "Episode  4\n",
            "Episode  5\n",
            "Episode  6\n",
            "Episode  7\n",
            "Episode  8\n",
            "Episode  9\n",
            "Episode  10\n",
            "Episode  11\n",
            "Episode  12\n",
            "Episode  13\n",
            "Episode  14\n",
            "Episode  15\n",
            "Episode  16\n",
            "Episode  17\n",
            "Episode  18\n",
            "Episode  19\n",
            "Episode  20\n",
            "Episode  21\n",
            "Episode  22\n",
            "Episode  23\n",
            "Episode  24\n",
            "Episode  25\n",
            "Episode  26\n",
            "Episode  27\n",
            "Episode  28\n",
            "Episode  29\n",
            "Episode  30\n",
            "Episode  31\n",
            "Episode  32\n",
            "Episode  33\n",
            "Episode  34\n",
            "Episode  35\n",
            "Episode  36\n",
            "Episode  37\n",
            "Episode  38\n",
            "Episode  39\n",
            "Episode  40\n",
            "Episode  41\n",
            "Episode  42\n",
            "Episode  43\n",
            "Episode  44\n",
            "Episode  45\n",
            "Episode  46\n",
            "Episode  47\n",
            "Episode  48\n",
            "Episode  49\n",
            "Episode  50\n",
            "Episode  51\n",
            "Episode  52\n",
            "Episode  53\n",
            "Episode  54\n",
            "Episode  55\n",
            "Episode  56\n",
            "Episode  57\n",
            "Episode  58\n",
            "Episode  59\n",
            "Episode  60\n",
            "Episode  61\n",
            "Episode  62\n",
            "Episode  63\n",
            "Episode  64\n",
            "Episode  65\n",
            "Episode  66\n",
            "Episode  67\n",
            "Episode  68\n",
            "Episode  69\n",
            "Episode  70\n",
            "Episode  71\n",
            "Episode  72\n",
            "Episode  73\n",
            "Episode  74\n",
            "Episode  75\n",
            "Episode  76\n",
            "Episode  77\n",
            "Episode  78\n",
            "Episode  79\n",
            "Episode  80\n",
            "Episode  81\n",
            "Episode  82\n",
            "Episode  83\n",
            "Episode  84\n",
            "Episode  85\n",
            "Episode  86\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-670-67fb0d53dfca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobj3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-526-3bd33f79eaf5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, seed, gamma, bufferSize, batchSize, optimizerFn, optimizerLR, MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES, explorationStrategyTrainFn, explorationStrategyEvalFn, updateFrequency)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplayBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufferSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunDDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#Your code goes in here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-528-7d2d3031c69a>\u001b[0m in \u001b[0;36mrunDDQN\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#Your code goes in here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrainRewardsList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTimeList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalRewardsList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwallClockTimeList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmeanTrainRewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-584-140f14cae9cc>\u001b[0m in \u001b[0;36mtrainAgent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-530-1a47e6f785d2>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0mQ_ns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monline_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m           \u001b[0mQ_ns2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmaxAct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQ_ns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-225-7d3945ac40cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFh75IaeuImQ"
      },
      "source": [
        "## Dueling DDQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv5B2R_duImQ"
      },
      "source": [
        "Implement the Dueling Double Deep Q algorithm. We have studied about Dueling Double DQN agent in the Lecture. Use the function definitions (given below).\n",
        "\n",
        "This class implements the Dueling Double DQN agent, you are required to implement the various methods of this class\n",
        "as outlined below. Note this class is generic and should work with any permissible Gym environment\n",
        "\n",
        "```\n",
        "class D3QN():\n",
        "    def __init__(env, seed, gamma, tau,\n",
        "                 bufferSize,\n",
        "                 batchSize,\n",
        "                 optimizerFn,\n",
        "                 optimizerLR,\n",
        "                 MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn,\n",
        "                 explorationStrategyEvalFn,\n",
        "                 updateFrequency)\n",
        "    def initBookKeeping(self)\n",
        "    def performBookKeeping(self, train = True)\n",
        "    def runD3QN(self)\n",
        "    def trainAgent(self)\n",
        "    def trainNetwork(self, experiences)\n",
        "    def updateNetwork(self, onlineNet, targetNet)\n",
        "    def evaluateAgent(self)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "qeQxwam5uImQ"
      },
      "outputs": [],
      "source": [
        "class D3QN():\n",
        "    def __init__(self, env, seed=69, gamma=0.99, tau=10,\n",
        "                 bufferSize=100,\n",
        "                 batchSize=50,\n",
        "                 optimizerFn=torch.optim.Adam,\n",
        "                 optimizerLR=0.01,\n",
        "                 MAX_TRAIN_EPISODES=MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES=MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn=None,\n",
        "                 explorationStrategyEvalFn=None,\n",
        "                 updateFrequency=5):\n",
        "        #this D3QN method\n",
        "        # 1. creates and initializes (with seed) the environment, train/eval episodes, gamma, etc.\n",
        "        # 2. creates and intializes all the variables required for book-keeping values via the initBookKeeping method\n",
        "        # 3. creates tareget and online Q-networks using the createValueNetwork above\n",
        "        # 4. creates and initializes (with network params) the optimizer function\n",
        "        # 5. sets the explorationStartegy variables/functions for train and evaluation\n",
        "        # 6. sets the batchSize for the number of experiences\n",
        "        # 7. Creates the replayBuffer\n",
        "        self.env = env\n",
        "        self.seed = seed\n",
        "        self.env.seed = self.seed\n",
        "        self.gamma = gamma\n",
        "        self.bufferSize = bufferSize\n",
        "        self.batchSize = batchSize\n",
        "        self.optimizerFn = optimizerFn\n",
        "        self.optimizerLR = optimizerLR\n",
        "        self.MAX_TRAIN_EPISODES = MAX_TRAIN_EPISODES\n",
        "        self.MAX_EVAL_EPISODES = MAX_EVAL_EPISODES\n",
        "        self.explorationStrategyTrainFn = explorationStrategyTrainFn\n",
        "        self.explorationStrategyEvalFn = explorationStrategyEvalFn\n",
        "        self.updateFrequency = updateFrequency\n",
        "        self.initBookKeeping()\n",
        "        self.online_net = createDuelingNetwork(inDim=np.size(env.reset()[0]), outDim=env.action_space.n)()\n",
        "        self.target_net = createDuelingNetwork(inDim=np.size(env.reset()[0]), outDim=env.action_space.n)()\n",
        "        self.target_net.load_state_dict(self.online_net.state_dict())\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.epsilon_min = 0.01\n",
        "        self.buffer = ReplayBuffer(bufferSize)\n",
        "        return\n",
        "        #Your code goes in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "x3X4LC38uImQ"
      },
      "outputs": [],
      "source": [
        "class D3QN(D3QN):\n",
        "    def initBookKeeping(self):\n",
        "        #this method creates and intializes all the variables required for book-keeping values and it is called\n",
        "        #init method\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "        self.trainRewardList=[]\n",
        "        self.trainTimeList = []\n",
        "        self.evalRewardList = []\n",
        "        self.wallClockTimeList = []\n",
        "        self.finalEvalReward = None\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "o-SoygLGuImR"
      },
      "outputs": [],
      "source": [
        "class D3QN(D3QN):\n",
        "    def performBookKeeping(self, train = True):\n",
        "        #this method updates relevant variables for the bookKeeping, this can be called\n",
        "        #multiple times during training\n",
        "        #if you want you can print information using this, so it may help to monitor progress and also help to debug\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "PKsOB9XuuImR"
      },
      "outputs": [],
      "source": [
        "class D3QN(D3QN):\n",
        "    def runD3QN(self):\n",
        "        #this is the main method, it trains the agent, performs bookkeeping while training and finally evaluates\n",
        "        #the agent and returns the following quantities:\n",
        "        #1. episode wise mean train rewards\n",
        "        #2. epsiode wise mean eval rewards\n",
        "        #2. episode wise trainTime (in seconds): time elapsed during training since the start of the first episode\n",
        "        #3. episode wise wallClockTime (in seconds): actual time elapsed since the start of training,\n",
        "        #                               note this will include time for BookKeeping and evaluation\n",
        "        # Note both trainTime and wallClockTime get accumulated as episodes proceed.\n",
        "\n",
        "        #Your code goes in here\n",
        "        trainRewardsList, trainTimeList, evalRewardsList, wallClockTimeList = self.trainAgent()\n",
        "\n",
        "        meanTrainRewards = []\n",
        "        meanEvalRewards = []\n",
        "        sum1=0\n",
        "        sum2=0\n",
        "        for i in range(len(trainRewardsList)):\n",
        "          sum1+=trainRewardsList[i]\n",
        "          meanTrainRewards.append(sum1/(i+1))\n",
        "        for i in range(len(evalRewardsList)):\n",
        "          sum2+=evalRewardsList[i]\n",
        "          meanEvalRewards.append(sum2/(i+1))\n",
        "\n",
        "        return meanTrainRewards, trainTimeList, meanEvalRewards, wallClockTimeList\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "uBXAw5VnuImR"
      },
      "outputs": [],
      "source": [
        "class D3QN(D3QN):\n",
        "    def trainAgent(self):\n",
        "        #this method collects experiences and trains the agent and does BookKeeping while training.\n",
        "        #this calls the trainNetwork() method internally, it also evaluates the agent per episode\n",
        "        #it trains the agent for MAX_TRAIN_EPISODES\n",
        "\n",
        "        #Your code goes in here\n",
        "        i=0\n",
        "        for e in range(self.MAX_TRAIN_EPISODES):\n",
        "          i+=1\n",
        "          #print(\"Episode \",i)\n",
        "          start_time = time.time()\n",
        "          s = self.env.reset()[0]\n",
        "          done = False\n",
        "          total_reward = 0\n",
        "          j=0\n",
        "          total_reward = self.buffer.collectExperiences(self.env,self.online_net, s, self.epsilon, self.bufferSize)\n",
        "          if self.buffer.length()>=self.batchSize:\n",
        "            for j in range(100):\n",
        "              self.trainNetwork()\n",
        "\n",
        "\n",
        "          self.trainRewardList.append(total_reward)\n",
        "          self.trainTimeList.append(time.time()-start_time)\n",
        "          eval_reward = np.mean(self.evaluateAgent())\n",
        "          self.evalRewardList.append(eval_reward)\n",
        "\n",
        "          if self.finalEvalReward is None or eval_reward>self.finalEvalReward:\n",
        "            self.finalEvalReward = eval_reward\n",
        "\n",
        "          self.wallClockTimeList.append(time.time())\n",
        "\n",
        "          if e%self.updateFrequency:\n",
        "            self.updateNetwork()\n",
        "\n",
        "        return self.trainRewardList, self.trainTimeList, self.evalRewardList, self.wallClockTimeList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "nqLEk5IsuImR"
      },
      "outputs": [],
      "source": [
        "class D3QN(D3QN):\n",
        "    def trainNetwork(self):\n",
        "        # this method trains the value network epoch number of times and is called by the trainAgent function\n",
        "        # it essentially uses the experiences to calculate target, using the targets it calculates the error, which\n",
        "        # is further used for calulating the loss. It then uses the optimizer over the loss\n",
        "        # to update the params of the network by backpropagating through the network\n",
        "        # this function does not return anything\n",
        "        # you can try out other loss functions other than MSE like Huber loss, MAE, etc.\n",
        "\n",
        "        #Your code goes in here\n",
        "        experiences = self.buffer\n",
        "        batch =self.buffer.sample(self.batchSize)\n",
        "        s, a, r, ns, dones = self.buffer.splitExperiences(batch)\n",
        "        states = torch.tensor(s)\n",
        "        actions = torch.tensor(a)\n",
        "        rewards = torch.tensor(r)\n",
        "        next_states = torch.tensor(ns)\n",
        "        dones = torch.tensor(dones)\n",
        "        done_b = []\n",
        "        for i in range(len(dones)):\n",
        "          done_b.append(1 if dones[i] else 0)\n",
        "        dones = torch.tensor(done_b)\n",
        "        Q_ns=[]\n",
        "        Q_ns2=[]\n",
        "        for i in next_states:\n",
        "          Q_ns.append(self.online_net.forward(i))\n",
        "        for i in next_states:\n",
        "          Q_ns2.append(self.target_net.forward(i))\n",
        "        maxAct=[]\n",
        "        for j in Q_ns:\n",
        "          maxAct.append(torch.argmax(j))\n",
        "        maxQ=[]\n",
        "        for j in range(len(Q_ns)):\n",
        "          maxQ.append(Q_ns2[j][maxAct[j]])\n",
        "        maxQ = torch.tensor(maxQ)\n",
        "        with torch.no_grad():\n",
        "          target_values = rewards+self.gamma*(1-dones)*maxQ\n",
        "        target_values.requires_grad = True\n",
        "        Q_ns=[]\n",
        "        for i in states:\n",
        "          Q_ns.append(self.online_net.forward(i))\n",
        "        maxQ=[]\n",
        "        for j in Q_ns:\n",
        "          maxQ.append(torch.max(j))\n",
        "        maxQ = torch.tensor(maxQ)\n",
        "        current_values = maxQ\n",
        "        current_values.requires_grad = True\n",
        "        loss = nn.functional.mse_loss(current_values, target_values)\n",
        "        optimizer = self.optimizerFn(self.online_net.parameters(), lr = self.optimizerLR)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "hAmKSZ2uuImR"
      },
      "outputs": [],
      "source": [
        "class D3QN(D3QN):\n",
        "    def updateNetwork(self):\n",
        "        #this function updates the onlineNetwork with the target network using Polyak averaging\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "        self.target_net.load_state_dict(self.online_net.state_dict())\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "2SAt6Ib1uImR"
      },
      "outputs": [],
      "source": [
        "class D3QN(D3QN):\n",
        "    def evaluateAgent(self):\n",
        "        #this function evaluates the agent using the value network, it evaluates agent for MAX_EVAL_EPISODES\n",
        "        #typcially MAX_EVAL_EPISODES = 1\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        finalEvalRewardsList = []\n",
        "        for _ in range(self.MAX_EVAL_EPISODES):\n",
        "          state = self.env.reset()\n",
        "          done = False\n",
        "          total_reward = 0\n",
        "          i=0\n",
        "          while not done and i<100:\n",
        "            i+=1\n",
        "            action = selectEpsilonGreedyAction(self.online_net,state,self.epsilon)\n",
        "            ns, r, done, _, info = self.env.step(action)\n",
        "            state = ns\n",
        "            total_reward += r\n",
        "          finalEvalRewardsList.append(total_reward)\n",
        "\n",
        "        return finalEvalRewardsList"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj4 = D3QN(env1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHpbc_hn9610",
        "outputId": "618f5f12-f4d5-4aa1-ff2f-af5dac90b36b"
      },
      "execution_count": 604,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode  1\n",
            "Episode  2\n",
            "Episode  3\n",
            "Episode  4\n",
            "Episode  5\n",
            "Episode  6\n",
            "Episode  7\n",
            "Episode  8\n",
            "Episode  9\n",
            "Episode  10\n",
            "Episode  11\n",
            "Episode  12\n",
            "Episode  13\n",
            "Episode  14\n",
            "Episode  15\n",
            "Episode  16\n",
            "Episode  17\n",
            "Episode  18\n",
            "Episode  19\n",
            "Episode  20\n",
            "Episode  21\n",
            "Episode  22\n",
            "Episode  23\n",
            "Episode  24\n",
            "Episode  25\n",
            "Episode  26\n",
            "Episode  27\n",
            "Episode  28\n",
            "Episode  29\n",
            "Episode  30\n",
            "([45.0, 50.5, 40.333333333333336, 33.5, 29.4, 27.333333333333332, 25.142857142857142, 27.375, 32.44444444444444, 31.8, 29.90909090909091, 29.083333333333332, 29.0, 27.928571428571427, 27.066666666666666, 28.6875, 28.11764705882353, 27.38888888888889, 26.57894736842105, 26.2, 26.047619047619047, 27.0, 26.26086956521739, 25.875, 25.92, 25.576923076923077, 25.185185185185187, 25.464285714285715, 25.06896551724138, 24.9], [0.02047896385192871, 3.81558895111084, 4.0150041580200195, 4.150068283081055, 3.998572826385498, 4.8023576736450195, 4.036288499832153, 4.1797707080841064, 5.399410009384155, 4.338858127593994, 4.398319482803345, 4.509273052215576, 4.016475200653076, 4.587686777114868, 4.1728575229644775, 4.511591911315918, 4.862165927886963, 4.0498716831207275, 3.999936580657959, 4.639646053314209, 4.291909456253052, 5.087352275848389, 4.574954509735107, 4.1092307567596436, 4.674091815948486, 3.97749662399292, 4.595623731613159, 4.530880689620972, 4.096762418746948, 4.882975101470947], [23.2, 22.35, 24.333333333333332, 25.275, 25.939999999999998, 25.25, 24.24285714285714, 24.5625, 25.033333333333335, 24.45, 24.263636363636362, 23.866666666666664, 23.584615384615383, 23.564285714285713, 23.439999999999998, 23.381249999999998, 23.4, 23.166666666666664, 23.357894736842102, 23.244999999999997, 22.957142857142856, 23.186363636363634, 22.97391304347826, 22.837500000000002, 22.58, 22.626923076923074, 22.48148148148148, 22.267857142857142, 22.29655172413793, 22.203333333333333], [1711261655.8919938, 1711261659.762627, 1711261663.8775377, 1711261668.1081698, 1711261672.1825593, 1711261677.0442402, 1711261681.1383555, 1711261685.3979568, 1711261690.8972323, 1711261695.3002446, 1711261699.7901309, 1711261704.357225, 1711261708.4313264, 1711261713.0853689, 1711261717.3173306, 1711261721.8946595, 1711261726.830454, 1711261730.9419565, 1711261735.0714927, 1711261739.7681413, 1711261744.1106565, 1711261749.2835128, 1711261753.9102182, 1711261758.0767035, 1711261762.7969258, 1711261766.8561823, 1711261771.5231256, 1711261776.1008148, 1711261780.2618613, 1711261785.1992474])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eldLG7kquImR"
      },
      "source": [
        "## Dueling Double Deep Q Network with Prioritized Experience Replay (D3QN-PER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB38zmJ6uImS"
      },
      "source": [
        "Implement the Dueling Double DQN with Prioritized Experience Replay (D3QN-PER) agent. We have studied about D3QN-PER agent in the Lecture. Use the function definitions (given below).\n",
        "\n",
        "This class implements the D3QN-PER agent, you are required to implement the various methods of this class\n",
        "as outlined below. Note this class is generic and should work with any permissible Gym environment\n",
        "\n",
        "```\n",
        "class D3QN_PER():\n",
        "    def __init__(env, seed, gamma, tau, alpha, beta, beta_rate,\n",
        "                 bufferSize,\n",
        "                 batchSize,\n",
        "                 optimizerFn,\n",
        "                 optimizerLR,\n",
        "                 MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn,\n",
        "                 explorationStrategyEvalFn,\n",
        "                 updateFrequency)\n",
        "    def initBookKeeping(self)\n",
        "    def performBookKeeping(self, train = True)\n",
        "    def runD3QN_PER(self)\n",
        "    def trainAgent(self)\n",
        "    def trainNetwork(self, experiences)\n",
        "    def updateNetwork(self, onlineNet, targetNet)\n",
        "    def evaluateAgent(self)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6kh3Vp1uImS"
      },
      "outputs": [],
      "source": [
        "class D3QN_PER():\n",
        "    def __init__(env, seed, gamma, tau, alpha, beta, beta_rate,\n",
        "                 bufferSize,\n",
        "                 batchSize,\n",
        "                 optimizerFn,\n",
        "                 optimizerLR,\n",
        "                 MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn,\n",
        "                 explorationStrategyEvalFn,\n",
        "                 updateFrequency):\n",
        "        #this D3QN method\n",
        "        # 1. creates and initializes (with seed) the environment, train/eval episodes, gamma, etc.\n",
        "        # 2. creates and intializes all the variables required for book-keeping values via the initBookKeeping method\n",
        "        # 3. creates tareget and online Q-networks using the createValueNetwork above\n",
        "        # 4. creates and initializes (with network params) the optimizer function\n",
        "        # 5. sets the explorationStartegy variables/functions for train and evaluation\n",
        "        # 6. sets the batchSize for the number of experiences\n",
        "        # 7. Creates the replayBuffer,\n",
        "        #    the replayBuffer takes the parameters bufferSize, alpha, beta and beta_rate\n",
        "        #\n",
        "        # Your code goes in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7bBEjBXuImT"
      },
      "outputs": [],
      "source": [
        "class D3QN_PER(D3QN_PER):\n",
        "    def initBookKeeping(self):\n",
        "        #this method creates and intializes all the variables required for book-keeping values and it is called\n",
        "        #init method\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PRzTGXGuImT"
      },
      "outputs": [],
      "source": [
        "class D3QN_PER(D3QN_PER):\n",
        "    def performBookKeeping(self, train = True):\n",
        "        #this method updates relevant variables for the bookKeeping, this can be called\n",
        "        #multiple times during training\n",
        "        #if you want you can print information using this, so it may help to monitor progress and also help to debug\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgQv1psFuImT"
      },
      "outputs": [],
      "source": [
        "class D3QN_PER(D3QN_PER):\n",
        "    def runD3QN_PER(self):\n",
        "        #this is the main method, it trains the agent, performs bookkeeping while training and finally evaluates\n",
        "        #the agent and returns the following quantities:\n",
        "        #1. episode wise mean train rewards\n",
        "        #2. epsiode wise mean eval rewards\n",
        "        #2. episode wise trainTime (in seconds): time elapsed during training since the start of the first episode\n",
        "        #3. episode wise wallClockTime (in seconds): actual time elapsed since the start of training,\n",
        "        #                               note this will include time for BookKeeping and evaluation\n",
        "        # Note both trainTime and wallClockTime get accumulated as episodes proceed.\n",
        "        #\n",
        "        # Your code goes in here\n",
        "\n",
        "        return trainRewardsList, trainTimeList, evalRewardsList, wallClockTimeList, finalEvalReward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhvbPhH2uImT"
      },
      "outputs": [],
      "source": [
        "class D3QN_PER(D3QN_PER):\n",
        "    def trainAgent(self):\n",
        "        #this method collects experiences and trains the agent and does BookKeeping while training.\n",
        "        #this calls the trainNetwork() method internally, it also evaluates the agent per episode\n",
        "        #it trains the agent for MAX_TRAIN_EPISODES\n",
        "        #\n",
        "        #Your code goes in here\n",
        "\n",
        "        return trainRewardsList, trainTimeList, evalRewardsList, wallClockTimeList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxZn3t75uImT"
      },
      "outputs": [],
      "source": [
        "class D3QN_PER(D3QN_PER):\n",
        "    def trainNetwork(self, experiences):\n",
        "        # this method trains the value network epoch number of times and is called by the trainAgent function\n",
        "        # it essentially uses the experiences to calculate target, using the targets it calculates the error, which\n",
        "        # is further used for calulating the loss. It then uses the optimizer over the loss\n",
        "        # to update the params of the network by backpropagating through the network\n",
        "        # this function does not return anything\n",
        "        # you can try out other loss functions other than MSE like Huber loss, MAE, etc.\n",
        "        #\n",
        "        #Your code goes in here\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilBAYqAkuImT"
      },
      "outputs": [],
      "source": [
        "class D3QN_PER(D3QN_PER):\n",
        "    def updateNetwork(self, onlineNet, targetNet):\n",
        "        #this function updates the onlineNetwork with the target network using Polyak averaging \\\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        #\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D158X4siuImU"
      },
      "outputs": [],
      "source": [
        "class D3QN_PER(D3QN_PER):\n",
        "    def evaluateAgent(self):\n",
        "        #this function evaluates the agent using the value network, it evaluates agent for MAX_EVAL_EPISODES\n",
        "        #typcially MAX_EVAL_EPISODES = 1\n",
        "        #\n",
        "        #Your code goes in here\n",
        "\n",
        "        return finalEvalRewardsList"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUBns1tkuImU"
      },
      "source": [
        "# Deep Policy Based RL agents.\n",
        "<a id=\"deep-policy-based\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwMT1xmQuImU"
      },
      "source": [
        "### The purpose of this part is to learn about different Deep Policy Based RL agents.\n",
        "\n",
        "In this part of the assignment you will be implementing Deep Policy based RL algorithms we learnt in Lectures. Namely, we will be implementing REINFORCE and VPG.\n",
        "\n",
        "For all the algorithms below, this time we will not be specifying the hyper-parameters, please play with the hyper-params to come up with the best values. This way you will learn to tune the model. Some of the values were specified in the lecture, that would be a good starting point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt833D1IuImU"
      },
      "source": [
        "## REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVOd1CzbuImU"
      },
      "source": [
        "Implement the REINFORCE algorithm. We have studied about REINFORCE algorithm in the Lecture. Use the function definitions (given below).\n",
        "\n",
        "This class implements the REINFORCE Agent, you are required to implement the various methods of this class\n",
        "as outlined below. Note this class is generic and should work with any permissible Gym environment\n",
        "\n",
        "```\n",
        "class REINFORCE():\n",
        "    def __init__(env, seed, gamma,\n",
        "                 optimizerFn,\n",
        "                 optimizerLR,\n",
        "                 MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn,\n",
        "                 explorationStrategyEvalFn)\n",
        "    def initBookKeeping(self)\n",
        "    def performBookKeeping(self, train = True)\n",
        "    def runREINFORCE(self)\n",
        "    def trainAgent(self)\n",
        "    def trainPolicyNetwork(self, experiences)\n",
        "    def evaluateAgent(self)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRB1xpG7uImU"
      },
      "source": [
        "### Implement the methods for the REINFORCE class below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Q9-VDrShuImU"
      },
      "outputs": [],
      "source": [
        "class REINFORCE():\n",
        "    def __init__(self, env, seed=69, gamma=0.99, optimizerFn=torch.optim.Adam,\n",
        "             optimizerLR=0.01,\n",
        "             MAX_TRAIN_EPISODES = MAX_TRAIN_EPISODES,\n",
        "             MAX_EVAL_EPISODES = MAX_EVAL_EPISODES, epsilon=epsilon):\n",
        "      self.env = env\n",
        "      self.seed=seed\n",
        "      self.env.seed = self.seed\n",
        "      self.gamma = gamma\n",
        "      self.optimizerFn = optimizerFn\n",
        "      self.optimizerLR = optimizerLR\n",
        "      self.MAX_TRAIN_EPISODES = MAX_TRAIN_EPISODES\n",
        "      self.MAX_EVAL_EPISODES = MAX_EVAL_EPISODES\n",
        "      self.initBookKeeping()\n",
        "      self.policy_net = createPolicyNetwork(inDim=np.size(env.reset()[0]), outDim=env.action_space.n)()\n",
        "      self.optimizer = self.optimizerFn(self.policy_net.parameters(), lr=self.optimizerLR)\n",
        "      self.epsilon = epsilon\n",
        "      return self.runREINFORCE()\n",
        "\n",
        "    def initBookKeeping(self):\n",
        "      self.trainRewardList = []\n",
        "      self.evalRewardList = []\n",
        "      self.trainTimeList = []\n",
        "      self.wallClockTimeList = []\n",
        "      self.finalEvalReward=None\n",
        "\n",
        "    def runREINFORCE(self):\n",
        "      trainRewardsList, trainTimeList, evalRewardsList, wallClockTimeList = self.trainAgent()\n",
        "\n",
        "      meanTrainRewards = []\n",
        "      meanEvalRewards = []\n",
        "      sum1=0\n",
        "      sum2=0\n",
        "      for i in range(len(trainRewardsList)):\n",
        "        sum1+=trainRewardsList[i]\n",
        "        meanTrainRewards.append(sum1/(i+1))\n",
        "      for i in range(len(evalRewardsList)):\n",
        "        sum2+=evalRewardsList[i]\n",
        "        meanEvalRewards.append(sum2/(i+1))\n",
        "\n",
        "      return meanTrainRewards, trainTimeList, meanEvalRewards, wallClockTimeList\n",
        "\n",
        "\n",
        "    def trainAgent(self):\n",
        "      self.initBookKeeping()\n",
        "      for e in range(self.MAX_TRAIN_EPISODES):\n",
        "        #print(\"Episode \",e)\n",
        "        start_time = time.time()\n",
        "        s = self.env.reset()[0]\n",
        "        done=False\n",
        "        rewards = []\n",
        "        logProbs = []\n",
        "        i=0\n",
        "        total_reward=0\n",
        "        while not done and i<=100:\n",
        "          i+=1\n",
        "          a, logp_a = self.policy_net.selectAction(s)\n",
        "          s, r, done, truncated, info = env.step(a)\n",
        "          rewards.append(r)\n",
        "          logProbs.append(logp_a)\n",
        "          total_reward+=r\n",
        "\n",
        "        self.trainPolicyNetwork(rewards, logProbs)\n",
        "\n",
        "        self.trainRewardList.append(total_reward)\n",
        "        self.trainTimeList.append(time.time()-start_time)\n",
        "        eval_reward = np.mean(self.evaluateAgent(self.policy_net))\n",
        "        self.evalRewardList.append(eval_reward)\n",
        "\n",
        "        if self.finalEvalReward is None or eval_reward>self.finalEvalReward:\n",
        "            self.finalEvalReward = eval_reward\n",
        "\n",
        "        self.wallClockTimeList.append(time.time())\n",
        "      return self.trainRewardList, self.trainTimeList, self.evalRewardList, self.wallClockTimeList\n",
        "\n",
        "\n",
        "    def trainPolicyNetwork(self, rewards, logProbs):\n",
        "      returns, gammas = self.getStepWiseReturnsandDiscounts(gamma, rewards)\n",
        "      policyLoss = torch.Tensor(-1*gammas*returns*logProbs)\n",
        "      policyLoss.requires_grad = True\n",
        "      policyLoss = torch.mean(policyLoss)\n",
        "      self.optimizer.zero_grad()\n",
        "      policyLoss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "    def getStepWiseReturnsandDiscounts(self,gamma,rewards):\n",
        "      returns=[]\n",
        "      Gt=0\n",
        "      gammas=[]\n",
        "      i=0\n",
        "      for reward in rewards:\n",
        "        i+=1\n",
        "        Gt=reward+gamma*Gt\n",
        "        returns.insert(0,Gt)\n",
        "        gammas.append(gamma**(i-1))\n",
        "      returns = np.array(returns)\n",
        "      gammas = np.array(gammas)\n",
        "\n",
        "      return gammas, returns\n",
        "\n",
        "\n",
        "    def evaluateAgent(self,pNet):\n",
        "      rewards=[]\n",
        "      for e in range(self.MAX_EVAL_EPISODES):\n",
        "        rs=0\n",
        "        s=self.env.reset()[0]\n",
        "        done=False\n",
        "        i=0\n",
        "        while not done and i<=100:\n",
        "          i+=1\n",
        "          action = selectEpsilonGreedyAction(self.policy_net,s,self.epsilon)\n",
        "          ns, r, done, _, info = self.env.step(action)\n",
        "          s = ns\n",
        "          rs += r\n",
        "\n",
        "        rewards.append(rs)\n",
        "\n",
        "      return rewards\n",
        "\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 676,
      "metadata": {
        "id": "81yQoXz2uImV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6813739c-25c2-43b3-e698-824bf81cbbbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode  0\n",
            "Episode  1\n",
            "Episode  2\n",
            "Episode  3\n",
            "Episode  4\n",
            "Episode  5\n",
            "Episode  6\n",
            "Episode  7\n",
            "Episode  8\n",
            "Episode  9\n",
            "Episode  10\n",
            "Episode  11\n",
            "Episode  12\n",
            "Episode  13\n",
            "Episode  14\n",
            "Episode  15\n",
            "Episode  16\n",
            "Episode  17\n",
            "Episode  18\n",
            "Episode  19\n",
            "Episode  20\n",
            "Episode  21\n",
            "Episode  22\n",
            "Episode  23\n",
            "Episode  24\n",
            "Episode  25\n",
            "Episode  26\n",
            "Episode  27\n",
            "Episode  28\n",
            "Episode  29\n",
            "([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0026204586029052734, 0.0019121170043945312, 0.0016145706176757812, 0.0017242431640625, 0.001847982406616211, 0.0025398731231689453, 0.002969980239868164, 0.002635478973388672, 0.0020678043365478516, 0.002105712890625, 0.0020411014556884766, 0.0029540061950683594, 0.0019142627716064453, 0.0018565654754638672, 0.0018770694732666016, 0.001779317855834961, 0.0014028549194335938, 0.0024454593658447266, 0.0024161338806152344, 0.0018422603607177734, 0.002504110336303711, 0.002451181411743164, 0.0020990371704101562, 0.0024046897888183594, 0.002438783645629883, 0.002414226531982422, 0.002784252166748047, 0.0025000572204589844, 0.0024573802947998047, 0.0024590492248535156], [15.2, 15.149999999999999, 14.633333333333333, 14.325, 14.279999999999998, 13.699999999999998, 13.657142857142857, 13.6625, 13.511111111111111, 13.84, 13.772727272727273, 14.0, 14.161538461538461, 14.12142857142857, 13.979999999999999, 14.125, 14.152941176470588, 14.011111111111111, 14.021052631578947, 14.054999999999998, 14.004761904761903, 13.954545454545451, 13.986956521739128, 14.045833333333329, 14.079999999999995, 14.080769230769228, 14.040740740740738, 14.107142857142852, 14.110344827586202, 14.066666666666663], [1711269305.6435857, 1711269305.677473, 1711269305.7182791, 1711269305.752511, 1711269305.8050044, 1711269305.8394835, 1711269305.8723302, 1711269305.9195013, 1711269305.9578662, 1711269306.0093074, 1711269306.051129, 1711269306.1015654, 1711269306.1508887, 1711269306.1918278, 1711269306.2321558, 1711269306.2801683, 1711269306.307549, 1711269306.3273764, 1711269306.3738108, 1711269306.4029913, 1711269306.4259195, 1711269306.452179, 1711269306.4768026, 1711269306.5014179, 1711269306.5288687, 1711269306.5558946, 1711269306.5783608, 1711269306.6065474, 1711269306.6305196, 1711269306.6525626])\n"
          ]
        }
      ],
      "source": [
        "obj5  = REINFORCE(env1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPRIs7h7uImV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gaUFRNYuImV"
      },
      "outputs": [],
      "source": [
        "# def runREINFORCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fu-6SCMuImV"
      },
      "outputs": [],
      "source": [
        "# def trainAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmz_MSkWuImV"
      },
      "outputs": [],
      "source": [
        "# def trainPolicyNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQoLXAGouImV"
      },
      "outputs": [],
      "source": [
        "# def evaluateAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QxkAbhvuImV"
      },
      "source": [
        "## Vanilla Policy Gradient (VPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do-Cb5zquImW"
      },
      "source": [
        "Implement the VPG algorithm. We have studied about VPG algorithm in the Lecture. Use the function definitions (given below).\n",
        "\n",
        "This class implements the VPG Agent, you are required to implement the various methods of this class\n",
        "as outlined below. Note this class is generic and should work with any permissible Gym environment\n",
        "\n",
        "```\n",
        "class VPG():\n",
        "    def __init__(env, seed, gamma, beta,\n",
        "                 optimizerFn,\n",
        "                 optimizerLR,\n",
        "                 MAX_TRAIN_EPISODES, MAX_EVAL_EPISODES,\n",
        "                 explorationStrategyTrainFn,\n",
        "                 explorationStrategyEvalFn)\n",
        "    def initBookKeeping(self)\n",
        "    def performBookKeeping(self, train = True)\n",
        "    def runVPG(self)\n",
        "    def trainAgent(self)\n",
        "    def trainPolicyNetwork(self, experiences)\n",
        "    def evaluateAgent(self)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNsAVOnKuImW"
      },
      "outputs": [],
      "source": [
        "# def __init__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QykXTE_MuImW"
      },
      "outputs": [],
      "source": [
        "# def initBookKeeping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTEtzdHquImW"
      },
      "outputs": [],
      "source": [
        "# def performBookKeeping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ms9zqhouImW"
      },
      "outputs": [],
      "source": [
        "# def runVPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zi_mX-XuImW"
      },
      "outputs": [],
      "source": [
        "# def trainAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KsYt8ZBuImW"
      },
      "outputs": [],
      "source": [
        "# def trainPolicyNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hmy9elfUuImW"
      },
      "outputs": [],
      "source": [
        "# def evaluateAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJDZO1FuImW"
      },
      "source": [
        "# Experiments and Plots\n",
        "<a id=\"experiments\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB0u6orfuImX"
      },
      "source": [
        "Run the NFQ, DQN, Double DQN, Dueling Double DQN, Dueling Double Deep Q Network with Prioritized Experience Replay, REINFORCE and VPG agent on CartPole environment and MountainCar enviroment.\n",
        "\n",
        "Plot the following for each of the environment separately. Note based on different hyper-parameters and stratgies you use, can you have multiple plots for each of the below.\n",
        "\n",
        "As you are aware from your past experience, single run of the agent over the environment results in plots that have lot of variance and look very noisy. One way to overcome this is to create several different instances of the environment using different seeds and then average out the results across these and plot these. For all the plots below, you this strategy. You need to run 5 different instances of the environment for each agent. As you have seen in the lecture slides, we plot the maximum and minimum values around the mean in the plots, so this gives us the shaded plot with the mean curve in the between. In this assignment, you are required to do the same. Generate plots with envelop between maximum and minimum value (check the plotQuantity() function in the helper functions).\n",
        "\n",
        "For each of the quantity of interest, plot each of the agent within the same plot using different colors for the envelop. Choose colors such that that there is clear contrast between the plots corresponding to different agents.\n",
        "\n",
        "1. Plot mean train rewards vs episodes for Cartpole environment.\n",
        "2. Plot mean train rewards vs episodes for MountatinCar environment.\n",
        "3. Plot mean evaluation rewards vs episodes\n",
        "4. Plot mean evaluation rewards vs episodes\n",
        "5. Plot total steps vs episode for Cartpole environment.\n",
        "6. Plot total steps vs episode for MountatinCar environment.\n",
        "7. Plot train time vs episode for Cartpole environment.\n",
        "8. Plot train time vs episode for MountatinCar environment.\n",
        "9. Plot wall clock time vs episode for Cartpole environment.\n",
        "10. Plot wall clock time vs episode for MountatinCar environment.\n",
        "11. Based on plots for CartPole environment, what are your observations about different agents. Compare different agents.  \n",
        "12. Based on plots for MountainCar environment, what are your observations about different agents. Compare different agents. Do these observations concur with the ones for CartPole environment?\n",
        "13. Based on both the environments, can you generalize some of the findings for the value-based agents? If yes what are those findings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGRjzgD1uImX"
      },
      "outputs": [],
      "source": [
        "def runDeepValueBasedAgents():\n",
        "    # this function will initialize 5 different instances of the env (using different seeds), run all the agents\n",
        "    # over these different instances. Collects results and generate the plots state above.\n",
        "    # generate your plots in the cells below\n",
        "    # write the answers to part 11, 12 and 13 in the cells below the plot-cells.\n",
        "    envs1 = []\n",
        "    envs2 = []\n",
        "    for i in range(5):\n",
        "      envs1.append(gym.make('CartPole-v0'))\n",
        "      envs2.append(gym.make('MountainCar-v0'))\n",
        "\n",
        "    NFQdict={}\n",
        "    DQNdict={}\n",
        "    DDQNdict = {}\n",
        "    D3QNdict = {}\n",
        "    for i in range(5):\n",
        "      seed=random.randint(0,100)\n",
        "      NFQdict[i] = NFQ(envs1[i],seed=seed)\n",
        "      NFQdict[i] = NFQdict[i].runNFQ()\n",
        "      DQNdict[i] = DQN(envs1[i],seed=seed)\n",
        "      DQNdict[i] = DQNdict[i].runDQN()\n",
        "      DDQNdict[i] = DDQN(envs1[i], seed=seed)\n",
        "      DDQNdict[i] = DDQNdict[i].runDDQN()\n",
        "      D3QNdict[i] = D3QN(envs1[i], seed = seed)\n",
        "      D3QNdict[i] = D3QNdict[i].runD3QN()\n",
        "\n",
        "    NFQ_plot1 = {}\n",
        "    DQN_plot1 = {}\n",
        "    DDQN_plot1 ={}\n",
        "    D3QN_plot1 = {}\n",
        "    for i in range(5):\n",
        "      NFQ_plot1[i] = NFQdict[i][0]\n",
        "      DQN_plot1[i] = DQNdict[i][0]\n",
        "      DDQN_plot1[i] = DDQNdict[i][0]\n",
        "      D3QN_plot1[i] = D3QNdict[i][0]\n",
        "\n",
        "    plotQuantity(NFQ_plot1, len(NFQ_plot1[0]), \"Mean Train Rewards vs Episodes in NFQ in CartPole\")\n",
        "    plotQuantity(DQN_plot1, len(DQN_plot1[0]), \"Mean Train Rewards vs Episodes in DQN in CartPole\")\n",
        "    plotQuantity(DDQN_plot1, len(DDQN_plot1[0]), \"Mean Train Rewards vs Episodes in DDQN in CartPole\")\n",
        "    plotQuantity(D3QN_plot1, len(D3QN_plot1[0]), \"Mean Train Rewards vs Episodes in D3QN in CartPole\")\n",
        "\n",
        "    NFQ_plot1 = {}\n",
        "    DQN_plot1 = {}\n",
        "    DDQN_plot1 ={}\n",
        "    D3QN_plot1 = {}\n",
        "    for i in range(5):\n",
        "      NFQ_plot1[i] = NFQdict[i][2]\n",
        "      DQN_plot1[i] = DQNdict[i][2]\n",
        "      DDQN_plot1[i] = DDQNdict[i][2]\n",
        "      D3QN_plot1[i] = D3QNdict[i][2]\n",
        "\n",
        "    plotQuantity(NFQ_plot1, len(NFQ_plot1[0]), \"Mean Eval Rewards vs Episodes in NFQ in CartPole\")\n",
        "    plotQuantity(DQN_plot1, len(DQN_plot1[0]), \"Mean Eval Rewards vs Episodes in DQN in CartPole\")\n",
        "    plotQuantity(DDQN_plot1, len(DDQN_plot1[0]), \"Mean Eval Rewards vs Episodes in DDQN in CartPole\")\n",
        "    plotQuantity(D3QN_plot1, len(D3QN_plot1[0]), \"Mean Eval Rewards vs Episodes in D3QN in CartPole\")\n",
        "\n",
        "    NFQ_plot1 = {}\n",
        "    DQN_plot1 = {}\n",
        "    DDQN_plot1 ={}\n",
        "    D3QN_plot1 = {}\n",
        "    for i in range(5):\n",
        "      NFQ_plot1[i] = NFQdict[i][1]\n",
        "      DQN_plot1[i] = DQNdict[i][1]\n",
        "      DDQN_plot1[i] = DDQNdict[i][1]\n",
        "      D3QN_plot1[i] = D3QNdict[i][1]\n",
        "\n",
        "    plotQuantity(NFQ_plot1, len(NFQ_plot1[0]), \"Training Time vs Episodes in NFQ in CartPole\")\n",
        "    plotQuantity(DQN_plot1, len(DQN_plot1[0]), \"Training Time vs Episodes in DQN in CartPole\")\n",
        "    plotQuantity(DDQN_plot1, len(DDQN_plot1[0]), \"Training Time vs Episodes in DDQN in CartPole\")\n",
        "    plotQuantity(D3QN_plot1, len(D3QN_plot1[0]), \"Training Time vs Episodes in D3QN in CartPole\")\n",
        "\n",
        "    NFQ_plot1 = {}\n",
        "    DQN_plot1 = {}\n",
        "    DDQN_plot1 ={}\n",
        "    D3QN_plot1 = {}\n",
        "    for i in range(5):\n",
        "      NFQ_plot1[i] = NFQdict[i][3]\n",
        "      DQN_plot1[i] = DQNdict[i][3]\n",
        "      DDQN_plot1[i] = DDQNdict[i][3]\n",
        "      D3QN_plot1[i] = D3QNdict[i][3]\n",
        "\n",
        "    plotQuantity(NFQ_plot1, len(NFQ_plot1[0]), \"Wall Clock Time vs Episodes in NFQ in CartPole\")\n",
        "    plotQuantity(DQN_plot1, len(DQN_plot1[0]), \"Wall Clock Time vs Episodes in DQN in CartPole\")\n",
        "    plotQuantity(DDQN_plot1, len(DDQN_plot1[0]), \"Wall Clock Time vs Episodes in DDQN in CartPole\")\n",
        "    plotQuantity(D3QN_plot1, len(D3QN_plot1[0]), \"Wall Clock Time vs Episodes in D3QN in CartPole\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    NFQdict={}\n",
        "    DQNdict={}\n",
        "    DDQNdict = {}\n",
        "    D3QNdict = {}\n",
        "    for i in range(5):\n",
        "      seed=random.randint(0,100)\n",
        "      NFQdict[i] = NFQ(envs2[i],seed=seed)\n",
        "      NFQdict[i] = NFQdict[i].runNFQ()\n",
        "      DQNdict[i] = DQN(envs2[i],seed=seed)\n",
        "      DQNdict[i] = DQNdict[i].runDQN()\n",
        "      DDQNdict[i] = DDQN(envs2[i], seed=seed)\n",
        "      DDQNdict[i] = DDQNdict[i].runDDQN()\n",
        "      D3QNdict[i] = D3QN(envs2[i], seed = seed)\n",
        "      D3QNdict[i] = D3QNdict[i].runD3QN()\n",
        "\n",
        "    NFQ_plot1 = {}\n",
        "    DQN_plot1 = {}\n",
        "    DDQN_plot1 ={}\n",
        "    D3QN_plot1 = {}\n",
        "    for i in range(5):\n",
        "      NFQ_plot1[i] = NFQdict[i][0]\n",
        "      DQN_plot1[i] = DQNdict[i][0]\n",
        "      DDQN_plot1[i] = DDQNdict[i][0]\n",
        "      D3QN_plot1[i] = D3QNdict[i][0]\n",
        "\n",
        "    plotQuantity(NFQ_plot1, len(NFQ_plot1[0]), \"Mean Train Rewards vs Episodes in NFQ in Mountain Car\")\n",
        "    plotQuantity(DQN_plot1, len(DQN_plot1[0]), \"Mean Train Rewards vs Episodes in DQN in Mountain Car\")\n",
        "    plotQuantity(DDQN_plot1, len(DDQN_plot1[0]), \"Mean Train Rewards vs Episodes in DDQN in Mountain Car\")\n",
        "    plotQuantity(D3QN_plot1, len(D3QN_plot1[0]), \"Mean Train Rewards vs Episodes in D3QN in Mountain Car\")\n",
        "\n",
        "    NFQ_plot1 = {}\n",
        "    DQN_plot1 = {}\n",
        "    DDQN_plot1 ={}\n",
        "    D3QN_plot1 = {}\n",
        "    for i in range(5):\n",
        "      NFQ_plot1[i] = NFQdict[i][2]\n",
        "      DQN_plot1[i] = DQNdict[i][2]\n",
        "      DDQN_plot1[i] = DDQNdict[i][2]\n",
        "      D3QN_plot1[i] = D3QNdict[i][2]\n",
        "\n",
        "    plotQuantity(NFQ_plot1, len(NFQ_plot1[0]), \"Mean Eval Rewards vs Episodes in NFQ in Mountain Car\")\n",
        "    plotQuantity(DQN_plot1, len(DQN_plot1[0]), \"Mean Eval Rewards vs Episodes in DQN in Mountain Car\")\n",
        "    plotQuantity(DDQN_plot1, len(DDQN_plot1[0]), \"Mean Eval Rewards vs Episodes in DDQN in Mountain Car\")\n",
        "    plotQuantity(D3QN_plot1, len(D3QN_plot1[0]), \"Mean Eval Rewards vs Episodes in D3QN in Mountain Car\")\n",
        "\n",
        "    NFQ_plot1 = {}\n",
        "    DQN_plot1 = {}\n",
        "    DDQN_plot1 ={}\n",
        "    D3QN_plot1 = {}\n",
        "    for i in range(5):\n",
        "      NFQ_plot1[i] = NFQdict[i][1]\n",
        "      DQN_plot1[i] = DQNdict[i][1]\n",
        "      DDQN_plot1[i] = DDQNdict[i][1]\n",
        "      D3QN_plot1[i] = D3QNdict[i][1]\n",
        "\n",
        "    plotQuantity(NFQ_plot1, len(NFQ_plot1[0]), \"Training Time vs Episodes in NFQ in Mountain Car\")\n",
        "    plotQuantity(DQN_plot1, len(DQN_plot1[0]), \"Training Time vs Episodes in DQN in Mountain Car\")\n",
        "    plotQuantity(DDQN_plot1, len(DDQN_plot1[0]), \"Training Time vs Episodes in DDQN in Mountain Car\")\n",
        "    plotQuantity(D3QN_plot1, len(D3QN_plot1[0]), \"Training Time vs Episodes in D3QN in Mountain Car\")\n",
        "\n",
        "    NFQ_plot1 = {}\n",
        "    DQN_plot1 = {}\n",
        "    DDQN_plot1 ={}\n",
        "    D3QN_plot1 = {}\n",
        "    for i in range(5):\n",
        "      NFQ_plot1[i] = NFQdict[i][3]\n",
        "      DQN_plot1[i] = DQNdict[i][3]\n",
        "      DDQN_plot1[i] = DDQNdict[i][3]\n",
        "      D3QN_plot1[i] = D3QNdict[i][3]\n",
        "\n",
        "    plotQuantity(NFQ_plot1, len(NFQ_plot1[0]), \"Wall Clock Time vs Episodes in NFQ in Mountain Car\")\n",
        "    plotQuantity(DQN_plot1, len(DQN_plot1[0]), \"Wall Clock Time vs Episodes in DQN in Mountain Car\")\n",
        "    plotQuantity(DDQN_plot1, len(DDQN_plot1[0]), \"Wall Clock Time vs Episodes in DDQN in Mountain Car\")\n",
        "    plotQuantity(D3QN_plot1, len(D3QN_plot1[0]), \"Wall Clock Time vs Episodes in D3QN in Mountain Car\")\n",
        "\n",
        "\n",
        "\n",
        "runDeepValueBasedAgents()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6UD1SCguImX"
      },
      "outputs": [],
      "source": [
        "def runDeepPolicyBasedAgents():\n",
        "    # this function will initialize 5 different instances of the env (using different seeds), run all the agents\n",
        "    # over these different instances. Collects results and generate the plots state above.\n",
        "    # generate your plots in the cells below\n",
        "    # write the answers to part 11, 12 and 13 in the cells below the plot-cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv81L1gtuImX"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEzMO0RPuImX"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}